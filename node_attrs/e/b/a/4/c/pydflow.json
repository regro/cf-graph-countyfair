{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "bot": {
      "automerge": true
    },
    "conda_build": {
      "error_overlinking": true
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_name": "pydflow",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "dev_url": "https://github.com/deepmodeling/dflow",
      "doc_url": "https://github.com/deepmodeling/dflow",
      "home": "https://github.com/deepmodeling/dflow",
      "license": "LGPL-3.0-only",
      "license_family": "LGPL",
      "license_file": "LICENSE",
      "summary": "Dflow is a Python framework for constructing scientific computing workflows employing Argo Workflows as the workflow engine."
    },
    "build": {
      "entry_points": [
        "dflow = dflow.main:main"
      ],
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "njzjz",
        "zjgemi"
      ]
    },
    "package": {
      "name": "pydflow",
      "version": "1.8.132"
    },
    "requirements": {
      "host": [
        "python 3.10",
        "pip",
        "setuptools"
      ],
      "run": [
        "python >=3.10",
        "six",
        "python-dateutil",
        "urllib3",
        "certifi",
        "argo-workflows 5.0.0",
        "jsonpickle",
        "minio",
        "python-kubernetes",
        "pyyaml",
        "cloudpickle 2.2.0",
        "requests",
        "tqdm",
        "psutil",
        "filelock"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "026ba9b43659d7bc11f7ec5281ad309a0d219cd3acb69c4e083d724f5e0a401a",
      "url": "https://pypi.org/packages/source/p/pydflow/pydflow-1.8.132.tar.gz"
    },
    "test": {
      "commands": [
        "dflow -h",
        "pip check"
      ],
      "imports": [
        "dflow",
        "dflow.python"
      ],
      "requires": [
        "pip",
        "python 3.10"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "argo-workflows",
        "certifi",
        "cloudpickle",
        "filelock",
        "jsonpickle",
        "minio",
        "psutil",
        "python",
        "python-dateutil",
        "python-kubernetes",
        "pyyaml",
        "requests",
        "six",
        "tqdm",
        "urllib3"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "dev_url": "https://github.com/deepmodeling/dflow",
      "doc_url": "https://github.com/deepmodeling/dflow",
      "home": "https://github.com/deepmodeling/dflow",
      "license": "LGPL-3.0-only",
      "license_family": "LGPL",
      "license_file": "LICENSE",
      "summary": "Dflow is a Python framework for constructing scientific computing workflows employing Argo Workflows as the workflow engine."
    },
    "build": {
      "entry_points": [
        "dflow = dflow.main:main"
      ],
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "njzjz",
        "zjgemi"
      ]
    },
    "package": {
      "name": "pydflow",
      "version": "1.8.132"
    },
    "requirements": {
      "host": [
        "python 3.10",
        "pip",
        "setuptools"
      ],
      "run": [
        "python >=3.10",
        "six",
        "python-dateutil",
        "urllib3",
        "certifi",
        "argo-workflows 5.0.0",
        "jsonpickle",
        "minio",
        "python-kubernetes",
        "pyyaml",
        "cloudpickle 2.2.0",
        "requests",
        "tqdm",
        "psutil",
        "filelock"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "026ba9b43659d7bc11f7ec5281ad309a0d219cd3acb69c4e083d724f5e0a401a",
      "url": "https://pypi.org/packages/source/p/pydflow/pydflow-1.8.132.tar.gz"
    },
    "test": {
      "commands": [
        "dflow -h",
        "pip check"
      ],
      "imports": [
        "dflow",
        "dflow.python"
      ],
      "requires": [
        "pip",
        "python 3.10"
      ]
    }
  },
  "name": "pydflow",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "pydflow"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/pydflow.json"
  },
  "raw_meta_yaml": "{% set name = \"pydflow\" %}\n{% set version = \"1.8.132\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 026ba9b43659d7bc11f7ec5281ad309a0d219cd3acb69c4e083d724f5e0a401a\n\nbuild:\n  number: 0\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv\n  entry_points:\n    - dflow = dflow.main:main\n\nrequirements:\n  host:\n    - python {{ python_min }}\n    - pip\n    - setuptools\n  run:\n    - python >={{ python_min }}\n    - six\n    - python-dateutil\n    - urllib3\n    - certifi\n    - argo-workflows 5.0.0\n    - jsonpickle\n    - minio\n    - python-kubernetes\n    - pyyaml\n    - cloudpickle 2.2.0\n    - requests\n    - tqdm\n    - psutil\n    - filelock\n\ntest:\n  imports:\n    - dflow\n    - dflow.python\n  requires:\n    - pip\n    - python {{ python_min }}\n  commands:\n    - dflow -h\n    - pip check\n\nabout:\n  home: https://github.com/deepmodeling/dflow\n  license: LGPL-3.0-only\n  license_family: LGPL\n  license_file: LICENSE\n  summary: Dflow is a Python framework for constructing scientific computing workflows employing Argo Workflows as the workflow engine.\n  doc_url: https://github.com/deepmodeling/dflow\n  dev_url: https://github.com/deepmodeling/dflow\n\nextra:\n  recipe-maintainers:\n    - njzjz\n    - zjgemi\n",
  "req": {
    "__set__": true,
    "elements": [
      "argo-workflows",
      "certifi",
      "cloudpickle",
      "filelock",
      "jsonpickle",
      "minio",
      "pip",
      "psutil",
      "python",
      "python-dateutil",
      "python-kubernetes",
      "pyyaml",
      "requests",
      "setuptools",
      "six",
      "tqdm",
      "urllib3"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "argo-workflows",
        "certifi",
        "cloudpickle",
        "filelock",
        "jsonpickle",
        "minio",
        "psutil",
        "python",
        "python-dateutil",
        "python-kubernetes",
        "pyyaml",
        "requests",
        "six",
        "tqdm",
        "urllib3"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python 3.10",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "argo-workflows 5.0.0",
        "certifi",
        "cloudpickle 2.2.0",
        "filelock",
        "jsonpickle",
        "minio",
        "psutil",
        "python >=3.10",
        "python-dateutil",
        "python-kubernetes",
        "pyyaml",
        "requests",
        "six",
        "tqdm",
        "urllib3"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python 3.10"
      ]
    }
  },
  "url": "https://pypi.org/packages/source/p/pydflow/pydflow-1.8.132.tar.gz",
  "version": "1.8.132",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/pydflow.json"
  }
}