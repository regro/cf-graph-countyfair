{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "build_platform": {
      "linux_aarch64": "linux_64",
      "linux_ppc64le": "linux_64",
      "osx_arm64": "osx_64"
    },
    "conda_build": {
      "error_overlinking": true
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    },
    "test": "native_and_emulated"
  },
  "feedstock_name": "curated-tokenizers",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "dev_url": "https://github.com/explosion/curated-tokenizers",
      "home": "https://github.com/explosion/curated-transformers",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Lightweight piece tokenization library"
    },
    "build": {
      "number": "4",
      "script": "python -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "h-vetinari",
        "conda-forge/spacy"
      ]
    },
    "package": {
      "name": "curated-tokenizers",
      "version": "0.0.9"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "cython",
        "libprotobuf",
        "libsentencepiece"
      ],
      "run": [
        "python",
        "regex"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "patches/0001-use-our-own-sentencepiece-abseil.patch"
      ],
      "sha256": "c93d47e54ab3528a6db2796eeb4bdce5d44e8226c671e42c2f23522ab1d0ce25",
      "url": "https://pypi.org/packages/source/c/curated-tokenizers/curated-tokenizers-0.0.9.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "curated_tokenizers"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cython",
        "libprotobuf",
        "libsentencepiece",
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "linux_aarch64_meta_yaml": {
    "about": {
      "dev_url": "https://github.com/explosion/curated-tokenizers",
      "home": "https://github.com/explosion/curated-transformers",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Lightweight piece tokenization library"
    },
    "build": {
      "number": "4",
      "script": "python -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "h-vetinari",
        "conda-forge/spacy"
      ]
    },
    "package": {
      "name": "curated-tokenizers",
      "version": "0.0.9"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "cython",
        "libprotobuf",
        "libsentencepiece"
      ],
      "run": [
        "python",
        "regex"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "patches/0001-use-our-own-sentencepiece-abseil.patch"
      ],
      "sha256": "c93d47e54ab3528a6db2796eeb4bdce5d44e8226c671e42c2f23522ab1d0ce25",
      "url": "https://pypi.org/packages/source/c/curated-tokenizers/curated-tokenizers-0.0.9.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "curated_tokenizers"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "linux_aarch64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cython",
        "libprotobuf",
        "libsentencepiece",
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "linux_ppc64le_meta_yaml": {
    "about": {
      "dev_url": "https://github.com/explosion/curated-tokenizers",
      "home": "https://github.com/explosion/curated-transformers",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Lightweight piece tokenization library"
    },
    "build": {
      "number": "4",
      "script": "python -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "h-vetinari",
        "conda-forge/spacy"
      ]
    },
    "package": {
      "name": "curated-tokenizers",
      "version": "0.0.9"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "cython",
        "libprotobuf",
        "libsentencepiece"
      ],
      "run": [
        "python",
        "regex"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "patches/0001-use-our-own-sentencepiece-abseil.patch"
      ],
      "sha256": "c93d47e54ab3528a6db2796eeb4bdce5d44e8226c671e42c2f23522ab1d0ce25",
      "url": "https://pypi.org/packages/source/c/curated-tokenizers/curated-tokenizers-0.0.9.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "curated_tokenizers"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "linux_ppc64le_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cython",
        "libprotobuf",
        "libsentencepiece",
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "dev_url": "https://github.com/explosion/curated-tokenizers",
      "home": "https://github.com/explosion/curated-transformers",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Lightweight piece tokenization library"
    },
    "build": {
      "number": "4",
      "script": "python -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "h-vetinari",
        "conda-forge/spacy"
      ]
    },
    "package": {
      "name": "curated-tokenizers",
      "version": "0.0.9"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "cython",
        "libprotobuf",
        "libsentencepiece"
      ],
      "run": [
        "python",
        "regex"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "patches/0001-use-our-own-sentencepiece-abseil.patch"
      ],
      "sha256": "c93d47e54ab3528a6db2796eeb4bdce5d44e8226c671e42c2f23522ab1d0ce25",
      "url": "https://pypi.org/packages/source/c/curated-tokenizers/curated-tokenizers-0.0.9.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "curated_tokenizers"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "name": "curated-tokenizers",
  "osx_64_meta_yaml": {
    "about": {
      "dev_url": "https://github.com/explosion/curated-tokenizers",
      "home": "https://github.com/explosion/curated-transformers",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Lightweight piece tokenization library"
    },
    "build": {
      "number": "4",
      "script": "python -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "h-vetinari",
        "conda-forge/spacy"
      ]
    },
    "package": {
      "name": "curated-tokenizers",
      "version": "0.0.9"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "cython",
        "libprotobuf",
        "libsentencepiece"
      ],
      "run": [
        "python",
        "regex"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "patches/0001-use-our-own-sentencepiece-abseil.patch"
      ],
      "sha256": "c93d47e54ab3528a6db2796eeb4bdce5d44e8226c671e42c2f23522ab1d0ce25",
      "url": "https://pypi.org/packages/source/c/curated-tokenizers/curated-tokenizers-0.0.9.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "curated_tokenizers"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "osx_64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cython",
        "libprotobuf",
        "libsentencepiece",
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "osx_arm64_meta_yaml": {
    "about": {
      "dev_url": "https://github.com/explosion/curated-tokenizers",
      "home": "https://github.com/explosion/curated-transformers",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Lightweight piece tokenization library"
    },
    "build": {
      "number": "4",
      "script": "python -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "h-vetinari",
        "conda-forge/spacy"
      ]
    },
    "package": {
      "name": "curated-tokenizers",
      "version": "0.0.9"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "cython",
        "libprotobuf",
        "libsentencepiece"
      ],
      "run": [
        "python",
        "regex"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "patches/0001-use-our-own-sentencepiece-abseil.patch"
      ],
      "sha256": "c93d47e54ab3528a6db2796eeb4bdce5d44e8226c671e42c2f23522ab1d0ce25",
      "url": "https://pypi.org/packages/source/c/curated-tokenizers/curated-tokenizers-0.0.9.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "curated_tokenizers"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "osx_arm64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cython",
        "libprotobuf",
        "libsentencepiece",
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "outputs_names": {
    "__set__": true,
    "elements": [
      "curated-tokenizers"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64",
    "linux_aarch64",
    "linux_ppc64le",
    "osx_64",
    "osx_arm64",
    "win_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/curated-tokenizers.json"
  },
  "raw_meta_yaml": "{% set version = \"0.0.9\" %}\n\npackage:\n  name: curated-tokenizers\n  version: {{ version }}\n\nsource:\n  url: https://pypi.org/packages/source/c/curated-tokenizers/curated-tokenizers-{{ version }}.tar.gz\n  sha256: c93d47e54ab3528a6db2796eeb4bdce5d44e8226c671e42c2f23522ab1d0ce25\n  patches:\n    - patches/0001-use-our-own-sentencepiece-abseil.patch\n\nbuild:\n  script: python -m pip install . -vv\n  number: 4\n\nrequirements:\n  build:\n    - {{ stdlib(\"c\") }}\n    - {{ compiler(\"c\") }}\n    - {{ compiler(\"cxx\") }}\n    - python                                 # [build_platform != target_platform]\n    - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n    - cython                                 # [build_platform != target_platform]\n  host:\n    - python\n    - pip\n    - setuptools\n    - cython\n    - libprotobuf\n    - libsentencepiece\n  run:\n    - python\n    - regex\n\ntest:\n  requires:\n    - pip\n  imports:\n    - curated_tokenizers\n  commands:\n    - pip check\n\nabout:\n  home: https://github.com/explosion/curated-transformers\n  summary: 'Lightweight piece tokenization library'\n  license: MIT\n  license_family: MIT\n  license_file: LICENSE\n  dev_url: https://github.com/explosion/curated-tokenizers\n\nextra:\n  recipe-maintainers:\n    - h-vetinari\n    - conda-forge/spacy\n",
  "req": {
    "__set__": true,
    "elements": [
      "c_compiler_stub",
      "c_stdlib_stub",
      "cxx_compiler_stub",
      "cython",
      "libprotobuf",
      "libsentencepiece",
      "pip",
      "python",
      "regex",
      "setuptools"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub",
        "cython",
        "libprotobuf",
        "libsentencepiece",
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub",
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cython",
        "libprotobuf",
        "libsentencepiece",
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "url": "https://pypi.org/packages/source/c/curated-tokenizers/curated-tokenizers-0.0.9.tar.gz",
  "version": "0.0.9",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/curated-tokenizers.json"
  },
  "win_64_meta_yaml": {
    "about": {
      "dev_url": "https://github.com/explosion/curated-tokenizers",
      "home": "https://github.com/explosion/curated-transformers",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Lightweight piece tokenization library"
    },
    "build": {
      "number": "4",
      "script": "python -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "h-vetinari",
        "conda-forge/spacy"
      ]
    },
    "package": {
      "name": "curated-tokenizers",
      "version": "0.0.9"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "cython",
        "libprotobuf",
        "libsentencepiece"
      ],
      "run": [
        "python",
        "regex"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "patches/0001-use-our-own-sentencepiece-abseil.patch"
      ],
      "sha256": "c93d47e54ab3528a6db2796eeb4bdce5d44e8226c671e42c2f23522ab1d0ce25",
      "url": "https://pypi.org/packages/source/c/curated-tokenizers/curated-tokenizers-0.0.9.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "curated_tokenizers"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "win_64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cxx_compiler_stub"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cython",
        "libprotobuf",
        "libsentencepiece",
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  }
}