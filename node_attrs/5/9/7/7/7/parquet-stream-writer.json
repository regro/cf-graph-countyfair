{
  "archived": false,
  "branch": "main",
  "ci_support_linux_64_.yaml": "channel_sources:\n- conda-forge\nchannel_targets:\n- conda-forge main\ndocker_image:\n- quay.io/condaforge/linux-anvil-x86_64:alma9\npython_min:\n- '3.10'\n",
  "conda-forge.yml": {
    "conda_build": {
      "error_overlinking": true
    },
    "conda_build_tool": "rattler-build",
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_hash": "efd7206c56b79dd3f8a109b9dba226351b3f4ff6",
  "feedstock_hash_ts": 1768216049,
  "feedstock_name": "parquet-stream-writer",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "description": "`parquet-stream-writer` provides a memory-efficient way to write streaming\ndata to Parquet. It buffers incoming records and writes them incrementally\nto disk. When a configurable size threshold is reached, it starts a new\nParquet shard, avoiding the need to load the entire dataset into memory.\nThis makes this library suitable for datasets that are too large to fit in\nthe available memory or for continuously generated data.",
      "home": "https://github.com/apcamargo/parquet-stream-writer",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Write streaming data to Parquet files with automatic sharding."
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "apcamargo"
      ]
    },
    "outputs": [
      {
        "build": null,
        "name": "parquet-stream-writer",
        "requirements": {
          "build": [],
          "host": [
            "python 3.10.*",
            "uv-build >=0.9,<0.10",
            "pip"
          ],
          "run": [
            "python >=3.10",
            "pyarrow >=21.0"
          ]
        },
        "tests": [
          {
            "python": {
              "imports": [
                "parquet_stream_writer"
              ],
              "python_version": "3.10.*"
            }
          }
        ],
        "version": "0.2.0"
      }
    ],
    "package": {
      "name": "parquet-stream-writer",
      "version": "0.2.0"
    },
    "requirements": {
      "host": [
        "python 3.10.*",
        "uv-build >=0.9,<0.10",
        "pip"
      ],
      "run": [
        "python >=3.10",
        "pyarrow >=21.0"
      ]
    },
    "schema_version": 1,
    "source": {
      "sha256": "2b74fc464c41722498e5ce8481f8cd6bddd1607db7d39b87760a6e50740760cc",
      "url": "https://pypi.org/packages/source/p/parquet-stream-writer/parquet_stream_writer-0.2.0.tar.gz"
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "uv-build"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "pyarrow",
        "python"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "description": "`parquet-stream-writer` provides a memory-efficient way to write streaming\ndata to Parquet. It buffers incoming records and writes them incrementally\nto disk. When a configurable size threshold is reached, it starts a new\nParquet shard, avoiding the need to load the entire dataset into memory.\nThis makes this library suitable for datasets that are too large to fit in\nthe available memory or for continuously generated data.",
      "home": "https://github.com/apcamargo/parquet-stream-writer",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Write streaming data to Parquet files with automatic sharding."
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "apcamargo"
      ]
    },
    "outputs": [
      {
        "build": null,
        "name": "parquet-stream-writer",
        "requirements": {
          "build": [],
          "host": [
            "python 3.10.*",
            "uv-build >=0.9,<0.10",
            "pip"
          ],
          "run": [
            "python >=3.10",
            "pyarrow >=21.0"
          ]
        },
        "tests": [
          {
            "python": {
              "imports": [
                "parquet_stream_writer"
              ],
              "python_version": "3.10.*"
            }
          }
        ],
        "version": "0.2.0"
      }
    ],
    "package": {
      "name": "parquet-stream-writer",
      "version": "0.2.0"
    },
    "requirements": {
      "host": [
        "python 3.10.*",
        "uv-build >=0.9,<0.10",
        "pip"
      ],
      "run": [
        "python >=3.10",
        "pyarrow >=21.0"
      ]
    },
    "schema_version": 1,
    "source": {
      "sha256": "2b74fc464c41722498e5ce8481f8cd6bddd1607db7d39b87760a6e50740760cc",
      "url": "https://pypi.org/packages/source/p/parquet-stream-writer/parquet_stream_writer-0.2.0.tar.gz"
    }
  },
  "name": "parquet-stream-writer",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "parquet-stream-writer"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/parquet-stream-writer.json"
  },
  "raw_meta_yaml": "context:\n  version: 0.2.0\n\npackage:\n  name: parquet-stream-writer\n  version: ${{ version }}\n\nsource:\n- url: https://pypi.org/packages/source/p/parquet-stream-writer/parquet_stream_writer-${{ version }}.tar.gz\n  sha256: 2b74fc464c41722498e5ce8481f8cd6bddd1607db7d39b87760a6e50740760cc\n\nbuild:\n  script: ${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation\n  noarch: python\n  number: 0\n\nrequirements:\n  host:\n  - python ${{ python_min }}.*\n  - uv-build >=0.9,<0.10\n  - pip\n  run:\n  - python >=${{ python_min }}\n  - pyarrow >=21.0\n\ntests:\n- python:\n    imports:\n    - parquet_stream_writer\n    pip_check: true\n    python_version: ${{ python_min }}.*\n\nabout:\n  license: MIT\n  license_file: LICENSE\n  homepage: https://github.com/apcamargo/parquet-stream-writer\n  summary: Write streaming data to Parquet files with automatic sharding.\n  description: |\n    `parquet-stream-writer` provides a memory-efficient way to write streaming\n    data to Parquet. It buffers incoming records and writes them incrementally\n    to disk. When a configurable size threshold is reached, it starts a new\n    Parquet shard, avoiding the need to load the entire dataset into memory.\n    This makes this library suitable for datasets that are too large to fit in\n    the available memory or for continuously generated data.\n\nextra:\n  recipe-maintainers:\n    - apcamargo\n",
  "req": {
    "__set__": true,
    "elements": [
      "pip",
      "pyarrow",
      "python",
      "uv-build"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "uv-build"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "pyarrow",
        "python"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python 3.10.*",
        "uv-build >=0.9,<0.10"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "pyarrow >=21.0",
        "python >=3.10"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "url": "https://pypi.org/packages/source/p/parquet-stream-writer/parquet_stream_writer-0.2.0.tar.gz",
  "version": "0.2.0",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/parquet-stream-writer.json"
  }
}