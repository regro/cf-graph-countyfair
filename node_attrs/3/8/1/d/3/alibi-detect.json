{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "bot": {
      "automerge": true
    },
    "conda_build": {
      "pkg_format": "2"
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_hash": "09371da6892ee47a4586b79f19fa2e58904c339b",
  "feedstock_hash_ts": 1730846927,
  "feedstock_name": "alibi-detect",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "description": "[Alibi Detect](https://github.com/SeldonIO/alibi-detect) is an open source\nPython library focused on **outlier**, **adversarial** and **drift** detection.\nThe package aims to cover both online and offline detectors for tabular data,\ntext, images and time series. Both **TensorFlow** and **PyTorch** backends are\nsupported for drift detection.\n\n- [Documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/)\n\nFor more background on the importance of monitoring outliers and distributions\nin a production setting, check out\n[this talk](https://slideslive.com/38931758/monitoring-and-explainability-of-models-in-production?ref=speaker-37384-latest)\nfrom the *Challenges in Deploying and Monitoring Machine Learning Systems*\nICML 2020 workshop, based on the paper [Monitoring and explainability of models\nin production](https://arxiv.org/abs/2007.06299) and referencing Alibi Detect.\n\nFor a thorough introduction to drift detection, check out [Protecting Your\nMachine Learning Against Drift: An Introduction](https://youtu.be/tL5sEaQha5o).\nhe talk covers what drift is and why it pays to detect it, the different types\nof drift, how it can be detected in a principled manner and also describes the\nanatomy of a drift detector.\n\n\nPyPI: [https://pypi.org/project/alibi-detect/](https://pypi.org/project/alibi-detect/)\n",
      "dev_url": "https://github.com/SeldonIO/alibi-detect",
      "doc_url": "https://docs.seldon.io/projects/alibi-detect/en/latest/",
      "home": "https://github.com/SeldonIO/alibi-detect",
      "license": "Apache-2.0",
      "license_file": "LICENSE",
      "summary": "Algorithms for outlier detection, concept drift and metrics."
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "sugatoray",
        "jklaise",
        "ascillitoe"
      ]
    },
    "package": {
      "name": "alibi-detect",
      "version": "0.11.4"
    },
    "requirements": {
      "host": [
        "pip",
        "python >=3.7"
      ],
      "run": [
        "python >=3.7",
        "dill >=0.3.0,<0.4.0",
        "matplotlib-base >=3.0.0,<4.0.0",
        "numba >=0.50.0,!=0.54.0,<0.56.0",
        "numpy >=1.16.2,<2.0.0",
        "opencv >=3.2.0,<5.0.0",
        "pandas >=0.23.3,<2.0.0",
        "pillow >=5.4.1,<10.0.0",
        "requests >=2.21.0,<3.0.0",
        "scikit-image >=0.14.2,!=0.17.1,<0.20",
        "scikit-learn >=0.20.2,<2.0.0",
        "scipy >=1.3.0,<2.0.0",
        "tqdm >=4.28.1,<5.0.0",
        "transformers >=4.0.0,<5.0.0",
        "typing-extensions >=3.7.4.3",
        "pydantic >=1.8.0,<2.0.0",
        "toml >=0.10.1,<1.0.0",
        "catalogue >=2.0.0,<3.0.0",
        "tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.10.0",
        "tensorflow-probability >=0.8.0,<0.18.0",
        "pytorch >=1.7.0,<1.13.0",
        "libgdal"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "5e81eee628260a264e5ebf27d9ab400a34f8ab53d1c0e883547c4c6f9b1aa1be",
      "url": "https://pypi.io/packages/source/a/alibi-detect/alibi-detect-0.11.4.tar.gz"
    },
    "test": {
      "imports": [
        "alibi_detect"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "catalogue",
        "dill",
        "libgdal",
        "matplotlib-base",
        "numba",
        "numpy",
        "opencv",
        "pandas",
        "pillow",
        "pydantic",
        "python",
        "pytorch",
        "requests",
        "scikit-image",
        "scikit-learn",
        "scipy",
        "tensorflow",
        "tensorflow-probability",
        "toml",
        "tqdm",
        "transformers",
        "typing-extensions"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "meta_yaml": {
    "about": {
      "description": "[Alibi Detect](https://github.com/SeldonIO/alibi-detect) is an open source\nPython library focused on **outlier**, **adversarial** and **drift** detection.\nThe package aims to cover both online and offline detectors for tabular data,\ntext, images and time series. Both **TensorFlow** and **PyTorch** backends are\nsupported for drift detection.\n\n- [Documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/)\n\nFor more background on the importance of monitoring outliers and distributions\nin a production setting, check out\n[this talk](https://slideslive.com/38931758/monitoring-and-explainability-of-models-in-production?ref=speaker-37384-latest)\nfrom the *Challenges in Deploying and Monitoring Machine Learning Systems*\nICML 2020 workshop, based on the paper [Monitoring and explainability of models\nin production](https://arxiv.org/abs/2007.06299) and referencing Alibi Detect.\n\nFor a thorough introduction to drift detection, check out [Protecting Your\nMachine Learning Against Drift: An Introduction](https://youtu.be/tL5sEaQha5o).\nhe talk covers what drift is and why it pays to detect it, the different types\nof drift, how it can be detected in a principled manner and also describes the\nanatomy of a drift detector.\n\n\nPyPI: [https://pypi.org/project/alibi-detect/](https://pypi.org/project/alibi-detect/)\n",
      "dev_url": "https://github.com/SeldonIO/alibi-detect",
      "doc_url": "https://docs.seldon.io/projects/alibi-detect/en/latest/",
      "home": "https://github.com/SeldonIO/alibi-detect",
      "license": "Apache-2.0",
      "license_file": "LICENSE",
      "summary": "Algorithms for outlier detection, concept drift and metrics."
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "sugatoray",
        "jklaise",
        "ascillitoe"
      ]
    },
    "package": {
      "name": "alibi-detect",
      "version": "0.11.4"
    },
    "requirements": {
      "host": [
        "pip",
        "python >=3.7"
      ],
      "run": [
        "python >=3.7",
        "dill >=0.3.0,<0.4.0",
        "matplotlib-base >=3.0.0,<4.0.0",
        "numba >=0.50.0,!=0.54.0,<0.56.0",
        "numpy >=1.16.2,<2.0.0",
        "opencv >=3.2.0,<5.0.0",
        "pandas >=0.23.3,<2.0.0",
        "pillow >=5.4.1,<10.0.0",
        "requests >=2.21.0,<3.0.0",
        "scikit-image >=0.14.2,!=0.17.1,<0.20",
        "scikit-learn >=0.20.2,<2.0.0",
        "scipy >=1.3.0,<2.0.0",
        "tqdm >=4.28.1,<5.0.0",
        "transformers >=4.0.0,<5.0.0",
        "typing-extensions >=3.7.4.3",
        "pydantic >=1.8.0,<2.0.0",
        "toml >=0.10.1,<1.0.0",
        "catalogue >=2.0.0,<3.0.0",
        "tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.10.0",
        "tensorflow-probability >=0.8.0,<0.18.0",
        "pytorch >=1.7.0,<1.13.0",
        "libgdal"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "5e81eee628260a264e5ebf27d9ab400a34f8ab53d1c0e883547c4c6f9b1aa1be",
      "url": "https://pypi.io/packages/source/a/alibi-detect/alibi-detect-0.11.4.tar.gz"
    },
    "test": {
      "imports": [
        "alibi_detect"
      ]
    }
  },
  "name": "alibi-detect",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "alibi-detect"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/alibi-detect.json"
  },
  "raw_meta_yaml": "{% set name = \"alibi-detect\" %}\n{% set version = \"0.11.4\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/alibi-detect-{{ version }}.tar.gz\n  sha256: 5e81eee628260a264e5ebf27d9ab400a34f8ab53d1c0e883547c4c6f9b1aa1be\n\nbuild:\n  number: 0\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - python >=3.7\n  run:\n    # Core dependencies\n    - python >=3.7\n    - dill >=0.3.0,<0.4.0\n    - matplotlib-base >=3.0.0,<4.0.0\n    - numba >=0.50.0,!=0.54.0,<0.56.0\n    - numpy >=1.16.2,<2.0.0\n    - opencv >=3.2.0,<5.0.0\n    - pandas >=0.23.3,<2.0.0\n    - pillow >=5.4.1,<10.0.0\n    - requests >=2.21.0,<3.0.0\n    - scikit-image >=0.14.2,!=0.17.1,<0.20\n    - scikit-learn >=0.20.2,<2.0.0\n    - scipy >=1.3.0,<2.0.0\n    - tqdm >=4.28.1,<5.0.0\n    - transformers >=4.0.0,<5.0.0\n    - typing-extensions >=3.7.4.3\n    - pydantic >=1.8.0,<2.0.0\n    - toml >=0.10.1,<1.0.0\n    - catalogue >=2.0.0,<3.0.0\n    # Optional dependencies, but treat as core for conda\n    - tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.10.0\n    - tensorflow-probability >=0.8.0,<0.18.0\n    - pytorch >=1.7.0,<1.13.0\n    ## Note: Necessary for supporting \"opencv\"\n    #  A. \"mesa-libGL\" should be present in \"yum_requirements.txt\".\n    #  B. \"libgdal\" should be added to \"meta.yaml:requirements:run\".\n    - libgdal\n\ntest:\n  imports:\n    - alibi_detect\n  # commands:\n  #   - pip check\n  # requires:\n  #   - pip\n\nabout:\n  home: https://github.com/SeldonIO/alibi-detect\n  summary: Algorithms for outlier detection, concept drift and metrics.\n  license: Apache-2.0\n  license_file: LICENSE\n  description: |\n    [Alibi Detect](https://github.com/SeldonIO/alibi-detect) is an open source \n    Python library focused on **outlier**, **adversarial** and **drift** detection. \n    The package aims to cover both online and offline detectors for tabular data, \n    text, images and time series. Both **TensorFlow** and **PyTorch** backends are \n    supported for drift detection.\n\n    - [Documentation](https://docs.seldon.io/projects/alibi-detect/en/latest/)\n\n    For more background on the importance of monitoring outliers and distributions \n    in a production setting, check out \n    [this talk](https://slideslive.com/38931758/monitoring-and-explainability-of-models-in-production?ref=speaker-37384-latest) \n    from the *Challenges in Deploying and Monitoring Machine Learning Systems* \n    ICML 2020 workshop, based on the paper [Monitoring and explainability of models \n    in production](https://arxiv.org/abs/2007.06299) and referencing Alibi Detect.\n\n    For a thorough introduction to drift detection, check out [Protecting Your \n    Machine Learning Against Drift: An Introduction](https://youtu.be/tL5sEaQha5o). \n    he talk covers what drift is and why it pays to detect it, the different types \n    of drift, how it can be detected in a principled manner and also describes the \n    anatomy of a drift detector.\n\n\n    PyPI: [https://pypi.org/project/alibi-detect/](https://pypi.org/project/alibi-detect/)\n\n  doc_url: https://docs.seldon.io/projects/alibi-detect/en/latest/\n  dev_url: https://github.com/SeldonIO/alibi-detect\n\nextra:\n  recipe-maintainers:\n    - sugatoray\n    # Maintainers from upstream repo\n    - jklaise\n    - ascillitoe\n",
  "req": {
    "__set__": true,
    "elements": [
      "catalogue",
      "dill",
      "libgdal",
      "matplotlib-base",
      "numba",
      "numpy",
      "opencv",
      "pandas",
      "pillow",
      "pip",
      "pydantic",
      "python",
      "pytorch",
      "requests",
      "scikit-image",
      "scikit-learn",
      "scipy",
      "tensorflow",
      "tensorflow-probability",
      "toml",
      "tqdm",
      "transformers",
      "typing-extensions"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "catalogue",
        "dill",
        "libgdal",
        "matplotlib-base",
        "numba",
        "numpy",
        "opencv",
        "pandas",
        "pillow",
        "pydantic",
        "python",
        "pytorch",
        "requests",
        "scikit-image",
        "scikit-learn",
        "scipy",
        "tensorflow",
        "tensorflow-probability",
        "toml",
        "tqdm",
        "transformers",
        "typing-extensions"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python >=3.7"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "catalogue >=2.0.0,<3.0.0",
        "dill >=0.3.0,<0.4.0",
        "libgdal",
        "matplotlib-base >=3.0.0,<4.0.0",
        "numba >=0.50.0,!=0.54.0,<0.56.0",
        "numpy >=1.16.2,<2.0.0",
        "opencv >=3.2.0,<5.0.0",
        "pandas >=0.23.3,<2.0.0",
        "pillow >=5.4.1,<10.0.0",
        "pydantic >=1.8.0,<2.0.0",
        "python >=3.7",
        "pytorch >=1.7.0,<1.13.0",
        "requests >=2.21.0,<3.0.0",
        "scikit-image >=0.14.2,!=0.17.1,<0.20",
        "scikit-learn >=0.20.2,<2.0.0",
        "scipy >=1.3.0,<2.0.0",
        "tensorflow >=2.2.0,!=2.6.0,!=2.6.1,<2.10.0",
        "tensorflow-probability >=0.8.0,<0.18.0",
        "toml >=0.10.1,<1.0.0",
        "tqdm >=4.28.1,<5.0.0",
        "transformers >=4.0.0,<5.0.0",
        "typing-extensions >=3.7.4.3"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "url": "https://pypi.io/packages/source/a/alibi-detect/alibi-detect-0.11.4.tar.gz",
  "version": "0.11.4",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/alibi-detect.json"
  }
}