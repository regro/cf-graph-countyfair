{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "bot": {
      "automerge": true,
      "inspection": "update-grayskull"
    },
    "conda_build": {
      "error_overlinking": true
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_hash": "f77e8a13264a006ebc2b995714f20884405a2b8e",
  "feedstock_hash_ts": 1735639659,
  "feedstock_name": "llama-index-legacy",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "dev_url": "https://github.com/run-llama/llama_index/tree/main/llama-index-legacy",
      "home": "https://llamaindex.ai",
      "license": "MIT",
      "license_file": "LICENSE",
      "summary": "Interface between LLMs and your data"
    },
    "build": {
      "entry_points": [
        "llamaindex-legacy-cli = llama_index.legacy.command_line.command_line:main"
      ],
      "noarch": "python",
      "number": "1",
      "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "pavelzw"
      ]
    },
    "package": {
      "name": "llama-index-legacy",
      "version": "0.9.48.post4"
    },
    "requirements": {
      "host": [
        "python 3.9",
        "poetry-core",
        "pip"
      ],
      "run": [
        "typing_extensions >=4.5.0",
        "python >=3.9,<4.0",
        "sqlalchemy >=1.4.49",
        "dataclasses-json",
        "deprecated >=1.2.9.3",
        "fsspec >=2023.5.0",
        "httpx",
        "nest-asyncio >=1.5.8,<2.0.0",
        "nltk >=3.8.1",
        "numpy",
        "openai >=1.1.0",
        "pandas",
        "tenacity >=8.2.0,<9.0.0",
        "tiktoken >=0.3.3",
        "typing-extensions >=4.5.0",
        "typing_inspect >=0.8.0",
        "requests >=2.31.0",
        "aiohttp >=3.8.6,<4.0.0",
        "networkx >=3.0",
        "dirtyjson >=1.0.8,<2.0.0"
      ],
      "run_constrained": [
        "beautifulsoup4 >=4.12.2,<5.0.0",
        "langchain >=0.0.303",
        "gradientai >=1.4.0",
        "asyncpg >=0.28.0,<0.29.0",
        "pgvector >=0.1.0,<0.2.0",
        "optimum >=1.13.2,<2.0.0",
        "sentencepiece >=0.1.99,<0.2.0",
        "transformers >=4.33.1,<5.0.0",
        "guidance >=0.0.64,<0.0.65",
        "lm-format-enforcer >=0.4.3,<0.5.0",
        "jsonpath-ng >=1.6.0,<2.0.0",
        "rank-bm25 >=0.2.2,<0.3.0",
        "scikit-learn *",
        "spacy >=3.7.1,<4.0.0",
        "psycopg2-binary >=2.9.9,<3.0.0"
      ]
    },
    "schema_version": 0,
    "source": [
      {
        "sha256": "f8a9764e7e134a52bfef5e53d2d62561bfc01fc09874c51cc001df6f5302ae30",
        "url": "https://pypi.org/packages/source/l/llama-index-legacy/llama_index_legacy-0.9.48.post4.tar.gz"
      },
      {
        "sha256": "24f40b5190fdacabc24ddbb5f76364d15e4f030925220ea300d8a2dd4993c8cb",
        "url": "https://raw.githubusercontent.com/run-llama/llama_index/main/LICENSE"
      }
    ],
    "test": {
      "commands": [
        "pip check",
        "llamaindex-legacy-cli --help"
      ],
      "imports": [
        "llama_index.legacy"
      ],
      "requires": [
        "pip",
        "python 3.9"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "poetry-core",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "aiohttp",
        "dataclasses-json",
        "deprecated",
        "dirtyjson",
        "fsspec",
        "httpx",
        "nest-asyncio",
        "networkx",
        "nltk",
        "numpy",
        "openai",
        "pandas",
        "python",
        "requests",
        "sqlalchemy",
        "tenacity",
        "tiktoken",
        "typing-extensions",
        "typing_extensions",
        "typing_inspect"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "dev_url": "https://github.com/run-llama/llama_index/tree/main/llama-index-legacy",
      "home": "https://llamaindex.ai",
      "license": "MIT",
      "license_file": "LICENSE",
      "summary": "Interface between LLMs and your data"
    },
    "build": {
      "entry_points": [
        "llamaindex-legacy-cli = llama_index.legacy.command_line.command_line:main"
      ],
      "noarch": "python",
      "number": "1",
      "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "pavelzw"
      ]
    },
    "package": {
      "name": "llama-index-legacy",
      "version": "0.9.48.post4"
    },
    "requirements": {
      "host": [
        "python 3.9",
        "poetry-core",
        "pip"
      ],
      "run": [
        "typing_extensions >=4.5.0",
        "python >=3.9,<4.0",
        "sqlalchemy >=1.4.49",
        "dataclasses-json",
        "deprecated >=1.2.9.3",
        "fsspec >=2023.5.0",
        "httpx",
        "nest-asyncio >=1.5.8,<2.0.0",
        "nltk >=3.8.1",
        "numpy",
        "openai >=1.1.0",
        "pandas",
        "tenacity >=8.2.0,<9.0.0",
        "tiktoken >=0.3.3",
        "typing-extensions >=4.5.0",
        "typing_inspect >=0.8.0",
        "requests >=2.31.0",
        "aiohttp >=3.8.6,<4.0.0",
        "networkx >=3.0",
        "dirtyjson >=1.0.8,<2.0.0"
      ],
      "run_constrained": [
        "beautifulsoup4 >=4.12.2,<5.0.0",
        "langchain >=0.0.303",
        "gradientai >=1.4.0",
        "asyncpg >=0.28.0,<0.29.0",
        "pgvector >=0.1.0,<0.2.0",
        "optimum >=1.13.2,<2.0.0",
        "sentencepiece >=0.1.99,<0.2.0",
        "transformers >=4.33.1,<5.0.0",
        "guidance >=0.0.64,<0.0.65",
        "lm-format-enforcer >=0.4.3,<0.5.0",
        "jsonpath-ng >=1.6.0,<2.0.0",
        "rank-bm25 >=0.2.2,<0.3.0",
        "scikit-learn *",
        "spacy >=3.7.1,<4.0.0",
        "psycopg2-binary >=2.9.9,<3.0.0"
      ]
    },
    "schema_version": 0,
    "source": [
      {
        "sha256": "f8a9764e7e134a52bfef5e53d2d62561bfc01fc09874c51cc001df6f5302ae30",
        "url": "https://pypi.org/packages/source/l/llama-index-legacy/llama_index_legacy-0.9.48.post4.tar.gz"
      },
      {
        "sha256": "24f40b5190fdacabc24ddbb5f76364d15e4f030925220ea300d8a2dd4993c8cb",
        "url": "https://raw.githubusercontent.com/run-llama/llama_index/main/LICENSE"
      }
    ],
    "test": {
      "commands": [
        "pip check",
        "llamaindex-legacy-cli --help"
      ],
      "imports": [
        "llama_index.legacy"
      ],
      "requires": [
        "pip",
        "python 3.9"
      ]
    }
  },
  "name": "llama-index-legacy",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "llama-index-legacy"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/llama-index-legacy.json"
  },
  "raw_meta_yaml": "{% set name = \"llama-index-legacy\" %}\n{% set version = \"0.9.48.post4\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  - url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/llama_index_legacy-{{ version }}.tar.gz\n    sha256: f8a9764e7e134a52bfef5e53d2d62561bfc01fc09874c51cc001df6f5302ae30\n  # https://github.com/run-llama/llama_index/issues/10806\n  - url: https://raw.githubusercontent.com/run-llama/llama_index/main/LICENSE\n    sha256: 24f40b5190fdacabc24ddbb5f76364d15e4f030925220ea300d8a2dd4993c8cb\n\nbuild:\n  entry_points:\n    - llamaindex-legacy-cli = llama_index.legacy.command_line.command_line:main\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation\n  number: 1\n\nrequirements:\n  host:\n    - python {{ python_min }}\n    - poetry-core\n    - pip\n  run:\n    - typing_extensions >=4.5.0\n    - python >={{ python_min }},<4.0\n    - sqlalchemy >=1.4.49\n    - dataclasses-json\n    - deprecated >=1.2.9.3\n    - fsspec >=2023.5.0\n    - httpx\n    - nest-asyncio >=1.5.8,<2.0.0\n    - nltk >=3.8.1\n    - numpy\n    - openai >=1.1.0\n    - pandas\n    - tenacity >=8.2.0,<9.0.0\n    - tiktoken >=0.3.3\n    - typing-extensions >=4.5.0\n    - typing_inspect >=0.8.0\n    - requests >=2.31.0\n    - aiohttp >=3.8.6,<4.0.0\n    - networkx >=3.0\n    - dirtyjson >=1.0.8,<2.0.0\n  run_constrained:\n    - beautifulsoup4 >=4.12.2,<5.0.0\n    - langchain >=0.0.303\n    - gradientai >=1.4.0\n    - asyncpg >=0.28.0,<0.29.0\n    - pgvector >=0.1.0,<0.2.0\n    - optimum >=1.13.2,<2.0.0\n    - sentencepiece >=0.1.99,<0.2.0\n    - transformers >=4.33.1,<5.0.0\n    - guidance >=0.0.64,<0.0.65\n    - lm-format-enforcer >=0.4.3,<0.5.0\n    - jsonpath-ng >=1.6.0,<2.0.0\n    - rank-bm25 >=0.2.2,<0.3.0\n    - scikit-learn *\n    - spacy >=3.7.1,<4.0.0\n    - psycopg2-binary >=2.9.9,<3.0.0\n\ntest:\n  imports:\n    - llama_index.legacy\n  commands:\n    - pip check\n    - llamaindex-legacy-cli --help\n  requires:\n    - pip\n    - python {{ python_min }}\n\nabout:\n  home: https://llamaindex.ai\n  dev_url: https://github.com/run-llama/llama_index/tree/main/llama-index-legacy\n  summary: Interface between LLMs and your data\n  license: MIT\n  license_file: LICENSE\n\nextra:\n  recipe-maintainers:\n    - pavelzw\n",
  "req": {
    "__set__": true,
    "elements": [
      "aiohttp",
      "dataclasses-json",
      "deprecated",
      "dirtyjson",
      "fsspec",
      "httpx",
      "nest-asyncio",
      "networkx",
      "nltk",
      "numpy",
      "openai",
      "pandas",
      "pip",
      "poetry-core",
      "python",
      "requests",
      "sqlalchemy",
      "tenacity",
      "tiktoken",
      "typing-extensions",
      "typing_extensions",
      "typing_inspect"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "poetry-core",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "aiohttp",
        "dataclasses-json",
        "deprecated",
        "dirtyjson",
        "fsspec",
        "httpx",
        "nest-asyncio",
        "networkx",
        "nltk",
        "numpy",
        "openai",
        "pandas",
        "python",
        "requests",
        "sqlalchemy",
        "tenacity",
        "tiktoken",
        "typing-extensions",
        "typing_extensions",
        "typing_inspect"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "poetry-core",
        "python 3.9"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "aiohttp >=3.8.6,<4.0.0",
        "dataclasses-json",
        "deprecated >=1.2.9.3",
        "dirtyjson >=1.0.8,<2.0.0",
        "fsspec >=2023.5.0",
        "httpx",
        "nest-asyncio >=1.5.8,<2.0.0",
        "networkx >=3.0",
        "nltk >=3.8.1",
        "numpy",
        "openai >=1.1.0",
        "pandas",
        "python >=3.9,<4.0",
        "requests >=2.31.0",
        "sqlalchemy >=1.4.49",
        "tenacity >=8.2.0,<9.0.0",
        "tiktoken >=0.3.3",
        "typing-extensions >=4.5.0",
        "typing_extensions >=4.5.0",
        "typing_inspect >=0.8.0"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python 3.9"
      ]
    }
  },
  "url": "https://pypi.org/packages/source/l/llama-index-legacy/llama_index_legacy-0.9.48.post4.tar.gz",
  "version": "0.9.48.post4",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/llama-index-legacy.json"
  }
}