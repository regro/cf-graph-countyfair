{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "bot": {
      "automerge": true
    },
    "conda_build": {
      "error_overlinking": true
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_name": "r-fairmodels",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "home": "https://fairmodels.drwhy.ai/",
      "license": "GPL-3.0-only",
      "license_family": "GPL3",
      "license_file": [
        "/lib/R/share/licenses/GPL-3"
      ],
      "summary": "Measure fairness metrics in one place for many models. Check how big is model's bias towards different races, sex, nationalities etc. Use measures such as Statistical Parity, Equal odds to detect the discrimination against unprivileged groups. Visualize the bias using heatmap, radar plot, biplot, bar chart (and more!). There are various pre-processing and post-processing bias mitigation algorithms implemented. Package also supports calculating fairness metrics for regression models. Find more details in (Wiśniewski, Biecek (2021)) <arXiv:2104.00507>."
    },
    "build": {
      "noarch": "generic",
      "number": "2",
      "rpaths": [
        "lib/R/lib/",
        "lib/"
      ]
    },
    "extra": {
      "recipe-maintainers": [
        "conda-forge/r",
        "dillonroach"
      ]
    },
    "package": {
      "name": "r-fairmodels",
      "version": "1.2.1"
    },
    "requirements": {
      "build": [],
      "host": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ],
      "run": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "97c39e00fe05402bc65b03d05f14698ed8101266e837f3534dac09d8cb17b373",
      "url": [
        "https://cran.r-project.org/src/contrib/fairmodels_1.2.1.tar.gz",
        "https://cran.r-project.org/src/contrib/Archive/fairmodels/fairmodels_1.2.1.tar.gz"
      ]
    },
    "test": {
      "commands": [
        "$R -e \"library('fairmodels')\""
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "meta_yaml": {
    "about": {
      "home": "https://fairmodels.drwhy.ai/",
      "license": "GPL-3.0-only",
      "license_family": "GPL3",
      "license_file": [
        "/lib/R/share/licenses/GPL-3"
      ],
      "summary": "Measure fairness metrics in one place for many models. Check how big is model's bias towards different races, sex, nationalities etc. Use measures such as Statistical Parity, Equal odds to detect the discrimination against unprivileged groups. Visualize the bias using heatmap, radar plot, biplot, bar chart (and more!). There are various pre-processing and post-processing bias mitigation algorithms implemented. Package also supports calculating fairness metrics for regression models. Find more details in (Wiśniewski, Biecek (2021)) <arXiv:2104.00507>."
    },
    "build": {
      "noarch": "generic",
      "number": "2",
      "rpaths": [
        "lib/R/lib/",
        "lib/"
      ]
    },
    "extra": {
      "recipe-maintainers": [
        "conda-forge/r",
        "dillonroach"
      ]
    },
    "package": {
      "name": "r-fairmodels",
      "version": "1.2.1"
    },
    "requirements": {
      "build": [],
      "host": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ],
      "run": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "97c39e00fe05402bc65b03d05f14698ed8101266e837f3534dac09d8cb17b373",
      "url": [
        "https://cran.r-project.org/src/contrib/fairmodels_1.2.1.tar.gz",
        "https://cran.r-project.org/src/contrib/Archive/fairmodels/fairmodels_1.2.1.tar.gz"
      ]
    },
    "test": {
      "commands": [
        "$R -e \"library('fairmodels')\""
      ]
    }
  },
  "name": "r-fairmodels",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "r-fairmodels"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/r-fairmodels.json"
  },
  "raw_meta_yaml": "{% set version = '1.2.1' %}\n{% set posix = 'm2-' if win else '' %}\n\npackage:\n  name: r-fairmodels\n  version: {{ version|replace(\"-\", \"_\") }}\n\nsource:\n  url:\n    - {{ cran_mirror }}/src/contrib/fairmodels_{{ version }}.tar.gz\n    - {{ cran_mirror }}/src/contrib/Archive/fairmodels/fairmodels_{{ version }}.tar.gz\n  sha256: 97c39e00fe05402bc65b03d05f14698ed8101266e837f3534dac09d8cb17b373\n\nbuild:\n  noarch: generic\n  number: 2\n  rpaths:\n    - lib/R/lib/\n    - lib/\n\nrequirements:\n  build:\n    - cross-r-base {{ r_base }}    # [build_platform != target_platform]\n  host:\n    - r-base\n    - r-dalex\n    - r-ggplot2\n    - r-patchwork\n    - r-scales\n  run:\n    - r-base\n    - r-dalex\n    - r-ggplot2\n    - r-patchwork\n    - r-scales\n\ntest:\n  commands:\n    - $R -e \"library('fairmodels')\"           # [not win]\n\nabout:\n  home: https://fairmodels.drwhy.ai/\n  license: GPL-3.0-only\n  summary: \"Measure fairness metrics in one place for many models. Check how big is model's bias\n    towards different races, sex, nationalities etc. Use measures such as Statistical\n    Parity, Equal odds to detect the discrimination against unprivileged groups. Visualize\n    the bias using heatmap, radar plot, biplot, bar chart (and more!). There are various\n    pre-processing and post-processing bias mitigation algorithms implemented. Package\n    also supports calculating fairness metrics for regression models. Find more details\n    in (Wi\\u015Bniewski, Biecek (2021)) <arXiv:2104.00507>.\"\n  license_family: GPL3\n  license_file:\n    - '{{ environ[\"PREFIX\"] }}/lib/R/share/licenses/GPL-3'\n\nextra:\n  recipe-maintainers:\n    - conda-forge/r\n    - dillonroach\n\n# Package: fairmodels\n# Type: Package\n# Title: Flexible Tool for Bias Detection, Visualization, and Mitigation\n# Version: 1.2.1\n# Authors@R: c(person(\"Jakub\", \"Wisniewski\", role = c(\"aut\", \"cre\"), email = \"jakwisn@gmail.com\"), person(\"Przemysaw\", \"Biecek\", role = c(\"aut\"), comment = c(ORCID = \"0000-0001-8423-1823\")))\n# Description: Measure fairness metrics in one place for many models. Check how big is model's bias towards different races, sex, nationalities etc. Use measures such as Statistical Parity, Equal odds to detect the discrimination against unprivileged groups. Visualize the bias using heatmap, radar plot, biplot, bar chart (and more!). There are various pre-processing and post-processing bias mitigation algorithms implemented. Package also supports calculating fairness metrics for regression models. Find more details in (Wisniewski, Biecek (2021)) <arXiv:2104.00507>.\n# License: GPL-3\n# Encoding: UTF-8\n# LazyData: true\n# Depends: R (>= 3.5)\n# Imports: DALEX, ggplot2, scales, stats, patchwork,\n# Suggests: ranger, gbm, knitr, rmarkdown, covr, testthat, spelling, ggdendro, ggrepel,\n# RoxygenNote: 7.1.1.9001\n# VignetteBuilder: knitr\n# URL: https://fairmodels.drwhy.ai/\n# BugReports: https://github.com/ModelOriented/fairmodels/issues\n# Language: en-US\n# NeedsCompilation: no\n# Packaged: 2022-08-23 19:31:51 UTC; jakwi\n# Author: Jakub Wisniewski [aut, cre], Przemysaw Biecek [aut] (<https://orcid.org/0000-0001-8423-1823>)\n# Maintainer: Jakub Wisniewski <jakwisn@gmail.com>\n# Repository: CRAN\n# Date/Publication: 2022-08-23 19:50:06 UTC\n",
  "req": {
    "__set__": true,
    "elements": [
      "r-base",
      "r-dalex",
      "r-ggplot2",
      "r-patchwork",
      "r-scales"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-dalex",
        "r-ggplot2",
        "r-patchwork",
        "r-scales"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "url": [
    "https://cran.r-project.org/src/contrib/fairmodels_1.2.1.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/fairmodels/fairmodels_1.2.1.tar.gz"
  ],
  "version": "1.2.1",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/r-fairmodels.json"
  }
}