{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "conda_build": {
      "pkg_format": "2"
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_hash": "adfd4d4f5f782430c0f10e44ab0d9fb3fa153e0d",
  "feedstock_hash_ts": 1730849562,
  "feedstock_name": "optimum-habana",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "description": "Optimum Habana is the interface between the Hugging Face Transformers library\nand Habana Gaudi Processor (HPU). It provides a set of tools enabling easy model\nloading and fine-tuning on single- and multi-HPU settings for different downstream tasks.\n\nPyPI: [https://pypi.org/project/optimum-habana/](https://pypi.org/project/optimum-habana/)\n",
      "dev_url": "https://github.com/huggingface/optimum-habana",
      "doc_url": "https://huggingface.co/hardware/habana",
      "home": "https://huggingface.co/hardware/habana",
      "license": "Apache-2.0",
      "license_file": [
        "LICENSE"
      ],
      "summary": "Optimum Habana is the interface between the Hugging Face Transformers library\nand Habana Gaudi Processor (HPU). It provides a set of tools enabling easy model\nloading and fine-tuning on single- and multi-HPU settings for different downstream tasks.\n"
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "sugatoray"
      ]
    },
    "package": {
      "name": "optimum-habana",
      "version": "1.1.2"
    },
    "requirements": {
      "host": [
        "pip",
        "python >=3.7"
      ],
      "run": [
        "python >=3.7",
        "datasets",
        "optimum",
        "pillow",
        "scipy",
        "sentencepiece",
        "tokenizers",
        "pytorch",
        "transformers >=4.20.0"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "bfe02df164de0250c0e75336d9bb1f92e674e9724e03750c94f0d1e508d64dc8",
      "url": "https://pypi.io/packages/source/o/optimum-habana/optimum-habana-1.1.2.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "optimum"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "datasets",
        "optimum",
        "pillow",
        "python",
        "pytorch",
        "scipy",
        "sentencepiece",
        "tokenizers",
        "transformers"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "description": "Optimum Habana is the interface between the Hugging Face Transformers library\nand Habana Gaudi Processor (HPU). It provides a set of tools enabling easy model\nloading and fine-tuning on single- and multi-HPU settings for different downstream tasks.\n\nPyPI: [https://pypi.org/project/optimum-habana/](https://pypi.org/project/optimum-habana/)\n",
      "dev_url": "https://github.com/huggingface/optimum-habana",
      "doc_url": "https://huggingface.co/hardware/habana",
      "home": "https://huggingface.co/hardware/habana",
      "license": "Apache-2.0",
      "license_file": [
        "LICENSE"
      ],
      "summary": "Optimum Habana is the interface between the Hugging Face Transformers library\nand Habana Gaudi Processor (HPU). It provides a set of tools enabling easy model\nloading and fine-tuning on single- and multi-HPU settings for different downstream tasks.\n"
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "sugatoray"
      ]
    },
    "package": {
      "name": "optimum-habana",
      "version": "1.1.2"
    },
    "requirements": {
      "host": [
        "pip",
        "python >=3.7"
      ],
      "run": [
        "python >=3.7",
        "datasets",
        "optimum",
        "pillow",
        "scipy",
        "sentencepiece",
        "tokenizers",
        "pytorch",
        "transformers >=4.20.0"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "bfe02df164de0250c0e75336d9bb1f92e674e9724e03750c94f0d1e508d64dc8",
      "url": "https://pypi.io/packages/source/o/optimum-habana/optimum-habana-1.1.2.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "optimum"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "name": "optimum-habana",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "optimum-habana"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/optimum-habana.json"
  },
  "raw_meta_yaml": "{% set name = \"optimum-habana\" %}\n{% set version = \"1.1.2\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/optimum-habana-{{ version }}.tar.gz\n  sha256: bfe02df164de0250c0e75336d9bb1f92e674e9724e03750c94f0d1e508d64dc8\n\nbuild:\n  number: 0\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - python >=3.7\n  run:\n    - python >=3.7\n    - datasets\n    - optimum\n    - pillow\n    - scipy\n    - sentencepiece\n    - tokenizers\n    - pytorch\n    - transformers >=4.20.0\n\ntest:\n  imports:\n    - optimum\n  commands:\n    - pip check\n  requires:\n    - pip\n\nabout:\n  home: https://huggingface.co/hardware/habana\n  summary: |\n    Optimum Habana is the interface between the Hugging Face Transformers library \n    and Habana Gaudi Processor (HPU). It provides a set of tools enabling easy model \n    loading and fine-tuning on single- and multi-HPU settings for different downstream tasks.\n  license: Apache-2.0\n  license_file:\n    - LICENSE\n  description: |\n    Optimum Habana is the interface between the Hugging Face Transformers library \n    and Habana Gaudi Processor (HPU). It provides a set of tools enabling easy model \n    loading and fine-tuning on single- and multi-HPU settings for different downstream tasks.\n\n    PyPI: [https://pypi.org/project/optimum-habana/](https://pypi.org/project/optimum-habana/)\n\n  doc_url: https://huggingface.co/hardware/habana\n  dev_url: https://github.com/huggingface/optimum-habana\n\nextra:\n  recipe-maintainers:\n    - sugatoray\n",
  "req": {
    "__set__": true,
    "elements": [
      "datasets",
      "optimum",
      "pillow",
      "pip",
      "python",
      "pytorch",
      "scipy",
      "sentencepiece",
      "tokenizers",
      "transformers"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "datasets",
        "optimum",
        "pillow",
        "python",
        "pytorch",
        "scipy",
        "sentencepiece",
        "tokenizers",
        "transformers"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python >=3.7"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "datasets",
        "optimum",
        "pillow",
        "python >=3.7",
        "pytorch",
        "scipy",
        "sentencepiece",
        "tokenizers",
        "transformers >=4.20.0"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "url": "https://pypi.io/packages/source/o/optimum-habana/optimum-habana-1.1.2.tar.gz",
  "version": "1.1.2",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/optimum-habana.json"
  }
}