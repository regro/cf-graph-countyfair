{
  "archived": false,
  "branch": "main",
  "ci_support_linux_64_.yaml": "cdt_name:\n- conda\nchannel_sources:\n- conda-forge\nchannel_targets:\n- conda-forge main\ndocker_image:\n- quay.io/condaforge/linux-anvil-x86_64:alma9\npython_min:\n- '3.10'\n",
  "conda-forge.yml": {
    "conda_build": {
      "error_overlinking": true
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_hash": "b29354278d61b3c28a739febb079d8ea9ca5ee16",
  "feedstock_hash_ts": 1765234167,
  "feedstock_name": "omnipkg",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "description": "OmniPkg 2.0.0 represents a paradigm shift from package management to a Distributed\nRuntime Architecture. It functions as a local Hypervisor for Python, allowing\nconflicting AI frameworks and hardware drivers to run concurrently in the same\nworkflow with near-zero latency.\n\nThis release introduces three critical architectural advancements for ML/AI pipelines:\n\n1. Universal GPU Inter-Process Communication (IPC):\n   Implements a custom, framework-agnostic CUDA IPC protocol using raw ctypes.\n   This enables true zero-copy tensor handoffs between isolated processes (e.g.,\n   passing data from PyTorch to TensorFlow) with ~1.5ms latency, significantly\n   outperforming standard serialization methods.\n\n2. Selective Hardware Virtualization:\n   Features dynamic LD_LIBRARY_PATH injection at the worker level. This allows\n   different worker processes to utilize different CUDA Toolkit versions or\n   runtime libraries (e.g., running legacy models on CUDA 11 alongside modern\n   models on CUDA 12) simultaneously on the same host machine without conflict.\n\n3. Elastic Persistent Daemon Architecture:\n   Replaces ad-hoc process spawning with a self-healing, elastic worker pool.\n   Workers utilize a \"clean slate\" architecture, morphing into specific framework\n   environments on-demand and purging themselves after execution. This reduces\n   environment context switching latency from ~2000ms (cold start) to ~60ms (warm).\n\nOmniPkg 2.0 eliminates the need for complex container orchestration for local\nmulti-model inference, providing a unified, high-performance runtime for\ncomplex scientific and financial modeling workflows.\n",
      "dev_url": "https://github.com/1minds3t",
      "doc_url": "https://github.com/1minds3t/omnipkg/tree/main/docs",
      "home": "https://github.com/1minds3t/omnipkg",
      "license": "AGPL-3.0-only",
      "license_family": "AGPL",
      "license_file": "LICENSE",
      "summary": "A distributed runtime hypervisor for Python enabling concurrent, zero-copy multi-framework orchestration."
    },
    "build": {
      "entry_points": [
        "omnipkg = omnipkg.cli:main",
        "8pkg = omnipkg.cli:main"
      ],
      "noarch": "python",
      "number": "0",
      "script": "python -m pip install . --no-deps --no-build-isolation -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "1minds3t"
      ]
    },
    "package": {
      "name": "omnipkg",
      "version": "2.0.0"
    },
    "requirements": {
      "host": [
        "python >=3.7,<3.15",
        "pip",
        "setuptools >=61.0"
      ],
      "run": [
        "python >=3.7,<3.15",
        "packaging >=23.0",
        "requests >=2.20",
        "authlib >=1.6.5",
        "filelock >=3.9",
        "psutil >=5.9.0",
        "safety >=3.0",
        "aiohttp >=3.13.1",
        "uv >=0.9.5"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "3d8b7016d0c1a19b12065601a0dd56b3f7456625e009a86f6966ca844a864d06",
      "url": "https://pypi.org/packages/source/o/omnipkg/omnipkg-2.0.0.tar.gz"
    },
    "test": {
      "commands": [
        "omnipkg --version"
      ],
      "imports": [
        "omnipkg"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "aiohttp",
        "authlib",
        "filelock",
        "packaging",
        "psutil",
        "python",
        "requests",
        "safety",
        "uv"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "meta_yaml": {
    "about": {
      "description": "OmniPkg 2.0.0 represents a paradigm shift from package management to a Distributed\nRuntime Architecture. It functions as a local Hypervisor for Python, allowing\nconflicting AI frameworks and hardware drivers to run concurrently in the same\nworkflow with near-zero latency.\n\nThis release introduces three critical architectural advancements for ML/AI pipelines:\n\n1. Universal GPU Inter-Process Communication (IPC):\n   Implements a custom, framework-agnostic CUDA IPC protocol using raw ctypes.\n   This enables true zero-copy tensor handoffs between isolated processes (e.g.,\n   passing data from PyTorch to TensorFlow) with ~1.5ms latency, significantly\n   outperforming standard serialization methods.\n\n2. Selective Hardware Virtualization:\n   Features dynamic LD_LIBRARY_PATH injection at the worker level. This allows\n   different worker processes to utilize different CUDA Toolkit versions or\n   runtime libraries (e.g., running legacy models on CUDA 11 alongside modern\n   models on CUDA 12) simultaneously on the same host machine without conflict.\n\n3. Elastic Persistent Daemon Architecture:\n   Replaces ad-hoc process spawning with a self-healing, elastic worker pool.\n   Workers utilize a \"clean slate\" architecture, morphing into specific framework\n   environments on-demand and purging themselves after execution. This reduces\n   environment context switching latency from ~2000ms (cold start) to ~60ms (warm).\n\nOmniPkg 2.0 eliminates the need for complex container orchestration for local\nmulti-model inference, providing a unified, high-performance runtime for\ncomplex scientific and financial modeling workflows.\n",
      "dev_url": "https://github.com/1minds3t",
      "doc_url": "https://github.com/1minds3t/omnipkg/tree/main/docs",
      "home": "https://github.com/1minds3t/omnipkg",
      "license": "AGPL-3.0-only",
      "license_family": "AGPL",
      "license_file": "LICENSE",
      "summary": "A distributed runtime hypervisor for Python enabling concurrent, zero-copy multi-framework orchestration."
    },
    "build": {
      "entry_points": [
        "omnipkg = omnipkg.cli:main",
        "8pkg = omnipkg.cli:main"
      ],
      "noarch": "python",
      "number": "0",
      "script": "python -m pip install . --no-deps --no-build-isolation -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "1minds3t"
      ]
    },
    "package": {
      "name": "omnipkg",
      "version": "2.0.0"
    },
    "requirements": {
      "host": [
        "python >=3.7,<3.15",
        "pip",
        "setuptools >=61.0"
      ],
      "run": [
        "python >=3.7,<3.15",
        "packaging >=23.0",
        "requests >=2.20",
        "authlib >=1.6.5",
        "filelock >=3.9",
        "psutil >=5.9.0",
        "safety >=3.0",
        "aiohttp >=3.13.1",
        "uv >=0.9.5"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "3d8b7016d0c1a19b12065601a0dd56b3f7456625e009a86f6966ca844a864d06",
      "url": "https://pypi.org/packages/source/o/omnipkg/omnipkg-2.0.0.tar.gz"
    },
    "test": {
      "commands": [
        "omnipkg --version"
      ],
      "imports": [
        "omnipkg"
      ]
    }
  },
  "name": "omnipkg",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "omnipkg"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/omnipkg.json"
  },
  "raw_meta_yaml": "{% set name = \"omnipkg\" %}\n{% set version = \"2.0.0\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.org/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 3d8b7016d0c1a19b12065601a0dd56b3f7456625e009a86f6966ca844a864d06\n\nbuild:\n  number: 0\n  noarch: python\n  script: \"python -m pip install . --no-deps --no-build-isolation -vv\"\n  entry_points:\n    - omnipkg = omnipkg.cli:main\n    - 8pkg = omnipkg.cli:main\n\nrequirements:\n  host:\n    - python >=3.7,<3.15\n    - pip\n    - setuptools >=61.0\n  run:\n    - python >=3.7,<3.15\n    - packaging >=23.0  # [py>=310]\n    - packaging >=21.0,<22.0  # [py<310]\n    - requests >=2.20\n    - authlib >=1.6.5\n    - filelock >=3.9\n    - psutil >=5.9.0\n    - tomli  # [py<311]\n    - safety >=3.0  # [py>=310 and py<314]\n    - aiohttp >=3.13.1\n    - pip-audit >=2.6.0  # [py>=314]\n    - uv >=0.9.5\n\ntest:\n  imports:\n    - omnipkg\n  commands:\n    - omnipkg --version\n\nabout:\n  home: https://github.com/1minds3t/omnipkg\n  license: AGPL-3.0-only\n  license_family: AGPL\n  license_file: LICENSE\n  summary: 'A distributed runtime hypervisor for Python enabling concurrent, zero-copy multi-framework orchestration.'\n  description: |\n    OmniPkg 2.0.0 represents a paradigm shift from package management to a Distributed\n    Runtime Architecture. It functions as a local Hypervisor for Python, allowing\n    conflicting AI frameworks and hardware drivers to run concurrently in the same\n    workflow with near-zero latency.\n\n    This release introduces three critical architectural advancements for ML/AI pipelines:\n\n    1. Universal GPU Inter-Process Communication (IPC):\n       Implements a custom, framework-agnostic CUDA IPC protocol using raw ctypes.\n       This enables true zero-copy tensor handoffs between isolated processes (e.g.,\n       passing data from PyTorch to TensorFlow) with ~1.5ms latency, significantly\n       outperforming standard serialization methods.\n\n    2. Selective Hardware Virtualization:\n       Features dynamic LD_LIBRARY_PATH injection at the worker level. This allows\n       different worker processes to utilize different CUDA Toolkit versions or\n       runtime libraries (e.g., running legacy models on CUDA 11 alongside modern\n       models on CUDA 12) simultaneously on the same host machine without conflict.\n\n    3. Elastic Persistent Daemon Architecture:\n       Replaces ad-hoc process spawning with a self-healing, elastic worker pool.\n       Workers utilize a \"clean slate\" architecture, morphing into specific framework\n       environments on-demand and purging themselves after execution. This reduces\n       environment context switching latency from ~2000ms (cold start) to ~60ms (warm).\n\n    OmniPkg 2.0 eliminates the need for complex container orchestration for local\n    multi-model inference, providing a unified, high-performance runtime for\n    complex scientific and financial modeling workflows.\n\n  doc_url: https://github.com/1minds3t/omnipkg/tree/main/docs\n  dev_url: https://github.com/1minds3t\n\nextra:\n  recipe-maintainers:\n    - 1minds3t\n",
  "req": {
    "__set__": true,
    "elements": [
      "aiohttp",
      "authlib",
      "filelock",
      "packaging",
      "pip",
      "psutil",
      "python",
      "requests",
      "safety",
      "setuptools",
      "uv"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "aiohttp",
        "authlib",
        "filelock",
        "packaging",
        "psutil",
        "python",
        "requests",
        "safety",
        "uv"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python >=3.7,<3.15",
        "setuptools >=61.0"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "aiohttp >=3.13.1",
        "authlib >=1.6.5",
        "filelock >=3.9",
        "packaging >=23.0",
        "psutil >=5.9.0",
        "python >=3.7,<3.15",
        "requests >=2.20",
        "safety >=3.0",
        "uv >=0.9.5"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "url": "https://pypi.org/packages/source/o/omnipkg/omnipkg-2.0.0.tar.gz",
  "version": "2.0.0",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/omnipkg.json"
  }
}