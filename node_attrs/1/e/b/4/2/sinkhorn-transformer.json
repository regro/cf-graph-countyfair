{
  "archived": false,
  "branch": "main",
  "ci_support_linux_64_.yaml": "channel_sources:\n- conda-forge\nchannel_targets:\n- conda-forge main\ndocker_image:\n- quay.io/condaforge/linux-anvil-x86_64:alma9\npython_min:\n- '3.10'\n",
  "conda-forge.yml": {
    "bot": {
      "automerge": true
    },
    "conda_build": {
      "error_overlinking": true
    },
    "conda_build_tool": "rattler-build",
    "conda_forge_output_validation": true,
    "conda_install_tool": "pixi",
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_hash": "d82ce71a68f7a934a0b66c0375821bbecabc2924",
  "feedstock_hash_ts": 1765169368,
  "feedstock_name": "sinkhorn-transformer",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "home": "https://github.com/lucidrains/sinkhorn-transformer",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Sinkhorn Transformer - Practical implementation of Sparse Sinkhorn Attention"
    },
    "build": {
      "noarch": "python",
      "number": "1",
      "script": "${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "danielnachun"
      ]
    },
    "outputs": [
      {
        "build": null,
        "name": "sinkhorn-transformer",
        "requirements": {
          "build": [],
          "host": [
            "python 3.10.*",
            "pip",
            "setuptools"
          ],
          "run": [
            "python >=3.10",
            "axial-positional-embedding >=0.1.0",
            "local-attention",
            "product-key-memory",
            "pytorch"
          ]
        },
        "tests": [
          {
            "python": {
              "imports": [
                "sinkhorn_transformer"
              ]
            }
          },
          {
            "requirements": {
              "run": [
                "pip",
                "python =3.10"
              ]
            },
            "script": "pip check"
          }
        ],
        "version": "0.11.4"
      }
    ],
    "package": {
      "name": "sinkhorn-transformer",
      "version": "0.11.4"
    },
    "requirements": {
      "host": [
        "python 3.10.*",
        "pip",
        "setuptools"
      ],
      "run": [
        "python >=3.10",
        "axial-positional-embedding >=0.1.0",
        "local-attention",
        "product-key-memory",
        "pytorch"
      ]
    },
    "schema_version": 1,
    "source": {
      "sha256": "2342bd71d3ba85b9828b526a203774473ba8567eca241589250b2af10e0ec847",
      "url": "https://github.com/lucidrains/sinkhorn-transformer/archive/0.11.4.tar.gz"
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "axial-positional-embedding",
        "local-attention",
        "product-key-memory",
        "python",
        "pytorch"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "home": "https://github.com/lucidrains/sinkhorn-transformer",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "Sinkhorn Transformer - Practical implementation of Sparse Sinkhorn Attention"
    },
    "build": {
      "noarch": "python",
      "number": "1",
      "script": "${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "danielnachun"
      ]
    },
    "outputs": [
      {
        "build": null,
        "name": "sinkhorn-transformer",
        "requirements": {
          "build": [],
          "host": [
            "python 3.10.*",
            "pip",
            "setuptools"
          ],
          "run": [
            "python >=3.10",
            "axial-positional-embedding >=0.1.0",
            "local-attention",
            "product-key-memory",
            "pytorch"
          ]
        },
        "tests": [
          {
            "python": {
              "imports": [
                "sinkhorn_transformer"
              ]
            }
          },
          {
            "requirements": {
              "run": [
                "pip",
                "python =3.10"
              ]
            },
            "script": "pip check"
          }
        ],
        "version": "0.11.4"
      }
    ],
    "package": {
      "name": "sinkhorn-transformer",
      "version": "0.11.4"
    },
    "requirements": {
      "host": [
        "python 3.10.*",
        "pip",
        "setuptools"
      ],
      "run": [
        "python >=3.10",
        "axial-positional-embedding >=0.1.0",
        "local-attention",
        "product-key-memory",
        "pytorch"
      ]
    },
    "schema_version": 1,
    "source": {
      "sha256": "2342bd71d3ba85b9828b526a203774473ba8567eca241589250b2af10e0ec847",
      "url": "https://github.com/lucidrains/sinkhorn-transformer/archive/0.11.4.tar.gz"
    }
  },
  "name": "sinkhorn-transformer",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "sinkhorn-transformer"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/sinkhorn-transformer.json"
  },
  "raw_meta_yaml": "schema_version: 1\n\ncontext:\n  version: 0.11.4\n\npackage:\n  name: sinkhorn-transformer\n  version: ${{ version }}\n\nsource:\n  url: https://github.com/lucidrains/sinkhorn-transformer/archive/${{ version }}.tar.gz\n  sha256: 2342bd71d3ba85b9828b526a203774473ba8567eca241589250b2af10e0ec847\n\nbuild:\n  number: 1\n  noarch: python\n  script: ${{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation\n\nrequirements:\n  host:\n    - python =${{ python_min }}\n    - pip\n    - setuptools\n  run:\n    - python >=${{ python_min }}\n    - axial-positional-embedding >=0.1.0\n    - local-attention\n    - product-key-memory\n    - pytorch\n\ntests:\n  - python:\n      imports:\n        - sinkhorn_transformer\n  - requirements:\n      run:\n        - pip\n        - python =${{ python_min }}\n    script:\n      - pip check\n\nabout:\n  license: MIT\n  license_file: LICENSE\n  summary: Sinkhorn Transformer - Practical implementation of Sparse Sinkhorn Attention\n  homepage: https://github.com/lucidrains/sinkhorn-transformer\n\nextra:\n  recipe-maintainers:\n    - danielnachun\n",
  "req": {
    "__set__": true,
    "elements": [
      "axial-positional-embedding",
      "local-attention",
      "pip",
      "product-key-memory",
      "python",
      "pytorch",
      "setuptools"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "axial-positional-embedding",
        "local-attention",
        "product-key-memory",
        "python",
        "pytorch"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python 3.10.*",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "axial-positional-embedding >=0.1.0",
        "local-attention",
        "product-key-memory",
        "python >=3.10",
        "pytorch"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python =3.10"
      ]
    }
  },
  "url": "https://github.com/lucidrains/sinkhorn-transformer/archive/0.11.4.tar.gz",
  "version": "0.11.4",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/sinkhorn-transformer.json"
  }
}