{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "bot": {
      "automerge": true
    },
    "conda_build": {
      "pkg_format": "2"
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    },
    "provider": {
      "win": "azure"
    }
  },
  "feedstock_name": "r-dalex",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "home": "https://ModelOriented.github.io/DALEX/, https://github.com/ModelOriented/DALEX",
      "license": "GPL-2.0-or-later",
      "license_family": "GPL3",
      "license_file": [
        "/lib/R/share/licenses/GPL-3"
      ],
      "summary": "Unverified black box model is the path to the failure. Opaqueness leads to distrust. Distrust leads to ignoration. Ignoration leads to rejection. DALEX package xrays any model and helps to explore and explain its behaviour. Machine Learning (ML) models are widely used and have various applications in classification or regression. Models created with boosting, bagging, stacking or similar techniques are often used due to their high performance. But such black-box models usually lack of direct interpretability. DALEX package contains various methods that help to understand the link between input variables and model output. Implemented methods help to explore model on the level of a single instance as well as a level of the whole dataset. All model explainers are model agnostic and can be compared across different models. DALEX package is the cornerstone for 'DrWhy.AI' universe of packages for visual model exploration. Find more details in (Biecek 2018) <arXiv:1806.08915>."
    },
    "build": {
      "noarch": "generic",
      "number": "1",
      "rpaths": [
        "lib/R/lib/",
        "lib/"
      ]
    },
    "extra": {
      "recipe-maintainers": [
        "conda-forge/r",
        "philip-khor"
      ]
    },
    "package": {
      "name": "r-dalex",
      "version": "2.5.2"
    },
    "requirements": {
      "build": [],
      "host": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown >=1.3.1",
        "r-ingredients >=2.0",
        "r-kernelshap"
      ],
      "run": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown >=1.3.1",
        "r-ingredients >=2.0",
        "r-kernelshap"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "462db07bca165f1f0c4efd14a5d2f87a834a16d4600518dc319aac32432a5764",
      "url": [
        "https://cran.r-project.org/src/contrib/DALEX_2.5.2.tar.gz",
        "https://cran.r-project.org/src/contrib/Archive/DALEX/DALEX_2.5.2.tar.gz"
      ]
    },
    "test": {
      "commands": [
        "$R -e \"library('DALEX')\""
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown",
        "r-ingredients",
        "r-kernelshap"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown",
        "r-ingredients",
        "r-kernelshap"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "meta_yaml": {
    "about": {
      "home": "https://ModelOriented.github.io/DALEX/, https://github.com/ModelOriented/DALEX",
      "license": "GPL-2.0-or-later",
      "license_family": "GPL3",
      "license_file": [
        "/lib/R/share/licenses/GPL-3"
      ],
      "summary": "Unverified black box model is the path to the failure. Opaqueness leads to distrust. Distrust leads to ignoration. Ignoration leads to rejection. DALEX package xrays any model and helps to explore and explain its behaviour. Machine Learning (ML) models are widely used and have various applications in classification or regression. Models created with boosting, bagging, stacking or similar techniques are often used due to their high performance. But such black-box models usually lack of direct interpretability. DALEX package contains various methods that help to understand the link between input variables and model output. Implemented methods help to explore model on the level of a single instance as well as a level of the whole dataset. All model explainers are model agnostic and can be compared across different models. DALEX package is the cornerstone for 'DrWhy.AI' universe of packages for visual model exploration. Find more details in (Biecek 2018) <arXiv:1806.08915>."
    },
    "build": {
      "noarch": "generic",
      "number": "1",
      "rpaths": [
        "lib/R/lib/",
        "lib/"
      ]
    },
    "extra": {
      "recipe-maintainers": [
        "conda-forge/r",
        "philip-khor"
      ]
    },
    "package": {
      "name": "r-dalex",
      "version": "2.5.2"
    },
    "requirements": {
      "build": [],
      "host": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown >=1.3.1",
        "r-ingredients >=2.0",
        "r-kernelshap"
      ],
      "run": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown >=1.3.1",
        "r-ingredients >=2.0",
        "r-kernelshap"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "462db07bca165f1f0c4efd14a5d2f87a834a16d4600518dc319aac32432a5764",
      "url": [
        "https://cran.r-project.org/src/contrib/DALEX_2.5.2.tar.gz",
        "https://cran.r-project.org/src/contrib/Archive/DALEX/DALEX_2.5.2.tar.gz"
      ]
    },
    "test": {
      "commands": [
        "$R -e \"library('DALEX')\""
      ]
    }
  },
  "name": "r-dalex",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "r-dalex"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/r-dalex.json"
  },
  "raw_meta_yaml": "{% set version = \"2.5.2\" %}\n{% set posix = 'm2-' if win else '' %}\n\npackage:\n  name: r-dalex\n  version: {{ version|replace(\"-\", \"_\") }}\n\nsource:\n  url:\n    - {{ cran_mirror }}/src/contrib/DALEX_{{ version }}.tar.gz\n    - {{ cran_mirror }}/src/contrib/Archive/DALEX/DALEX_{{ version }}.tar.gz\n  sha256: 462db07bca165f1f0c4efd14a5d2f87a834a16d4600518dc319aac32432a5764\n\nbuild:\n  number: 1\n  noarch: generic\n  rpaths:\n    - lib/R/lib/\n    - lib/\n\nrequirements:\n  build:\n    - {{ posix }}zip               # [win]\n    - cross-r-base {{ r_base }}    # [build_platform != target_platform]\n  host:\n    - r-base\n    - r-ggplot2\n    - r-ibreakdown >=1.3.1\n    - r-ingredients >=2.0\n    - r-kernelshap\n  run:\n    - r-base\n    - r-ggplot2\n    - r-ibreakdown >=1.3.1\n    - r-ingredients >=2.0\n    - r-kernelshap\n\ntest:\n  commands:\n    - $R -e \"library('DALEX')\"           # [not win]\n    - \"\\\"%R%\\\" -e \\\"library('DALEX')\\\"\"  # [win]\n\nabout:\n  home: https://ModelOriented.github.io/DALEX/, https://github.com/ModelOriented/DALEX\n  license: GPL-2.0-or-later\n  summary: Unverified black box model is the path to the failure. Opaqueness leads to distrust. Distrust leads to ignoration. Ignoration leads to rejection. DALEX package xrays any model and helps to explore and explain its behaviour. Machine Learning (ML) models are widely used and have various applications in classification\n    or regression. Models created with boosting, bagging, stacking or similar techniques are often used due to their high performance. But such black-box models usually lack of direct interpretability. DALEX package contains various methods that help to understand the link between input variables and model output. Implemented\n    methods help to explore model on the level of a single instance as well as a level of the whole dataset. All model explainers are model agnostic and can be compared across different models. DALEX package is the cornerstone for 'DrWhy.AI' universe of packages for visual model exploration. Find more details in (Biecek\n    2018) <arXiv:1806.08915>.\n  license_family: GPL3\n  license_file:\n    - {{ environ[\"PREFIX\"] }}/lib/R/share/licenses/GPL-3\n\nextra:\n  recipe-maintainers:\n    - conda-forge/r\n    - philip-khor\n\n# Package: DALEX\n# Title: moDel Agnostic Language for Exploration and eXplanation\n# Version: 1.2.0\n# Authors@R: c(person(\"Przemyslaw\", \"Biecek\", email = \"przemyslaw.biecek@gmail.com\", role = c(\"aut\", \"cre\"), comment = c(ORCID = \"0000-0001-8423-1823\")), person(\"Szymon\", \"Maksymiuk\", role = \"aut\"), person(\"Hubert\", \"Baniecki\", role = \"aut\", comment = c(ORCID = \"0000-0001-6661-5364\")))\n# Description: Unverified black box model is the path to the failure. Opaqueness leads to distrust. Distrust leads to ignoration. Ignoration leads to rejection. DALEX package xrays any model and helps to explore and explain its behaviour. Machine Learning (ML) models are widely used and have various applications in classification or regression. Models created with boosting, bagging, stacking or similar techniques are often used due to their high performance. But such black-box models usually lack of direct interpretability. DALEX package contains various methods that help to understand the link between input variables and model output. Implemented methods help to explore model on the level of a single instance as well as a level of the whole dataset. All model explainers are model agnostic and can be compared across different models. DALEX package is the cornerstone for 'DrWhy.AI' universe of packages for visual model exploration. Find more details in (Biecek 2018) <arXiv:1806.08915>.\n# License: GPL\n# Encoding: UTF-8\n# LazyData: true\n# RoxygenNote: 7.1.0\n# Depends: R (>= 3.5)\n# Imports: ggplot2, iBreakDown, ingredients\n# Suggests: gower, ggpubr, ranger, testthat\n# URL: https://ModelOriented.github.io/DALEX/, https://github.com/ModelOriented/DALEX\n# BugReports: https://github.com/ModelOriented/DALEX/issues\n# NeedsCompilation: no\n# Packaged: 2020-04-22 19:45:26 UTC; pbiecek\n# Author: Przemyslaw Biecek [aut, cre] (<https://orcid.org/0000-0001-8423-1823>), Szymon Maksymiuk [aut], Hubert Baniecki [aut] (<https://orcid.org/0000-0001-6661-5364>)\n# Maintainer: Przemyslaw Biecek <przemyslaw.biecek@gmail.com>\n# Repository: CRAN\n# Date/Publication: 2020-04-22 20:34:10 UTC\n",
  "req": {
    "__set__": true,
    "elements": [
      "r-base",
      "r-ggplot2",
      "r-ibreakdown",
      "r-ingredients",
      "r-kernelshap"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown",
        "r-ingredients",
        "r-kernelshap"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown",
        "r-ingredients",
        "r-kernelshap"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown >=1.3.1",
        "r-ingredients >=2.0",
        "r-kernelshap"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-ggplot2",
        "r-ibreakdown >=1.3.1",
        "r-ingredients >=2.0",
        "r-kernelshap"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "url": [
    "https://cran.r-project.org/src/contrib/DALEX_2.5.2.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/DALEX/DALEX_2.5.2.tar.gz"
  ],
  "version": "2.5.2",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/r-dalex.json"
  }
}