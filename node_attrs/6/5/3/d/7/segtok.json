{
  "archived": false,
  "branch": "main",
  "ci_support_linux_64_.yaml": "cdt_name:\n- cos6\nchannel_sources:\n- conda-forge\nchannel_targets:\n- conda-forge main\ndocker_image:\n- quay.io/condaforge/linux-anvil-cos7-x86_64\n",
  "conda-forge.yml": {
    "bot": {
      "automerge": true
    },
    "conda_build": {
      "pkg_format": "2"
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_hash": "1f7f8e7b10db130ad35fc0fa027d29cfcb7f259d",
  "feedstock_hash_ts": 1730889024,
  "feedstock_name": "segtok",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "dev_url": "https://github.com/fnl/segtok",
      "doc_url": "http://fnl.es/segtok-a-segmentation-and-tokenization-library.html",
      "home": "https://github.com/fnl/segtok",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "sentence segmentation and word tokenization tools"
    },
    "build": {
      "entry_points": [
        "tokenizer = segtok.tokenizer:main",
        "segmenter = segtok.segmenter:main"
      ],
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "mxr-conda"
      ]
    },
    "package": {
      "name": "segtok",
      "version": "1.5.11"
    },
    "requirements": {
      "host": [
        "pip",
        "python >=3.6"
      ],
      "run": [
        "python >=3.6",
        "regex"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "8ab2dd44245bcbfec25b575dc4618473bbdf2af8c2649698cd5a370f42f3db23",
      "url": "https://pypi.io/packages/source/s/segtok/segtok-1.5.11.tar.gz"
    },
    "test": {
      "commands": [
        "tokenizer --help",
        "segmenter --help"
      ],
      "imports": [
        "segtok"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "meta_yaml": {
    "about": {
      "dev_url": "https://github.com/fnl/segtok",
      "doc_url": "http://fnl.es/segtok-a-segmentation-and-tokenization-library.html",
      "home": "https://github.com/fnl/segtok",
      "license": "MIT",
      "license_family": "MIT",
      "license_file": "LICENSE",
      "summary": "sentence segmentation and word tokenization tools"
    },
    "build": {
      "entry_points": [
        "tokenizer = segtok.tokenizer:main",
        "segmenter = segtok.segmenter:main"
      ],
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "mxr-conda"
      ]
    },
    "package": {
      "name": "segtok",
      "version": "1.5.11"
    },
    "requirements": {
      "host": [
        "pip",
        "python >=3.6"
      ],
      "run": [
        "python >=3.6",
        "regex"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "8ab2dd44245bcbfec25b575dc4618473bbdf2af8c2649698cd5a370f42f3db23",
      "url": "https://pypi.io/packages/source/s/segtok/segtok-1.5.11.tar.gz"
    },
    "test": {
      "commands": [
        "tokenizer --help",
        "segmenter --help"
      ],
      "imports": [
        "segtok"
      ]
    }
  },
  "name": "segtok",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "segtok"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/segtok.json"
  },
  "raw_meta_yaml": "{% set name = \"segtok\" %}\n{% set version = \"1.5.11\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/{{ name }}-{{ version }}.tar.gz\n  sha256: 8ab2dd44245bcbfec25b575dc4618473bbdf2af8c2649698cd5a370f42f3db23\n\nbuild:\n  noarch: python\n  number: 0\n  entry_points:\n    - tokenizer = segtok.tokenizer:main\n    - segmenter = segtok.segmenter:main\n  script: {{ PYTHON }} -m pip install . -vv\n\nrequirements:\n  host:\n    - pip\n    - python >=3.6\n  run:\n    - python >=3.6\n    - regex\n\ntest:\n  imports:\n    - segtok\n  commands:\n    - tokenizer --help\n    - segmenter --help\n\nabout:\n  home: https://github.com/fnl/segtok\n  license: MIT\n  license_family: MIT\n  # License isn't packaged, track issue here: https://github.com/fnl/segtok/issues/22\n  license_file: LICENSE\n  summary: sentence segmentation and word tokenization tools\n  doc_url: http://fnl.es/segtok-a-segmentation-and-tokenization-library.html\n  dev_url: https://github.com/fnl/segtok\n\nextra:\n  recipe-maintainers:\n    - mxr-conda\n",
  "req": {
    "__set__": true,
    "elements": [
      "pip",
      "python",
      "regex"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python >=3.6"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "python >=3.6",
        "regex"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "url": "https://pypi.io/packages/source/s/segtok/segtok-1.5.11.tar.gz",
  "version": "1.5.11",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/segtok.json"
  }
}