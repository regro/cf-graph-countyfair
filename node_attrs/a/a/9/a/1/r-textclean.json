{
  "archived": false,
  "branch": "main",
  "ci_support_linux_64_r_base4.4.yaml": "cdt_name:\n- conda\nchannel_sources:\n- conda-forge\nchannel_targets:\n- conda-forge main\ncran_mirror:\n- https://cran.r-project.org\ndocker_image:\n- quay.io/condaforge/linux-anvil-x86_64:alma9\npin_run_as_build:\n  r-base:\n    min_pin: x.x\n    max_pin: x.x\nr_base:\n- '4.4'\ntarget_platform:\n- linux-64\n",
  "conda-forge.yml": {
    "bot": {
      "automerge": true
    },
    "conda_build": {
      "pkg_format": "2"
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    },
    "provider": {
      "win": "azure"
    }
  },
  "feedstock_hash": "0605f838953dd1d1f3761ede40878695222ff089",
  "feedstock_hash_ts": 1757892447,
  "feedstock_name": "r-textclean",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "home": "https://github.com/trinker/textclean",
      "license": "GPL-2",
      "license_family": "GPL2",
      "license_file": "/lib/R/share/licenses/GPL-2",
      "summary": "Tools to clean and process text.  Tools are geared at checking for substrings that are not optimal for analysis and replacing or removing them (normalizing) with more analysis friendly substrings (see Sproat, Black, Chen, Kumar, Ostendorf, & Richards (2001) <doi:10.1006/csla.2001.0169>) or extracting them into new variables. For example, emoticons are often used in text but not always easily handled by analysis algorithms.  The replace_emoticon() function replaces emoticons with word equivalents."
    },
    "build": {
      "noarch": "generic",
      "number": "1006",
      "rpaths": [
        "lib/R/lib/",
        "lib/"
      ]
    },
    "extra": {
      "recipe-maintainers": [
        "conda-forge/r",
        "CurtLH"
      ]
    },
    "package": {
      "name": "r-textclean",
      "version": "0.9.3"
    },
    "requirements": {
      "build": [],
      "host": [
        "r-base",
        "r-data.table",
        "r-english >=1.0_2",
        "r-glue >=1.3.0",
        "r-lexicon >=1.0.0",
        "r-mgsub >=1.5.0",
        "r-qdapregex",
        "r-stringi",
        "r-textshape >=1.0.1"
      ],
      "run": [
        "r-base",
        "r-data.table",
        "r-english >=1.0_2",
        "r-glue >=1.3.0",
        "r-lexicon >=1.0.0",
        "r-mgsub >=1.5.0",
        "r-qdapregex",
        "r-stringi",
        "r-textshape >=1.0.1"
      ]
    },
    "schema_version": 0,
    "source": {
      "fn": "textclean_0.9.3.tar.gz",
      "sha256": "3f6f3b0abaa3567a1d29f5457087aad31277f3c1473747989c9804479881f24d",
      "url": [
        "https://cran.r-project.org/src/contrib/textclean_0.9.3.tar.gz",
        "https://cran.r-project.org/src/contrib/Archive/textclean/textclean_0.9.3.tar.gz"
      ]
    },
    "test": {
      "commands": [
        "$R -e \"library('textclean')\""
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-data.table",
        "r-english",
        "r-glue",
        "r-lexicon",
        "r-mgsub",
        "r-qdapregex",
        "r-stringi",
        "r-textshape"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-data.table",
        "r-english",
        "r-glue",
        "r-lexicon",
        "r-mgsub",
        "r-qdapregex",
        "r-stringi",
        "r-textshape"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "meta_yaml": {
    "about": {
      "home": "https://github.com/trinker/textclean",
      "license": "GPL-2",
      "license_family": "GPL2",
      "license_file": "/lib/R/share/licenses/GPL-2",
      "summary": "Tools to clean and process text.  Tools are geared at checking for substrings that are not optimal for analysis and replacing or removing them (normalizing) with more analysis friendly substrings (see Sproat, Black, Chen, Kumar, Ostendorf, & Richards (2001) <doi:10.1006/csla.2001.0169>) or extracting them into new variables. For example, emoticons are often used in text but not always easily handled by analysis algorithms.  The replace_emoticon() function replaces emoticons with word equivalents."
    },
    "build": {
      "noarch": "generic",
      "number": "1006",
      "rpaths": [
        "lib/R/lib/",
        "lib/"
      ]
    },
    "extra": {
      "recipe-maintainers": [
        "conda-forge/r",
        "CurtLH"
      ]
    },
    "package": {
      "name": "r-textclean",
      "version": "0.9.3"
    },
    "requirements": {
      "build": [],
      "host": [
        "r-base",
        "r-data.table",
        "r-english >=1.0_2",
        "r-glue >=1.3.0",
        "r-lexicon >=1.0.0",
        "r-mgsub >=1.5.0",
        "r-qdapregex",
        "r-stringi",
        "r-textshape >=1.0.1"
      ],
      "run": [
        "r-base",
        "r-data.table",
        "r-english >=1.0_2",
        "r-glue >=1.3.0",
        "r-lexicon >=1.0.0",
        "r-mgsub >=1.5.0",
        "r-qdapregex",
        "r-stringi",
        "r-textshape >=1.0.1"
      ]
    },
    "schema_version": 0,
    "source": {
      "fn": "textclean_0.9.3.tar.gz",
      "sha256": "3f6f3b0abaa3567a1d29f5457087aad31277f3c1473747989c9804479881f24d",
      "url": [
        "https://cran.r-project.org/src/contrib/textclean_0.9.3.tar.gz",
        "https://cran.r-project.org/src/contrib/Archive/textclean/textclean_0.9.3.tar.gz"
      ]
    },
    "test": {
      "commands": [
        "$R -e \"library('textclean')\""
      ]
    }
  },
  "name": "r-textclean",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "r-textclean"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/r-textclean.json"
  },
  "raw_meta_yaml": "{% set version = '0.9.3' %}\n{% set posix = 'm2-' if win else '' %}\n\npackage:\n  name: r-textclean\n  version: {{ version|replace(\"-\", \"_\") }}\n\nsource:\n  fn: textclean_{{ version }}.tar.gz\n  url:\n    - {{ cran_mirror }}/src/contrib/textclean_{{ version }}.tar.gz\n    - {{ cran_mirror }}/src/contrib/Archive/textclean/textclean_{{ version }}.tar.gz\n  sha256: 3f6f3b0abaa3567a1d29f5457087aad31277f3c1473747989c9804479881f24d\n\nbuild:\n  noarch: generic\n  number: 1006\n  rpaths:\n    - lib/R/lib/\n    - lib/\n\nrequirements:\n  build:\n    - {{ posix }}zip               # [win]\n  host:\n    - r-base\n    - r-data.table\n    - r-english >=1.0_2\n    - r-glue >=1.3.0\n    - r-lexicon >=1.0.0\n    - r-mgsub >=1.5.0\n    - r-qdapregex\n    - r-stringi\n    - r-textshape >=1.0.1\n  run:\n    - r-base\n    - r-data.table\n    - r-english >=1.0_2\n    - r-glue >=1.3.0\n    - r-lexicon >=1.0.0\n    - r-mgsub >=1.5.0\n    - r-qdapregex\n    - r-stringi\n    - r-textshape >=1.0.1\n\ntest:\n  commands:\n    - $R -e \"library('textclean')\"           # [not win]\n    - \"\\\"%R%\\\" -e \\\"library('textclean')\\\"\"  # [win]\n\nabout:\n  home: https://github.com/trinker/textclean\n  license: GPL-2\n  summary: Tools to clean and process text.  Tools are geared at checking for substrings that\n    are not optimal for analysis and replacing or removing them (normalizing) with more\n    analysis friendly substrings (see Sproat, Black, Chen, Kumar, Ostendorf, & Richards\n    (2001) <doi:10.1006/csla.2001.0169>) or extracting them into new variables. For\n    example, emoticons are often used in text but not always easily handled by analysis\n    algorithms.  The replace_emoticon() function replaces emoticons with word equivalents.\n  license_family: GPL2\n  license_file: '{{ environ[\"PREFIX\"] }}/lib/R/share/licenses/GPL-2'\n\nextra:\n  recipe-maintainers:\n    - conda-forge/r\n    - CurtLH\n",
  "req": {
    "__set__": true,
    "elements": [
      "r-base",
      "r-data.table",
      "r-english",
      "r-glue",
      "r-lexicon",
      "r-mgsub",
      "r-qdapregex",
      "r-stringi",
      "r-textshape"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-data.table",
        "r-english",
        "r-glue",
        "r-lexicon",
        "r-mgsub",
        "r-qdapregex",
        "r-stringi",
        "r-textshape"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-data.table",
        "r-english",
        "r-glue",
        "r-lexicon",
        "r-mgsub",
        "r-qdapregex",
        "r-stringi",
        "r-textshape"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-data.table",
        "r-english >=1.0_2",
        "r-glue >=1.3.0",
        "r-lexicon >=1.0.0",
        "r-mgsub >=1.5.0",
        "r-qdapregex",
        "r-stringi",
        "r-textshape >=1.0.1"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "r-base",
        "r-data.table",
        "r-english >=1.0_2",
        "r-glue >=1.3.0",
        "r-lexicon >=1.0.0",
        "r-mgsub >=1.5.0",
        "r-qdapregex",
        "r-stringi",
        "r-textshape >=1.0.1"
      ]
    },
    "test": {
      "__set__": true,
      "elements": []
    }
  },
  "url": [
    "https://cran.r-project.org/src/contrib/textclean_0.9.3.tar.gz",
    "https://cran.r-project.org/src/contrib/Archive/textclean/textclean_0.9.3.tar.gz"
  ],
  "version": "0.9.3",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/r-textclean.json"
  }
}