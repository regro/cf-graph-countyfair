{
  "archived": false,
  "branch": "main",
  "ci_support_linux_64_.yaml": "channel_sources:\n- conda-forge\nchannel_targets:\n- conda-forge main\ndocker_image:\n- quay.io/condaforge/linux-anvil-x86_64:alma9\npython_min:\n- '3.10'\n",
  "conda-forge.yml": {
    "conda_build": {
      "error_overlinking": true
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_hash": "2e415248113a41cb7940e95a41042f688da06a3a",
  "feedstock_hash_ts": 1760475282,
  "feedstock_name": "llmcompressor",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "home": "https://github.com/vllm-project/llm-compressor",
      "license": "Apache-2.0",
      "license_file": [
        "LICENSE",
        "NOTICE"
      ],
      "summary": "A library for compressing large language models utilizing the latest techniques and research in the field for both training aware and post training techniques. The library is designed to be flexible and easy to use on top of PyTorch and HuggingFace Transformers, allowing for quick experimentation."
    },
    "build": {
      "entry_points": [
        "llmcompressor.trace=llmcompressor.transformers.tracing.debug:main"
      ],
      "noarch": "python",
      "number": "0",
      "script": [
        "export SETUPTOOLS_SCM_PRETEND_VERSION=\"$PKG_VERSION\"",
        "export BUILD_TYPE=release",
        "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
      ]
    },
    "extra": {
      "recipe-maintainers": [
        "timkpaine"
      ]
    },
    "package": {
      "name": "llmcompressor",
      "version": "0.8.1"
    },
    "requirements": {
      "host": [
        "python 3.10.*",
        "setuptools",
        "wheel",
        "setuptools-scm >8",
        "pip"
      ],
      "run": [
        "python >=3.10",
        "loguru >=0.7.2,<=0.7.3",
        "pyyaml >=6.0.1,<=6.0.3",
        "numpy >=2.0.0,<=2.3.3",
        "requests >=2.32.2,<=2.32.5",
        "tqdm >=4.66.3,<=4.67.1",
        "pytorch >=2.7.0,<=2.8.0",
        "transformers >=4.53.0,<=4.56.2",
        "datasets >=4.0.0,<=4.1.1",
        "accelerate >=1.6.0,<=1.10.1",
        "nvidia-ml-py >=12.560.30,<=13.580.82",
        "pillow >=10.4.0,<=11.3.0",
        "compressed-tensors ==0.12.2"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "54a29c3235ee6280348170a3b63997881186908fe08a0066928702791a916687",
      "url": "https://pypi.org/packages/source/l/llmcompressor/llmcompressor-0.8.1.tar.gz"
    },
    "test": {
      "commands": [
        "pip check",
        "llmcompressor.trace --help"
      ],
      "imports": [
        "llmcompressor"
      ],
      "requires": [
        "pip",
        "python 3.10.*"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools",
        "setuptools-scm",
        "wheel"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "accelerate",
        "compressed-tensors",
        "datasets",
        "loguru",
        "numpy",
        "nvidia-ml-py",
        "pillow",
        "python",
        "pytorch",
        "pyyaml",
        "requests",
        "tqdm",
        "transformers"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "home": "https://github.com/vllm-project/llm-compressor",
      "license": "Apache-2.0",
      "license_file": [
        "LICENSE",
        "NOTICE"
      ],
      "summary": "A library for compressing large language models utilizing the latest techniques and research in the field for both training aware and post training techniques. The library is designed to be flexible and easy to use on top of PyTorch and HuggingFace Transformers, allowing for quick experimentation."
    },
    "build": {
      "entry_points": [
        "llmcompressor.trace=llmcompressor.transformers.tracing.debug:main"
      ],
      "noarch": "python",
      "number": "0",
      "script": [
        "export SETUPTOOLS_SCM_PRETEND_VERSION=\"$PKG_VERSION\"",
        "export BUILD_TYPE=release",
        "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
      ]
    },
    "extra": {
      "recipe-maintainers": [
        "timkpaine"
      ]
    },
    "package": {
      "name": "llmcompressor",
      "version": "0.8.1"
    },
    "requirements": {
      "host": [
        "python 3.10.*",
        "setuptools",
        "wheel",
        "setuptools-scm >8",
        "pip"
      ],
      "run": [
        "python >=3.10",
        "loguru >=0.7.2,<=0.7.3",
        "pyyaml >=6.0.1,<=6.0.3",
        "numpy >=2.0.0,<=2.3.3",
        "requests >=2.32.2,<=2.32.5",
        "tqdm >=4.66.3,<=4.67.1",
        "pytorch >=2.7.0,<=2.8.0",
        "transformers >=4.53.0,<=4.56.2",
        "datasets >=4.0.0,<=4.1.1",
        "accelerate >=1.6.0,<=1.10.1",
        "nvidia-ml-py >=12.560.30,<=13.580.82",
        "pillow >=10.4.0,<=11.3.0",
        "compressed-tensors ==0.12.2"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "54a29c3235ee6280348170a3b63997881186908fe08a0066928702791a916687",
      "url": "https://pypi.org/packages/source/l/llmcompressor/llmcompressor-0.8.1.tar.gz"
    },
    "test": {
      "commands": [
        "pip check",
        "llmcompressor.trace --help"
      ],
      "imports": [
        "llmcompressor"
      ],
      "requires": [
        "pip",
        "python 3.10.*"
      ]
    }
  },
  "name": "llmcompressor",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "llmcompressor"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/llmcompressor.json"
  },
  "raw_meta_yaml": "{% set name = \"llmcompressor\" %}\n{% set version = \"0.8.1\" %}\n\npackage:\n  name: llmcompressor\n  version: {{ version }}\n\nsource:\n  url: https://pypi.org/packages/source/l/llmcompressor/llmcompressor-{{ version }}.tar.gz\n  sha256: 54a29c3235ee6280348170a3b63997881186908fe08a0066928702791a916687\n\nbuild:\n  entry_points:\n    - llmcompressor.trace=llmcompressor.transformers.tracing.debug:main\n  noarch: python\n  script:\n    - export SETUPTOOLS_SCM_PRETEND_VERSION=\"$PKG_VERSION\"   # [unix]\n    - set \"SETUPTOOLS_SCM_PRETEND_VERSION=%PKG_VERSION%\"     # [win]\n    - export BUILD_TYPE=release  # [unix]\n    - set \"BUILD_TYPE=release\"  # [win]\n    - {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation\n  number: 0\n\nrequirements:\n  host:\n    - python {{ python_min }}.*\n    - setuptools\n    - wheel\n    - setuptools-scm >8\n    - pip\n  run:\n    - python >={{ python_min }}\n    - loguru >=0.7.2,<=0.7.3\n    - pyyaml >=6.0.1,<=6.0.3\n    - numpy >=2.0.0,<=2.3.3\n    - requests >=2.32.2,<=2.32.5\n    - tqdm >=4.66.3,<=4.67.1\n    - pytorch >=2.7.0,<=2.8.0\n    - transformers >=4.53.0,<=4.56.2\n    - datasets >=4.0.0,<=4.1.1\n    - accelerate >=1.6.0,<=1.10.1\n    - nvidia-ml-py >=12.560.30,<=13.580.82\n    - pillow >=10.4.0,<=11.3.0\n    - compressed-tensors ==0.12.2\n\ntest:\n  imports:\n    - llmcompressor\n  commands:\n    - pip check\n    - llmcompressor.trace --help\n  requires:\n    - pip\n    - python {{ python_min }}.*\n\nabout:\n  home: https://github.com/vllm-project/llm-compressor\n  summary: A library for compressing large language models utilizing the latest techniques and research in the field for both training aware and post training techniques. The library is designed to be flexible and easy to use on top of PyTorch and HuggingFace Transformers, allowing for quick experimentation.\n  license: Apache-2.0\n  license_file:\n    - LICENSE\n    - NOTICE\n\nextra:\n  recipe-maintainers:\n    - timkpaine\n",
  "req": {
    "__set__": true,
    "elements": [
      "accelerate",
      "compressed-tensors",
      "datasets",
      "loguru",
      "numpy",
      "nvidia-ml-py",
      "pillow",
      "pip",
      "python",
      "pytorch",
      "pyyaml",
      "requests",
      "setuptools",
      "setuptools-scm",
      "tqdm",
      "transformers",
      "wheel"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools",
        "setuptools-scm",
        "wheel"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "accelerate",
        "compressed-tensors",
        "datasets",
        "loguru",
        "numpy",
        "nvidia-ml-py",
        "pillow",
        "python",
        "pytorch",
        "pyyaml",
        "requests",
        "tqdm",
        "transformers"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python 3.10.*",
        "setuptools",
        "setuptools-scm >8",
        "wheel"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "accelerate >=1.6.0,<=1.10.1",
        "compressed-tensors ==0.12.2",
        "datasets >=4.0.0,<=4.1.1",
        "loguru >=0.7.2,<=0.7.3",
        "numpy >=2.0.0,<=2.3.3",
        "nvidia-ml-py >=12.560.30,<=13.580.82",
        "pillow >=10.4.0,<=11.3.0",
        "python >=3.10",
        "pytorch >=2.7.0,<=2.8.0",
        "pyyaml >=6.0.1,<=6.0.3",
        "requests >=2.32.2,<=2.32.5",
        "tqdm >=4.66.3,<=4.67.1",
        "transformers >=4.53.0,<=4.56.2"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python 3.10.*"
      ]
    }
  },
  "url": "https://pypi.org/packages/source/l/llmcompressor/llmcompressor-0.8.1.tar.gz",
  "version": "0.8.1",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/llmcompressor.json"
  }
}