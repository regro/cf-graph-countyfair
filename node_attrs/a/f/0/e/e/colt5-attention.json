{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "bot": {
      "automerge": true
    },
    "conda_build": {
      "error_overlinking": true
    },
    "conda_forge_output_validation": true,
    "conda_install_tool": "pixi",
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_name": "colt5-attention",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "home": "https://github.com/lucidrains/CoLT5-attention",
      "license": "MIT",
      "license_file": "LICENSE",
      "summary": "Implementation of the conditionally routed attention in the CoLT5 architecture, in Pytorch"
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "danielnachun"
      ]
    },
    "package": {
      "name": "colt5-attention",
      "version": "0.11.1"
    },
    "requirements": {
      "host": [
        "python =3.9",
        "pip",
        "setuptools"
      ],
      "run": [
        "python >=3.9",
        "einops >=0.8.0",
        "local-attention >=1.8.6",
        "packaging",
        "pytorch >=1.10"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "597f1e4af5b9006d8969d73905ea03fcc55945cfb0ab7d3d722fd05fff6322f6",
      "url": "https://github.com/lucidrains/colt5-attention/archive/0.11.1.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "colt5_attention"
      ],
      "requires": [
        "pip",
        "python =3.9"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "einops",
        "local-attention",
        "packaging",
        "python",
        "pytorch"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "home": "https://github.com/lucidrains/CoLT5-attention",
      "license": "MIT",
      "license_file": "LICENSE",
      "summary": "Implementation of the conditionally routed attention in the CoLT5 architecture, in Pytorch"
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "danielnachun"
      ]
    },
    "package": {
      "name": "colt5-attention",
      "version": "0.11.1"
    },
    "requirements": {
      "host": [
        "python =3.9",
        "pip",
        "setuptools"
      ],
      "run": [
        "python >=3.9",
        "einops >=0.8.0",
        "local-attention >=1.8.6",
        "packaging",
        "pytorch >=1.10"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "597f1e4af5b9006d8969d73905ea03fcc55945cfb0ab7d3d722fd05fff6322f6",
      "url": "https://github.com/lucidrains/colt5-attention/archive/0.11.1.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "colt5_attention"
      ],
      "requires": [
        "pip",
        "python =3.9"
      ]
    }
  },
  "name": "colt5-attention",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "colt5-attention"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/colt5-attention.json"
  },
  "raw_meta_yaml": "{% set version = \"0.11.1\" %}\n\npackage:\n  name: colt5-attention\n  version: {{ version }}\n\nsource:\n  url: https://github.com/lucidrains/colt5-attention/archive/{{ version }}.tar.gz\n  sha256: 597f1e4af5b9006d8969d73905ea03fcc55945cfb0ab7d3d722fd05fff6322f6\n\nbuild:\n  number: 0\n  noarch: python\n  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation\n\nrequirements:\n  host:\n    - python ={{ python_min }}\n    - pip\n    - setuptools\n  run:\n    - python >={{ python_min }}\n    - einops >=0.8.0\n    - local-attention >=1.8.6\n    - packaging\n    - pytorch >=1.10\n\ntest:\n  commands:\n    - pip check\n  imports:\n    - colt5_attention\n  requires:\n    - pip\n    - python ={{ python_min }}\n\nabout:\n  home: https://github.com/lucidrains/CoLT5-attention\n  license: MIT\n  license_file: LICENSE\n  summary: Implementation of the conditionally routed attention in the CoLT5 architecture, in Pytorch\n\nextra:\n  recipe-maintainers:\n    - danielnachun\n",
  "req": {
    "__set__": true,
    "elements": [
      "einops",
      "local-attention",
      "packaging",
      "pip",
      "python",
      "pytorch",
      "setuptools"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "einops",
        "local-attention",
        "packaging",
        "python",
        "pytorch"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python =3.9",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "einops >=0.8.0",
        "local-attention >=1.8.6",
        "packaging",
        "python >=3.9",
        "pytorch >=1.10"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python =3.9"
      ]
    }
  },
  "url": "https://github.com/lucidrains/colt5-attention/archive/0.11.1.tar.gz",
  "version": "0.11.1",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/colt5-attention.json"
  }
}