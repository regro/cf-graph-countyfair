{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "bot": {
      "inspection": "hint-all"
    },
    "conda_build": {
      "pkg_format": "2"
    },
    "conda_build_tool": "rattler-build",
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_name": "datasets",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "description": "Datasets is a lightweight library providing one-line dataloaders for many\npublic datasets and one liners to download and pre-process any of the number\nof datasets major public datasets provided on the HuggingFace Datasets Hub.\nDatasets are ready to use in a dataloader for training/evaluating a ML model\n(Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for\nsimple, fast, and reproducible data pre-processing for the above public\ndatasets as well as your own local datasets in CSV/JSON/text.",
      "dev_url": "https://github.com/huggingface/datasets",
      "doc_url": "https://huggingface.co/docs/datasets/",
      "home": "https://github.com/huggingface/datasets",
      "license": "Apache-2.0",
      "license_family": "Apache-2.0",
      "license_file": "LICENSE",
      "summary": "HuggingFace/Datasets is an open library of NLP datasets."
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "${{ PYTHON }} -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "oblute",
        "Tata17",
        "thewchan",
        "mxr-conda"
      ]
    },
    "outputs": [
      {
        "build": null,
        "name": "datasets",
        "requirements": {
          "build": [],
          "host": [
            "pip",
            "python 3.10.*",
            "setuptools"
          ],
          "run": [
            "python >=3.10",
            "filelock",
            "numpy >=1.17",
            "pyarrow >=15.0.0",
            "dill >=0.3.0,<0.3.9",
            "pandas",
            "requests >=2.32.2",
            "tqdm >=4.66.3",
            "python-xxhash",
            "multiprocess <0.70.17",
            "fsspec >=2023.1.0,<=2025.3.0",
            "huggingface_hub >=0.24.0",
            "packaging",
            "pyyaml >=5.1",
            "aiohttp"
          ]
        },
        "tests": [
          {
            "python": {
              "imports": [
                "datasets"
              ],
              "python_version": "3.10.*"
            }
          },
          {
            "requirements": {
              "run": [
                "python 3.10.*"
              ]
            },
            "script": "datasets-cli --help"
          }
        ],
        "version": "4.0.0"
      }
    ],
    "package": {
      "name": "datasets",
      "version": "4.0.0"
    },
    "requirements": {
      "host": [
        "pip",
        "python 3.10.*",
        "setuptools"
      ],
      "run": [
        "python >=3.10",
        "filelock",
        "numpy >=1.17",
        "pyarrow >=15.0.0",
        "dill >=0.3.0,<0.3.9",
        "pandas",
        "requests >=2.32.2",
        "tqdm >=4.66.3",
        "python-xxhash",
        "multiprocess <0.70.17",
        "fsspec >=2023.1.0,<=2025.3.0",
        "huggingface_hub >=0.24.0",
        "packaging",
        "pyyaml >=5.1",
        "aiohttp"
      ]
    },
    "schema_version": 1,
    "source": {
      "sha256": "9657e7140a9050db13443ba21cb5de185af8af944479b00e7ff1e00a61c8dbf1",
      "url": "https://pypi.org/packages/source/d/datasets/datasets-4.0.0.tar.gz"
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "aiohttp",
        "dill",
        "filelock",
        "fsspec",
        "huggingface_hub",
        "multiprocess",
        "numpy",
        "packaging",
        "pandas",
        "pyarrow",
        "python",
        "python-xxhash",
        "pyyaml",
        "requests",
        "tqdm"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "description": "Datasets is a lightweight library providing one-line dataloaders for many\npublic datasets and one liners to download and pre-process any of the number\nof datasets major public datasets provided on the HuggingFace Datasets Hub.\nDatasets are ready to use in a dataloader for training/evaluating a ML model\n(Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for\nsimple, fast, and reproducible data pre-processing for the above public\ndatasets as well as your own local datasets in CSV/JSON/text.",
      "dev_url": "https://github.com/huggingface/datasets",
      "doc_url": "https://huggingface.co/docs/datasets/",
      "home": "https://github.com/huggingface/datasets",
      "license": "Apache-2.0",
      "license_family": "Apache-2.0",
      "license_file": "LICENSE",
      "summary": "HuggingFace/Datasets is an open library of NLP datasets."
    },
    "build": {
      "noarch": "python",
      "number": "0",
      "script": "${{ PYTHON }} -m pip install . -vv"
    },
    "extra": {
      "recipe-maintainers": [
        "oblute",
        "Tata17",
        "thewchan",
        "mxr-conda"
      ]
    },
    "outputs": [
      {
        "build": null,
        "name": "datasets",
        "requirements": {
          "build": [],
          "host": [
            "pip",
            "python 3.10.*",
            "setuptools"
          ],
          "run": [
            "python >=3.10",
            "filelock",
            "numpy >=1.17",
            "pyarrow >=15.0.0",
            "dill >=0.3.0,<0.3.9",
            "pandas",
            "requests >=2.32.2",
            "tqdm >=4.66.3",
            "python-xxhash",
            "multiprocess <0.70.17",
            "fsspec >=2023.1.0,<=2025.3.0",
            "huggingface_hub >=0.24.0",
            "packaging",
            "pyyaml >=5.1",
            "aiohttp"
          ]
        },
        "tests": [
          {
            "python": {
              "imports": [
                "datasets"
              ],
              "python_version": "3.10.*"
            }
          },
          {
            "requirements": {
              "run": [
                "python 3.10.*"
              ]
            },
            "script": "datasets-cli --help"
          }
        ],
        "version": "4.0.0"
      }
    ],
    "package": {
      "name": "datasets",
      "version": "4.0.0"
    },
    "requirements": {
      "host": [
        "pip",
        "python 3.10.*",
        "setuptools"
      ],
      "run": [
        "python >=3.10",
        "filelock",
        "numpy >=1.17",
        "pyarrow >=15.0.0",
        "dill >=0.3.0,<0.3.9",
        "pandas",
        "requests >=2.32.2",
        "tqdm >=4.66.3",
        "python-xxhash",
        "multiprocess <0.70.17",
        "fsspec >=2023.1.0,<=2025.3.0",
        "huggingface_hub >=0.24.0",
        "packaging",
        "pyyaml >=5.1",
        "aiohttp"
      ]
    },
    "schema_version": 1,
    "source": {
      "sha256": "9657e7140a9050db13443ba21cb5de185af8af944479b00e7ff1e00a61c8dbf1",
      "url": "https://pypi.org/packages/source/d/datasets/datasets-4.0.0.tar.gz"
    }
  },
  "name": "datasets",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "datasets"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/datasets.json"
  },
  "raw_meta_yaml": "schema_version: 1\n\ncontext:\n  name: datasets\n  version: 4.0.0\n\npackage:\n  name: ${{ name|lower }}\n  version: ${{ version }}\n\nsource:\n  url: https://pypi.org/packages/source/${{ name[0] }}/${{ name }}/${{ name }}-${{ version }}.tar.gz\n  sha256: 9657e7140a9050db13443ba21cb5de185af8af944479b00e7ff1e00a61c8dbf1\n\nbuild:\n  number: 0\n  noarch: python\n  script: ${{ PYTHON }} -m pip install . -vv\n  python:\n    entry_points:\n      - datasets-cli=datasets.commands.datasets_cli:main\n\nrequirements:\n  host:\n    - pip\n    - python ${{ python_min }}.*\n    - setuptools\n  run:\n    - python >=${{ python_min }}\n    - filelock\n    - numpy >=1.17\n    - pyarrow >=15.0.0\n    - dill >=0.3.0,<0.3.9\n    - pandas\n    - requests >=2.32.2\n    - tqdm >=4.66.3\n    - python-xxhash\n    - multiprocess <0.70.17\n    - fsspec >=2023.1.0,<=2025.3.0\n    - huggingface_hub >=0.24.0\n    - packaging\n    - pyyaml >=5.1\n    # For fsspec[http]\n    - aiohttp\n\ntests:\n  - python:\n      imports:\n        - datasets\n      pip_check: true\n      python_version: ${{ python_min }}.*\n  - requirements:\n      run:\n        - python ${{ python_min }}.*\n    script:\n      - datasets-cli --help\n\nabout:\n  license: Apache-2.0\n  license_file: LICENSE\n  summary: HuggingFace/Datasets is an open library of NLP datasets.\n  description: |\n    Datasets is a lightweight library providing one-line dataloaders for many\n    public datasets and one liners to download and pre-process any of the number\n    of datasets major public datasets provided on the HuggingFace Datasets Hub.\n    Datasets are ready to use in a dataloader for training/evaluating a ML model\n    (Numpy/Pandas/PyTorch/TensorFlow/JAX). Datasets also provide an API for\n    simple, fast, and reproducible data pre-processing for the above public\n    datasets as well as your own local datasets in CSV/JSON/text.\n  homepage: https://github.com/huggingface/datasets\n  repository: https://github.com/huggingface/datasets\n  documentation: https://huggingface.co/docs/datasets/\n\nextra:\n  recipe-maintainers:\n    - oblute\n    - Tata17\n    - thewchan\n    - mxr-conda\n",
  "req": {
    "__set__": true,
    "elements": [
      "aiohttp",
      "dill",
      "filelock",
      "fsspec",
      "huggingface_hub",
      "multiprocess",
      "numpy",
      "packaging",
      "pandas",
      "pip",
      "pyarrow",
      "python",
      "python-xxhash",
      "pyyaml",
      "requests",
      "setuptools",
      "tqdm"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "aiohttp",
        "dill",
        "filelock",
        "fsspec",
        "huggingface_hub",
        "multiprocess",
        "numpy",
        "packaging",
        "pandas",
        "pyarrow",
        "python",
        "python-xxhash",
        "pyyaml",
        "requests",
        "tqdm"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "pip",
        "python 3.10.*",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "aiohttp",
        "dill >=0.3.0,<0.3.9",
        "filelock",
        "fsspec >=2023.1.0,<=2025.3.0",
        "huggingface_hub >=0.24.0",
        "multiprocess <0.70.17",
        "numpy >=1.17",
        "packaging",
        "pandas",
        "pyarrow >=15.0.0",
        "python >=3.10",
        "python-xxhash",
        "pyyaml >=5.1",
        "requests >=2.32.2",
        "tqdm >=4.66.3"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip",
        "python 3.10.*"
      ]
    }
  },
  "url": "https://pypi.org/packages/source/d/datasets/datasets-4.0.0.tar.gz",
  "version": "4.0.0",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/datasets.json"
  }
}