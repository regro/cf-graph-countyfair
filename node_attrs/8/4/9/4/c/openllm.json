{
  "archived": false,
  "branch": "main",
  "conda-forge.yml": {
    "bot": {
      "automerge": true
    },
    "conda_build": {
      "error_overlinking": true
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    }
  },
  "feedstock_name": "openllm",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "home": "https://github.com/bentoml/OpenLLM",
      "license": "Apache-2.0",
      "license_file": "LICENSE.md",
      "summary": "OpenLLM: Operating LLMs in production"
    },
    "build": {
      "entry_points": [
        "openllm = openllm_cli.entrypoint:cli",
        "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
        "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
        "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
        "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
        "openllm-list-models = openllm_cli.extension.list_models:cli",
        "openllm-playground = openllm_cli.extension.playground:cli"
      ],
      "number": "0",
      "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "rxm7706",
        "conda-forge/openllm-client",
        "conda-forge/openllm-core"
      ]
    },
    "package": {
      "name": "openllm",
      "version": "0.4.44"
    },
    "requirements": {
      "host": [
        "python",
        "hatchling ==1.18.0",
        "hatch-vcs ==0.3.0",
        "hatch-fancy-pypi-readme ==23.1.0",
        "pip"
      ],
      "run": [
        "python",
        "bentoml >=1.1.11,<1.2",
        "transformers >=4.36.0",
        "openllm-client >=0.4.44",
        "openllm-core >=0.4.44",
        "safetensors",
        "optimum >=1.12.0",
        "accelerate",
        "ghapi",
        "einops",
        "sentencepiece",
        "scipy",
        "python-build <1",
        "click >=8.1.3",
        "cuda-python",
        "bitsandbytes <0.42"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "b1063f19a41479464102222b31ef240bf1a6c9557c8e0cfa24959b2c4c10bb34",
      "url": "https://pypi.io/packages/source/o/openllm/openllm-0.4.44.tar.gz"
    },
    "test": {
      "commands": [
        "pip check",
        "openllm --help",
        "openllm-dive-bentos --help",
        "openllm-get-containerfile --help",
        "openllm-get-prompt --help",
        "openllm-list-bentos --help",
        "openllm-list-models --help"
      ],
      "imports": [
        "openllm"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "hatch-fancy-pypi-readme",
        "hatch-vcs",
        "hatchling",
        "pip",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "accelerate",
        "bentoml",
        "bitsandbytes",
        "click",
        "cuda-python",
        "einops",
        "ghapi",
        "openllm-client",
        "openllm-core",
        "optimum",
        "python",
        "python-build",
        "safetensors",
        "scipy",
        "sentencepiece",
        "transformers"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "home": "https://github.com/bentoml/OpenLLM",
      "license": "Apache-2.0",
      "license_file": "LICENSE.md",
      "summary": "OpenLLM: Operating LLMs in production"
    },
    "build": {
      "entry_points": [
        "openllm = openllm_cli.entrypoint:cli",
        "openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli",
        "openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli",
        "openllm-get-prompt = openllm_cli.extension.get_prompt:cli",
        "openllm-list-bentos = openllm_cli.extension.list_bentos:cli",
        "openllm-list-models = openllm_cli.extension.list_models:cli",
        "openllm-playground = openllm_cli.extension.playground:cli"
      ],
      "number": "0",
      "script": "PYTHON -m pip install . -vv --no-deps --no-build-isolation"
    },
    "extra": {
      "recipe-maintainers": [
        "rxm7706",
        "conda-forge/openllm-client",
        "conda-forge/openllm-core"
      ]
    },
    "package": {
      "name": "openllm",
      "version": "0.4.44"
    },
    "requirements": {
      "host": [
        "python",
        "hatchling ==1.18.0",
        "hatch-vcs ==0.3.0",
        "hatch-fancy-pypi-readme ==23.1.0",
        "pip"
      ],
      "run": [
        "python",
        "bentoml >=1.1.11,<1.2",
        "transformers >=4.36.0",
        "openllm-client >=0.4.44",
        "openllm-core >=0.4.44",
        "safetensors",
        "optimum >=1.12.0",
        "accelerate",
        "ghapi",
        "einops",
        "sentencepiece",
        "scipy",
        "python-build <1",
        "click >=8.1.3",
        "cuda-python",
        "bitsandbytes <0.42"
      ]
    },
    "schema_version": 0,
    "source": {
      "sha256": "b1063f19a41479464102222b31ef240bf1a6c9557c8e0cfa24959b2c4c10bb34",
      "url": "https://pypi.io/packages/source/o/openllm/openllm-0.4.44.tar.gz"
    },
    "test": {
      "commands": [
        "pip check",
        "openllm --help",
        "openllm-dive-bentos --help",
        "openllm-get-containerfile --help",
        "openllm-get-prompt --help",
        "openllm-list-bentos --help",
        "openllm-list-models --help"
      ],
      "imports": [
        "openllm"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "name": "openllm",
  "outputs_names": {
    "__set__": true,
    "elements": [
      "openllm"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/openllm.json"
  },
  "raw_meta_yaml": "{% set name = \"openllm\" %}\n{% set version = \"0.4.44\" %}\n\npackage:\n  name: {{ name|lower }}\n  version: {{ version }}\n\nsource:\n  url: https://pypi.io/packages/source/{{ name[0] }}/{{ name }}/openllm-{{ version }}.tar.gz\n  sha256: b1063f19a41479464102222b31ef240bf1a6c9557c8e0cfa24959b2c4c10bb34\n\nbuild:\n  skip: true  # [win or osx]\n  skip: true  # [py<38]\n  entry_points:\n    - openllm = openllm_cli.entrypoint:cli\n    - openllm-dive-bentos = openllm_cli.extension.dive_bentos:cli\n    - openllm-get-containerfile = openllm_cli.extension.get_containerfile:cli\n    - openllm-get-prompt = openllm_cli.extension.get_prompt:cli\n    - openllm-list-bentos = openllm_cli.extension.list_bentos:cli\n    - openllm-list-models = openllm_cli.extension.list_models:cli\n    - openllm-playground = openllm_cli.extension.playground:cli\n  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation\n  number: 0\n\nrequirements:\n  host:\n    - python\n    - hatchling ==1.18.0\n    - hatch-vcs ==0.3.0\n    - hatch-fancy-pypi-readme ==23.1.0\n    - pip\n  run:\n    - python\n    - bentoml >=1.1.11,<1.2\n    - transformers >=4.36.0\n    - openllm-client >={{ version }}\n    - openllm-core >={{ version }}\n    - safetensors\n    - optimum >=1.12.0\n    - accelerate\n    - ghapi\n    - einops\n    - sentencepiece\n    - scipy\n    - python-build <1\n    - click >=8.1.3\n    - cuda-python\n    - bitsandbytes <0.42\n\ntest:\n  imports:\n    - openllm\n  commands:\n    - pip check\n    - openllm --help\n    - openllm-dive-bentos --help\n    - openllm-get-containerfile --help\n    - openllm-get-prompt --help\n    - openllm-list-bentos --help\n    - openllm-list-models --help\n  requires:\n    - pip\n\nabout:\n  summary: 'OpenLLM: Operating LLMs in production'\n  home: https://github.com/bentoml/OpenLLM\n  license: Apache-2.0\n  license_file: LICENSE.md\n\nextra:\n  recipe-maintainers:\n    - rxm7706\n    - conda-forge/openllm-client\n    - conda-forge/openllm-core\n",
  "req": {
    "__set__": true,
    "elements": [
      "accelerate",
      "bentoml",
      "bitsandbytes",
      "click",
      "cuda-python",
      "einops",
      "ghapi",
      "hatch-fancy-pypi-readme",
      "hatch-vcs",
      "hatchling",
      "openllm-client",
      "openllm-core",
      "optimum",
      "pip",
      "python",
      "python-build",
      "safetensors",
      "scipy",
      "sentencepiece",
      "transformers"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "hatch-fancy-pypi-readme",
        "hatch-vcs",
        "hatchling",
        "pip",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "accelerate",
        "bentoml",
        "bitsandbytes",
        "click",
        "cuda-python",
        "einops",
        "ghapi",
        "openllm-client",
        "openllm-core",
        "optimum",
        "python",
        "python-build",
        "safetensors",
        "scipy",
        "sentencepiece",
        "transformers"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "hatch-fancy-pypi-readme ==23.1.0",
        "hatch-vcs ==0.3.0",
        "hatchling ==1.18.0",
        "pip",
        "python"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "accelerate",
        "bentoml >=1.1.11,<1.2",
        "bitsandbytes <0.42",
        "click >=8.1.3",
        "cuda-python",
        "einops",
        "ghapi",
        "openllm-client >=0.4.44",
        "openllm-core >=0.4.44",
        "optimum >=1.12.0",
        "python",
        "python-build <1",
        "safetensors",
        "scipy",
        "sentencepiece",
        "transformers >=4.36.0"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "url": "https://pypi.io/packages/source/o/openllm/openllm-0.4.44.tar.gz",
  "version": "0.4.44",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/openllm.json"
  }
}