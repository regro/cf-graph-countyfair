{
  "archived": false,
  "branch": "main",
  "ci_support_linux_64_blas_implgenericc_stdlib_version2.17channel_targetsconda-forge_maincuda_compiler_version12.9github_actions_labelscirun-openstack-gpu-2xlargeis_rcFalse.yaml": "blas_impl:\n- generic\nc_compiler:\n- gcc\nc_compiler_version:\n- '14'\nc_stdlib:\n- sysroot\nc_stdlib_version:\n- '2.17'\nchannel_sources:\n- conda-forge\nchannel_targets:\n- conda-forge main\ncuda_compiler:\n- cuda-nvcc\ncuda_compiler_version:\n- '12.9'\ncxx_compiler:\n- gxx\ncxx_compiler_version:\n- '14'\ndocker_image:\n- quay.io/condaforge/linux-anvil-x86_64:alma9\nfmt:\n- '12.1'\ngithub_actions_labels:\n- cirun-openstack-gpu-2xlarge\nis_rc:\n- 'False'\nlibabseil:\n- '20250512'\nlibblas:\n- 3.9.* *netlib\nlibcblas:\n- 3.9.* *netlib\nlibcudnn_dev:\n- '9'\nliblapack:\n- 3.9.* *netlib\nlibmagma_devel:\n- '2.9'\nlibmagma_sparse:\n- '2.9'\nlibprotobuf:\n- 6.31.1\nlibtorch:\n- '2.9'\nmkl:\n- '2025'\nmkl_devel:\n- '2025'\nnccl:\n- '2'\nnumpy:\n- '2'\norc:\n- 2.2.2\npin_run_as_build:\n  python:\n    min_pin: x.x\n    max_pin: x.x\npybind11_abi:\n- '11'\npython:\n- 3.10.* *_cpython\n- 3.11.* *_cpython\n- 3.12.* *_cpython\n- 3.13.* *_cp313\n- 3.14.* *_cp314\npytorch:\n- '2.9'\ntarget_platform:\n- linux-64\nzip_keys:\n- - c_compiler_version\n  - cxx_compiler_version\n  - c_stdlib_version\n  - cuda_compiler_version\n- - channel_targets\n  - is_rc\nzlib:\n- '1'\n",
  "conda-forge.yml": {
    "azure": {
      "free_disk_space": true,
      "settings_linux": {
        "timeoutInMinutes": 1
      }
    },
    "bot": {
      "abi_migration_branches": [
        "v2.9.x"
      ]
    },
    "build_platform": {
      "linux_aarch64": "linux_64",
      "osx_64": "osx_arm64"
    },
    "conda_build": {
      "pkg_format": "2"
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    },
    "github_actions": {
      "resize_win_partitions": true,
      "self_hosted": true,
      "store_build_artifacts": true,
      "timeout_minutes": 1440,
      "triggers": [
        "push",
        "pull_request"
      ]
    },
    "provider": {
      "linux_64": "github_actions",
      "osx_arm64": "github_actions",
      "win_64": "github_actions"
    },
    "test": "native_and_emulated"
  },
  "feedstock_hash": "8e736bf3d419490c659a7e47b04b5f5adfed704b",
  "feedstock_hash_ts": 1769899710,
  "feedstock_name": "pytorch-cpu",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
      "dev_url": "https://github.com/pytorch/pytorch",
      "doc_url": "https://pytorch.org/docs/",
      "home": "https://pytorch.org/",
      "license": "BSD-3-Clause",
      "license_family": "BSD",
      "license_file": [
        "LICENSE",
        "NOTICE",
        "third_party/CMake/Copyright.txt"
      ],
      "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
    },
    "build": {
      "detect_binary_files_with_prefix": false,
      "ignore_run_exports": [
        "python *",
        "numpy *",
        "libmagma_sparse"
      ],
      "ignore_run_exports_from": [
        "python *",
        "numpy *"
      ],
      "missing_dso_whitelist": [
        "*/libcuda.so.*"
      ],
      "number": "301",
      "run_exports": [
        "libtorch"
      ],
      "string": "cuda130_mkl_h1234567_301"
    },
    "extra": {
      "feedstock-name": "pytorch-cpu",
      "recipe-maintainers": [
        "baszalmstra",
        "benjaminrwilson",
        "beckermr",
        "h-vetinari",
        "hmaarrfk",
        "jeongseok-meta",
        "mgorny",
        "sodre",
        "Tobias-Fischer"
      ]
    },
    "outputs": [
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda129_generic_py314_h1234567_201"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 12.9",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_generic_py314_h1234567_201"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_generic_py314*201"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_generic_h1234567_201"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_generic*201"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_generic_py314*1"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_h1234567_1"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_generic*1"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda130_generic_py314_h1234567_201"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 13.0",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_generic_py314_h1234567_201"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_generic_py314*201"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_generic_h1234567_201"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_generic*201"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda129_mkl_py314_h1234567_301"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 12.9",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_mkl_py314_h1234567_301"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_mkl_py314*301"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_mkl_h1234567_301"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_mkl*301"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_mkl_py314*101"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_h1234567_101"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_mkl*101"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda130_mkl_py314_h1234567_301"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 13.0",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_mkl_py314_h1234567_301"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_mkl_py314*301"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_mkl_h1234567_301"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_mkl*301"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      }
    ],
    "package": {
      "name": "libtorch",
      "version": "2.10.0"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "llvm-openmp",
        "cmake",
        "ninja",
        "libprotobuf",
        "protobuf",
        "make",
        "grep",
        "rsync"
      ],
      "host": [
        "cuda-cudart-dev",
        "cuda-cupti-dev",
        "cuda-driver-dev",
        "cuda-nvml-dev",
        "cuda-nvrtc-dev",
        "cuda-nvtx-dev",
        "cuda-profiler-api",
        "cuda-version 12.9",
        "cusparselt",
        "libcublas-dev",
        "libcudnn-dev",
        "libcudss-dev",
        "libcufile-dev",
        "libcufft-dev",
        "libcurand-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "libmagma-devel",
        "nccl",
        "nvtx-c",
        "python 3.12",
        "numpy *",
        "pip",
        "setuptools",
        "pyyaml",
        "requests",
        "six",
        "libblas",
        "libcblas",
        "liblapack",
        "libabseil",
        "libprotobuf",
        "llvm-openmp",
        "sleef",
        "libuv",
        "pkg-config",
        "typing_extensions",
        "pybind11",
        "pybind11-abi",
        "eigen",
        "zlib",
        "fmt",
        "packaging",
        "cuda-version 13.0",
        "mkl-devel",
        "libcblas * *_mkl"
      ],
      "run": [
        "libblas * *mkl"
      ],
      "run_constrained": [
        "pytorch-gpu 2.10.0",
        "pytorch-cpu <0.0a0",
        "pytorch 2.10.0 cuda129_generic_*_201",
        "libopenblas * openmp_*",
        "openblas * openmp_*",
        "pytorch-cpu 2.10.0",
        "pytorch-gpu <0.0a0",
        "pytorch 2.10.0 cpu_generic_*_1",
        "pytorch 2.10.0 cuda130_generic_*_201",
        "pytorch 2.10.0 cuda129_mkl_*_301",
        "pytorch 2.10.0 cpu_mkl_*_101",
        "pytorch 2.10.0 cuda130_mkl_*_301"
      ]
    },
    "schema_version": 0,
    "source": [
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      }
    ],
    "test": {
      "commands": [
        "test -f $PREFIX/lib/libc10.so",
        "test -f $PREFIX/lib/libshm.so",
        "test -f $PREFIX/lib/libtorch.so",
        "test -f $PREFIX/lib/libtorch_cpu.so",
        "test -f $PREFIX/lib/libtorch_global_deps.so",
        "test -f $PREFIX/lib/libtorch_cuda_linalg.so",
        "test -f $PREFIX/lib/libc10_cuda.so",
        "test -f $PREFIX/lib/libcaffe2_nvrtc.so",
        "test -f $PREFIX/lib/libtorch_cuda.so",
        "test -f $PREFIX/share/cmake/Torch/TorchConfig.cmake",
        "cd cmake_test",
        "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS ."
      ],
      "files": [
        "cmake_test/"
      ],
      "requires": [
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "cuda-nvrtc-dev",
        "nvtx-c",
        "cmake",
        "ninja",
        "pkg-config"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cmake",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "grep",
        "libprotobuf",
        "llvm-openmp",
        "make",
        "ninja",
        "protobuf",
        "python",
        "rsync"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cuda-cudart-dev",
        "cuda-cupti-dev",
        "cuda-driver-dev",
        "cuda-nvml-dev",
        "cuda-nvrtc-dev",
        "cuda-nvtx-dev",
        "cuda-profiler-api",
        "cuda-version",
        "cusparselt",
        "eigen",
        "fmt",
        "libabseil",
        "libblas",
        "libcblas",
        "libcublas-dev",
        "libcudnn-dev",
        "libcudss-dev",
        "libcufft-dev",
        "libcufile-dev",
        "libcurand-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "liblapack",
        "libmagma-devel",
        "libprotobuf",
        "libtorch",
        "libuv",
        "llvm-openmp",
        "mkl-devel",
        "nccl",
        "numpy",
        "nvtx-c",
        "packaging",
        "pip",
        "pkg-config",
        "pybind11",
        "pybind11-abi",
        "python",
        "pyyaml",
        "requests",
        "setuptools",
        "six",
        "sleef",
        "typing_extensions",
        "zlib"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "__cuda",
        "filelock",
        "fsspec",
        "jinja2",
        "libblas",
        "libtorch",
        "llvm-openmp",
        "networkx",
        "nomkl",
        "optree",
        "pybind11",
        "python",
        "pytorch",
        "setuptools",
        "sympy",
        "triton",
        "typing_extensions"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "boto3",
        "c_compiler_stub",
        "cmake",
        "cuda-nvrtc-dev",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "expecttest",
        "hypothesis",
        "ninja",
        "nvtx-c",
        "pip",
        "pkg-config",
        "pybind11",
        "pydot",
        "pytest",
        "pytest-flakefinder",
        "pytest-rerunfailures",
        "pytest-timeout",
        "pytest-xdist",
        "pyyaml",
        "tabulate",
        "xmlrunner"
      ]
    }
  },
  "linux_aarch64_meta_yaml": {
    "about": {
      "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
      "dev_url": "https://github.com/pytorch/pytorch",
      "doc_url": "https://pytorch.org/docs/",
      "home": "https://pytorch.org/",
      "license": "BSD-3-Clause",
      "license_family": "BSD",
      "license_file": [
        "LICENSE",
        "NOTICE",
        "third_party/CMake/Copyright.txt"
      ],
      "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
    },
    "build": {
      "detect_binary_files_with_prefix": false,
      "ignore_run_exports": [
        "python *",
        "numpy *",
        "libmagma_sparse"
      ],
      "ignore_run_exports_from": [
        "python *",
        "numpy *"
      ],
      "missing_dso_whitelist": [
        "*/libcuda.so.*"
      ],
      "number": "201",
      "run_exports": [
        "libtorch"
      ],
      "string": "cuda130_generic_h1234567_201"
    },
    "extra": {
      "feedstock-name": "pytorch-cpu",
      "recipe-maintainers": [
        "baszalmstra",
        "benjaminrwilson",
        "beckermr",
        "h-vetinari",
        "hmaarrfk",
        "jeongseok-meta",
        "mgorny",
        "sodre",
        "Tobias-Fischer"
      ]
    },
    "outputs": [
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda129_generic_py314_h1234567_201"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 12.9",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_generic_py314_h1234567_201"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_generic_py314*201"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_generic_h1234567_201"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_generic*201"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_generic_py314*1"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_h1234567_1"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_generic*1"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda130_generic_py314_h1234567_201"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 13.0",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_generic_py314_h1234567_201"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_generic_py314*201"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_generic_h1234567_201"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_generic*201"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      }
    ],
    "package": {
      "name": "libtorch",
      "version": "2.10.0"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "llvm-openmp",
        "cmake",
        "ninja",
        "libprotobuf",
        "protobuf",
        "make",
        "grep",
        "rsync"
      ],
      "host": [
        "cuda-cudart-dev",
        "cuda-cupti-dev",
        "cuda-driver-dev",
        "cuda-nvml-dev",
        "cuda-nvrtc-dev",
        "cuda-nvtx-dev",
        "cuda-profiler-api",
        "cuda-version 12.9",
        "cusparselt",
        "libcublas-dev",
        "libcudnn-dev",
        "libcudss-dev",
        "libcufile-dev",
        "libcufft-dev",
        "libcurand-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "libmagma-devel",
        "nccl",
        "nvtx-c",
        "python 3.12",
        "numpy *",
        "pip",
        "setuptools",
        "pyyaml",
        "requests",
        "six",
        "libblas",
        "libcblas",
        "liblapack",
        "libabseil",
        "libprotobuf",
        "llvm-openmp",
        "sleef",
        "libuv",
        "pkg-config",
        "typing_extensions",
        "pybind11",
        "pybind11-abi",
        "eigen",
        "zlib",
        "fmt",
        "packaging",
        "cuda-version 13.0"
      ],
      "run": [],
      "run_constrained": [
        "pytorch-gpu 2.10.0",
        "pytorch-cpu <0.0a0",
        "pytorch 2.10.0 cuda129_generic_*_201",
        "libopenblas * openmp_*",
        "openblas * openmp_*",
        "pytorch-cpu 2.10.0",
        "pytorch-gpu <0.0a0",
        "pytorch 2.10.0 cpu_generic_*_1",
        "pytorch 2.10.0 cuda130_generic_*_201"
      ]
    },
    "schema_version": 0,
    "source": [
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      }
    ],
    "test": {
      "commands": [
        "test -f $PREFIX/lib/libc10.so",
        "test -f $PREFIX/lib/libshm.so",
        "test -f $PREFIX/lib/libtorch.so",
        "test -f $PREFIX/lib/libtorch_cpu.so",
        "test -f $PREFIX/lib/libtorch_global_deps.so",
        "test -f $PREFIX/lib/libtorch_cuda_linalg.so",
        "test -f $PREFIX/lib/libc10_cuda.so",
        "test -f $PREFIX/lib/libcaffe2_nvrtc.so",
        "test -f $PREFIX/lib/libtorch_cuda.so",
        "test -f $PREFIX/share/cmake/Torch/TorchConfig.cmake",
        "cd cmake_test",
        "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS ."
      ],
      "files": [
        "cmake_test/"
      ],
      "requires": [
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "cuda-nvrtc-dev",
        "nvtx-c",
        "cmake",
        "ninja",
        "pkg-config"
      ]
    }
  },
  "linux_aarch64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cmake",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "grep",
        "libprotobuf",
        "llvm-openmp",
        "make",
        "ninja",
        "protobuf",
        "python",
        "rsync"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cuda-cudart-dev",
        "cuda-cupti-dev",
        "cuda-driver-dev",
        "cuda-nvml-dev",
        "cuda-nvrtc-dev",
        "cuda-nvtx-dev",
        "cuda-profiler-api",
        "cuda-version",
        "cusparselt",
        "eigen",
        "fmt",
        "libabseil",
        "libblas",
        "libcblas",
        "libcublas-dev",
        "libcudnn-dev",
        "libcudss-dev",
        "libcufft-dev",
        "libcufile-dev",
        "libcurand-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "liblapack",
        "libmagma-devel",
        "libprotobuf",
        "libtorch",
        "libuv",
        "llvm-openmp",
        "nccl",
        "numpy",
        "nvtx-c",
        "packaging",
        "pip",
        "pkg-config",
        "pybind11",
        "pybind11-abi",
        "python",
        "pyyaml",
        "requests",
        "setuptools",
        "six",
        "sleef",
        "typing_extensions",
        "zlib"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "__cuda",
        "filelock",
        "fsspec",
        "jinja2",
        "libtorch",
        "llvm-openmp",
        "networkx",
        "nomkl",
        "optree",
        "pybind11",
        "python",
        "pytorch",
        "setuptools",
        "sympy",
        "triton",
        "typing_extensions"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "boto3",
        "c_compiler_stub",
        "cmake",
        "cuda-nvrtc-dev",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "expecttest",
        "hypothesis",
        "ninja",
        "nvtx-c",
        "pip",
        "pkg-config",
        "pybind11",
        "pydot",
        "pytest",
        "pytest-flakefinder",
        "pytest-rerunfailures",
        "pytest-timeout",
        "pytest-xdist",
        "pyyaml",
        "tabulate",
        "xmlrunner"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
      "dev_url": "https://github.com/pytorch/pytorch",
      "doc_url": "https://pytorch.org/docs/",
      "home": "https://pytorch.org/",
      "license": "BSD-3-Clause",
      "license_family": "BSD",
      "license_file": [
        "LICENSE",
        "NOTICE",
        "third_party/CMake/Copyright.txt"
      ],
      "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
    },
    "build": {
      "detect_binary_files_with_prefix": false,
      "ignore_run_exports": [
        "python *",
        "numpy *",
        "libmagma_sparse"
      ],
      "ignore_run_exports_from": [
        "python *",
        "numpy *"
      ],
      "missing_dso_whitelist": [
        "*/nvcuda.dll"
      ],
      "number": "101",
      "run_exports": [
        "libtorch"
      ],
      "string": "cpu_mkl_h1234567_101"
    },
    "extra": {
      "feedstock-name": "pytorch-cpu",
      "recipe-maintainers": [
        "baszalmstra",
        "benjaminrwilson",
        "beckermr",
        "h-vetinari",
        "hmaarrfk",
        "jeongseok-meta",
        "mgorny",
        "sodre",
        "Tobias-Fischer"
      ]
    },
    "outputs": [
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda129_generic_py314_h1234567_201"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 12.9",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_generic_py314_h1234567_201"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_generic_py314*201"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_generic_h1234567_201"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_generic*201"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_generic_py314*1"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_h1234567_1"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_generic*1"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda130_generic_py314_h1234567_201"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 13.0",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_generic_py314_h1234567_201"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_generic_py314*201"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_generic_h1234567_201"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_generic*201"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda129_mkl_py314_h1234567_301"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 12.9",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_mkl_py314_h1234567_301"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_mkl_py314*301"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_mkl_h1234567_301"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_mkl*301"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_mkl_py314*101"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_h1234567_101"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_mkl*101"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda130_mkl_py314_h1234567_301"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 13.0",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_mkl_py314_h1234567_301"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_mkl_py314*301"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_mkl_h1234567_301"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_mkl*301"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda129_generic_py314_h1234567_201"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 12.9",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_generic_py314_h1234567_201"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_generic_py314*201"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda129_generic_h1234567_201"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_generic*201"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_generic_py314*1"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_h1234567_1"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_generic*1"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda130_generic_py314_h1234567_201"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "make"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-driver-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 13.0",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufile-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nccl",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "triton ==3.6.0",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_generic_py314_h1234567_201"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_generic_py314*201"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_generic_h1234567_201"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_generic*201"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_generic_py314*1"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_h1234567_1"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_generic*1"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_mkl_py314*101"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_h1234567_101"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_mkl*101"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_generic_py314*1"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_h1234567_1"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_generic*1"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda128_mkl_py314_h1234567_301"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "sccache"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 12.8",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "magma",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "bld.bat"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda128_mkl_py314_h1234567_301"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_mkl_py314*301"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\torch_python.lib exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\_C.lib exit 1",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON %CMAKE_ARGS% ..",
            "cmake --build . --config Release",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=%SP_DIR%/torch/share/cmake/Torch %CMAKE_ARGS% .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda128_mkl_h1234567_301"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_mkl*301"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda130_mkl_py314_h1234567_301"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "sccache"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 13.0",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "bld.bat"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_mkl_py314_h1234567_301"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_mkl_py314*301"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\torch_python.lib exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\_C.lib exit 1",
            "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON %CMAKE_ARGS% ..",
            "cmake --build . --config Release",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=%SP_DIR%/torch/share/cmake/Torch %CMAKE_ARGS% .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_mkl_h1234567_301"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_mkl*301"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "sccache"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "bld.bat"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_mkl_py314*101"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\torch_python.lib exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\_C.lib exit 1",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON %CMAKE_ARGS% ..",
            "cmake --build . --config Release",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=%SP_DIR%/torch/share/cmake/Torch %CMAKE_ARGS% .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_h1234567_101"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_mkl*101"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      }
    ],
    "package": {
      "name": "libtorch",
      "version": "2.10.0"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "llvm-openmp",
        "cmake",
        "ninja",
        "libprotobuf",
        "protobuf",
        "make",
        "grep",
        "rsync",
        "libuv",
        "sccache"
      ],
      "host": [
        "cuda-cudart-dev",
        "cuda-cupti-dev",
        "cuda-driver-dev",
        "cuda-nvml-dev",
        "cuda-nvrtc-dev",
        "cuda-nvtx-dev",
        "cuda-profiler-api",
        "cuda-version 12.9",
        "cusparselt",
        "libcublas-dev",
        "libcudnn-dev",
        "libcudss-dev",
        "libcufile-dev",
        "libcufft-dev",
        "libcurand-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "libmagma-devel",
        "nccl",
        "nvtx-c",
        "python 3.12",
        "numpy *",
        "pip",
        "setuptools",
        "pyyaml",
        "requests",
        "six",
        "libblas",
        "libcblas",
        "liblapack",
        "libabseil",
        "libprotobuf",
        "llvm-openmp",
        "sleef",
        "libuv",
        "pkg-config",
        "typing_extensions",
        "pybind11",
        "pybind11-abi",
        "eigen",
        "zlib",
        "fmt",
        "packaging",
        "cuda-version 13.0",
        "mkl-devel",
        "libcblas * *_mkl",
        "cuda-version 12.8",
        "magma"
      ],
      "run": [
        "libblas * *mkl"
      ],
      "run_constrained": [
        "pytorch-gpu 2.10.0",
        "pytorch-cpu <0.0a0",
        "pytorch 2.10.0 cuda129_generic_*_201",
        "libopenblas * openmp_*",
        "openblas * openmp_*",
        "pytorch-cpu 2.10.0",
        "pytorch-gpu <0.0a0",
        "pytorch 2.10.0 cpu_generic_*_1",
        "pytorch 2.10.0 cuda130_generic_*_201",
        "pytorch 2.10.0 cuda129_mkl_*_301",
        "pytorch 2.10.0 cpu_mkl_*_101",
        "pytorch 2.10.0 cuda130_mkl_*_301",
        "pytorch 2.10.0 cuda128_mkl_*_301"
      ]
    },
    "schema_version": 0,
    "source": [
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0008-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0008-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0008-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      }
    ],
    "test": {
      "commands": [
        "test -f $PREFIX/lib/libc10.so",
        "test -f $PREFIX/lib/libshm.so",
        "test -f $PREFIX/lib/libtorch.so",
        "test -f $PREFIX/lib/libtorch_cpu.so",
        "test -f $PREFIX/lib/libtorch_global_deps.so",
        "test -f $PREFIX/lib/libtorch_cuda_linalg.so",
        "test -f $PREFIX/lib/libc10_cuda.so",
        "test -f $PREFIX/lib/libcaffe2_nvrtc.so",
        "test -f $PREFIX/lib/libtorch_cuda.so",
        "test -f $PREFIX/share/cmake/Torch/TorchConfig.cmake",
        "cd cmake_test",
        "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS .",
        "test -f $PREFIX/lib/libc10.dylib",
        "test -f $PREFIX/lib/libshm.dylib",
        "test -f $PREFIX/lib/libtorch.dylib",
        "test -f $PREFIX/lib/libtorch_cpu.dylib",
        "test -f $PREFIX/lib/libtorch_global_deps.dylib",
        "if not exist %LIBRARY_BIN%\\c10.dll exit 1",
        "if not exist %LIBRARY_LIB%\\c10.lib exit 1",
        "if not exist %LIBRARY_BIN%\\shm.dll exit 1",
        "if not exist %LIBRARY_LIB%\\shm.lib exit 1",
        "if not exist %LIBRARY_BIN%\\torch.dll exit 1",
        "if not exist %LIBRARY_LIB%\\torch.lib exit 1",
        "if not exist %LIBRARY_BIN%\\torch_cpu.dll exit 1",
        "if not exist %LIBRARY_LIB%\\torch_cpu.lib exit 1",
        "if not exist %LIBRARY_BIN%\\torch_global_deps.dll exit 1",
        "if not exist %LIBRARY_BIN%\\c10_cuda.dll exit 1",
        "if not exist %LIBRARY_LIB%\\c10_cuda.lib exit 1",
        "if not exist %LIBRARY_BIN%\\caffe2_nvrtc.dll exit 1",
        "if not exist %LIBRARY_LIB%\\caffe2_nvrtc.lib exit 1",
        "if not exist %LIBRARY_BIN%\\torch_cuda.dll exit 1",
        "if not exist %LIBRARY_LIB%\\torch_cuda.lib exit 1",
        "if not exist %LIBRARY_PREFIX%\\share\\cmake\\Torch\\TorchConfig.cmake exit 1",
        "cmake -GNinja -DCMAKE_CXX_STANDARD=17 %CMAKE_ARGS% ."
      ],
      "files": [
        "cmake_test/"
      ],
      "requires": [
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "cuda-nvrtc-dev",
        "nvtx-c",
        "cmake",
        "ninja",
        "pkg-config"
      ]
    }
  },
  "name": "libtorch",
  "osx_64_meta_yaml": {
    "about": {
      "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
      "dev_url": "https://github.com/pytorch/pytorch",
      "doc_url": "https://pytorch.org/docs/",
      "home": "https://pytorch.org/",
      "license": "BSD-3-Clause",
      "license_family": "BSD",
      "license_file": [
        "LICENSE",
        "NOTICE",
        "third_party/CMake/Copyright.txt"
      ],
      "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
    },
    "build": {
      "detect_binary_files_with_prefix": false,
      "ignore_run_exports": [
        "python *",
        "numpy *",
        "libmagma_sparse"
      ],
      "ignore_run_exports_from": [
        "python *",
        "numpy *"
      ],
      "missing_dso_whitelist": null,
      "number": "101",
      "run_exports": [
        "libtorch"
      ],
      "string": "cpu_mkl_h1234567_101"
    },
    "extra": {
      "feedstock-name": "pytorch-cpu",
      "recipe-maintainers": [
        "baszalmstra",
        "benjaminrwilson",
        "beckermr",
        "h-vetinari",
        "hmaarrfk",
        "jeongseok-meta",
        "mgorny",
        "sodre",
        "Tobias-Fischer"
      ]
    },
    "outputs": [
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_generic_py314*1"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_h1234567_1"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_generic*1"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_mkl_py314*101"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_h1234567_101"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_mkl*101"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      }
    ],
    "package": {
      "name": "libtorch",
      "version": "2.10.0"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub",
        "llvm-openmp",
        "cmake",
        "ninja",
        "libprotobuf",
        "protobuf",
        "grep",
        "rsync"
      ],
      "host": [
        "python 3.12",
        "numpy *",
        "pip",
        "setuptools",
        "pyyaml",
        "requests",
        "six",
        "libblas",
        "libcblas",
        "liblapack",
        "libabseil",
        "libprotobuf",
        "llvm-openmp",
        "sleef",
        "libuv",
        "pkg-config",
        "typing_extensions",
        "pybind11",
        "pybind11-abi",
        "eigen",
        "zlib",
        "fmt",
        "packaging",
        "mkl-devel",
        "libcblas * *_mkl"
      ],
      "run": [
        "libblas * *mkl"
      ],
      "run_constrained": [
        "pytorch-cpu 2.10.0",
        "pytorch-gpu <0.0a0",
        "pytorch 2.10.0 cpu_generic_*_1",
        "libopenblas * openmp_*",
        "openblas * openmp_*",
        "pytorch 2.10.0 cpu_mkl_*_101"
      ]
    },
    "schema_version": 0,
    "source": [
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      }
    ],
    "test": {
      "commands": [
        "test -f $PREFIX/lib/libc10.dylib",
        "test -f $PREFIX/lib/libshm.dylib",
        "test -f $PREFIX/lib/libtorch.dylib",
        "test -f $PREFIX/lib/libtorch_cpu.dylib",
        "test -f $PREFIX/lib/libtorch_global_deps.dylib",
        "cd cmake_test",
        "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS ."
      ],
      "files": [
        "cmake_test/"
      ],
      "requires": [
        "cxx_compiler_stub",
        "cmake",
        "ninja",
        "pkg-config"
      ]
    }
  },
  "osx_64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cmake",
        "cxx_compiler_stub",
        "grep",
        "libprotobuf",
        "llvm-openmp",
        "ninja",
        "protobuf",
        "python",
        "rsync"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "eigen",
        "fmt",
        "libabseil",
        "libblas",
        "libcblas",
        "liblapack",
        "libprotobuf",
        "libtorch",
        "libuv",
        "llvm-openmp",
        "mkl-devel",
        "numpy",
        "packaging",
        "pip",
        "pkg-config",
        "pybind11",
        "pybind11-abi",
        "python",
        "pyyaml",
        "requests",
        "setuptools",
        "six",
        "sleef",
        "typing_extensions",
        "zlib"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "filelock",
        "fsspec",
        "jinja2",
        "libblas",
        "libtorch",
        "llvm-openmp",
        "networkx",
        "nomkl",
        "optree",
        "pybind11",
        "python",
        "pytorch",
        "setuptools",
        "sympy",
        "typing_extensions"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "boto3",
        "c_compiler_stub",
        "cmake",
        "cxx_compiler_stub",
        "expecttest",
        "hypothesis",
        "ninja",
        "pip",
        "pkg-config",
        "pybind11",
        "pydot",
        "pytest",
        "pytest-flakefinder",
        "pytest-rerunfailures",
        "pytest-timeout",
        "pytest-xdist",
        "pyyaml",
        "tabulate",
        "xmlrunner"
      ]
    }
  },
  "osx_arm64_meta_yaml": {
    "about": {
      "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
      "dev_url": "https://github.com/pytorch/pytorch",
      "doc_url": "https://pytorch.org/docs/",
      "home": "https://pytorch.org/",
      "license": "BSD-3-Clause",
      "license_family": "BSD",
      "license_file": [
        "LICENSE",
        "NOTICE",
        "third_party/CMake/Copyright.txt"
      ],
      "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
    },
    "build": {
      "detect_binary_files_with_prefix": false,
      "ignore_run_exports": [
        "python *",
        "numpy *",
        "libmagma_sparse"
      ],
      "ignore_run_exports_from": [
        "python *",
        "numpy *"
      ],
      "missing_dso_whitelist": null,
      "number": "1",
      "run_exports": [
        "libtorch"
      ],
      "string": "cpu_generic_h1234567_1"
    },
    "extra": {
      "feedstock-name": "pytorch-cpu",
      "recipe-maintainers": [
        "baszalmstra",
        "benjaminrwilson",
        "beckermr",
        "h-vetinari",
        "hmaarrfk",
        "jeongseok-meta",
        "mgorny",
        "sodre",
        "Tobias-Fischer"
      ]
    },
    "outputs": [
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "libcblas",
            "liblapack",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "pkg-config",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "nomkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "build.sh"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_py314_h1234567_1"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_generic_py314*1"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.distributed.is_available()\"",
            "test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}",
            "export OMP_NUM_THREADS=4",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..",
            "cmake --build .",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_generic_h1234567_1"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_generic*1"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      }
    ],
    "package": {
      "name": "libtorch",
      "version": "2.10.0"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub",
        "llvm-openmp",
        "cmake",
        "ninja",
        "libprotobuf",
        "protobuf",
        "grep",
        "rsync"
      ],
      "host": [
        "python 3.12",
        "numpy *",
        "pip",
        "setuptools",
        "pyyaml",
        "requests",
        "six",
        "libblas",
        "libcblas",
        "liblapack",
        "libabseil",
        "libprotobuf",
        "llvm-openmp",
        "sleef",
        "libuv",
        "pkg-config",
        "typing_extensions",
        "pybind11",
        "pybind11-abi",
        "eigen",
        "zlib",
        "fmt",
        "packaging"
      ],
      "run": [],
      "run_constrained": [
        "pytorch-cpu 2.10.0",
        "pytorch-gpu <0.0a0",
        "pytorch 2.10.0 cpu_generic_*_1",
        "libopenblas * openmp_*",
        "openblas * openmp_*"
      ]
    },
    "schema_version": 0,
    "source": [
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      }
    ],
    "test": {
      "commands": [
        "test -f $PREFIX/lib/libc10.dylib",
        "test -f $PREFIX/lib/libshm.dylib",
        "test -f $PREFIX/lib/libtorch.dylib",
        "test -f $PREFIX/lib/libtorch_cpu.dylib",
        "test -f $PREFIX/lib/libtorch_global_deps.dylib",
        "cd cmake_test",
        "cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS ."
      ],
      "files": [
        "cmake_test/"
      ],
      "requires": [
        "cxx_compiler_stub",
        "cmake",
        "ninja",
        "pkg-config"
      ]
    }
  },
  "osx_arm64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cmake",
        "cxx_compiler_stub",
        "grep",
        "libprotobuf",
        "llvm-openmp",
        "ninja",
        "protobuf",
        "python",
        "rsync"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "eigen",
        "fmt",
        "libabseil",
        "libblas",
        "libcblas",
        "liblapack",
        "libprotobuf",
        "libtorch",
        "libuv",
        "llvm-openmp",
        "numpy",
        "packaging",
        "pip",
        "pkg-config",
        "pybind11",
        "pybind11-abi",
        "python",
        "pyyaml",
        "requests",
        "setuptools",
        "six",
        "sleef",
        "typing_extensions",
        "zlib"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "filelock",
        "fsspec",
        "jinja2",
        "libtorch",
        "llvm-openmp",
        "networkx",
        "nomkl",
        "optree",
        "pybind11",
        "python",
        "pytorch",
        "setuptools",
        "sympy",
        "typing_extensions"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "boto3",
        "c_compiler_stub",
        "cmake",
        "cxx_compiler_stub",
        "expecttest",
        "hypothesis",
        "ninja",
        "pip",
        "pkg-config",
        "pybind11",
        "pydot",
        "pytest",
        "pytest-flakefinder",
        "pytest-rerunfailures",
        "pytest-timeout",
        "pytest-xdist",
        "pyyaml",
        "tabulate",
        "xmlrunner"
      ]
    }
  },
  "outputs_names": {
    "__set__": true,
    "elements": [
      "libtorch",
      "pytorch",
      "pytorch-cpu",
      "pytorch-gpu",
      "pytorch-tests"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64",
    "linux_aarch64",
    "osx_64",
    "osx_arm64",
    "win_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/pytorch-cpu.json"
  },
  "raw_meta_yaml": "# if you wish to build release candidate number X, append the version string with \".rcX\"\n{% set version = \"2.10.0\" %}\n{% set build = 1 %}\n\n# Use a higher build number for the CUDA variant, to ensure that it's\n# preferred by conda's solver, and it's preferentially\n# installed where the platform supports it.\n{% if cuda_compiler_version != \"None\" %}\n{% set build = build + 200 %}\n{% endif %}\n\n{% if blas_impl == \"mkl\" %}\n{% set build = build + 100 %}\n{% endif %}\n\n# see https://github.com/pytorch/pytorch/blame/v{{ version }}/.ci/docker/ci_commit_pins/triton.txt\n# pytorch and triton are released in tandem, see notes in their release process\n# https://github.com/pytorch/pytorch/blob/main/RELEASE.md#triton-dependency-for-the-release\n{% set triton = \"3.6.0\" %}\n\npackage:\n  name: libtorch\n  version: {{ version.replace(\"-\", \".\") }}\n\nsource:\n{% if \"rc\" in version %}\n  - url: https://download.pytorch.org/source_code/test/pytorch-v{{ version }}.tar.gz\n    sha256: f35b2d7839b284410e5be9ec2eeb7a3049e09c1b8f6a871d3f2cad495d93dcd6\n{% else %}\n  # The \"pytorch-v\" tarballs contain submodules; the \"pytorch-\" ones don't.\n  - url: https://github.com/pytorch/pytorch/releases/download/v{{ version }}/pytorch-v{{ version }}.tar.gz\n    sha256: fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f\n{% endif %}\n    patches:\n      - patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch\n      # conda-specific patch, lets us override CUDA paths\n      - patches/0002-Allow-overriding-CUDA-related-paths.patch\n      # fix BLAS calling convention for openblas\n      - patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch\n      - patches/0004-Fix-FindOpenBLAS.patch\n      # point to headers that are now living in $PREFIX/include instead of $SP_DIR/torch/include\n      - patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch\n      - patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch\n      - patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch\n      - patches/0008-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch                       # [win]\n      - patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch\n      # skip a test that fails with numpy v2.3; still triggers as of pytorch v2.9\n      - patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch\n      # backport https://github.com/pytorch/pytorch/pull/127702\n      - patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch\n      # backport https://github.com/pytorch/pytorch/pull/166824\n      - patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch\n      - patches/0013-Fix-building-kineto-against-system-fmt.patch\n      # backport https://github.com/pytorch/pytorch/pull/159828\n      - patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch\n      - patches/0015-Use-Intel-LLVM-openmp.patch\n      # continued $PREFIX/include headers\n      - patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch\n      - patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch\n\nbuild:\n  number: {{ build }}\n  # This logic allows two rc variants to be defined in the conda_build_config, but only one to actually be built.\n  # We want to be able to define two variants in the cbc so we can assign different labels to each in the upload channel\n  # (by zipping is_rc with channel_targets). This prevents rc builds being used unless specifically requested.\n{% if \"rc\" in version %}\n  skip: true  # [not is_rc]\n{% else %}\n  skip: true  # [is_rc]\n{% endif %}\n  # CUDA builds on GPU agents, non-CUDA builds on CPU agents; c.f.\n  # https://github.com/conda-forge/conda-smithy/pull/2434; the skip could be avoided\n  # using https://github.com/conda-forge/conda-forge-pinning-feedstock/pull/6910\n  # (plus a mechanism similar to CF_CUDA_ENABLED, preliminarily called CF_SELF_HOSTED).\n  # condition needs to be on a single line for conda-build to catch used variables\n  {% if (cuda_compiler_version == \"None\" and \"gpu\" in github_actions_labels) or (cuda_compiler_version != \"None\" and \"cpu\" in github_actions_labels) %}\n  skip: true\n  {% endif %}\n  string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_h{{ PKG_HASH }}_{{ build }}  # [cuda_compiler_version != \"None\"]\n  string: cpu_{{ blas_impl }}_h{{ PKG_HASH }}_{{ build }}                                                 # [cuda_compiler_version == \"None\"]\n  detect_binary_files_with_prefix: false\n  missing_dso_whitelist:\n    - '*/libcuda.so.*'    # [linux]\n    - '*/nvcuda.dll'      # [win]\n  run_exports:\n    - {{ pin_subpackage('libtorch', max_pin='x.x') }}\n  ignore_run_exports_from:\n    - python *\n    - numpy *\n    - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n  ignore_run_exports:\n    - python *\n    - numpy *\n    - libmagma_sparse\n\nrequirements:\n  # Keep this list synchronized (except for python*, numpy*) in outputs\n  # We use python to build libtorch as well because it is easier\n  build:\n    # When you change 3.12 here, change it in build.sh/bld.bat as well\n    - python 3.12                            # [build_platform != target_platform]\n    - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n    - numpy  *                               # [build_platform != target_platform]\n    - {{ stdlib('c') }}\n    - {{ compiler('c') }}\n    - {{ compiler('cxx') }}\n    - {{ compiler('cuda') }}                 # [cuda_compiler_version != \"None\"]\n    - libuv                     # [win]\n    - llvm-openmp\n    - cmake\n    - ninja\n    # Keep libprotobuf here so that a compatibile version\n    # of protobuf is installed between build and host\n    - libprotobuf\n    - protobuf\n    - make      # [linux]\n    - sccache   # [win]\n    - grep      # [unix]\n    - rsync     # [unix]\n  host:\n    # GPU requirements\n    {% if cuda_compiler_version != \"None\" %}\n    - cuda-cudart-dev\n    - cuda-cupti-dev\n    - cuda-driver-dev       # [linux]\n    - cuda-nvml-dev\n    - cuda-nvrtc-dev\n    - cuda-nvtx-dev\n    - cuda-profiler-api\n    - cuda-version {{ cuda_compiler_version }}\n    - cusparselt\n    - libcublas-dev\n    - libcudnn-dev\n    - libcudss-dev\n    - libcufile-dev         # [linux]\n    - libcufft-dev\n    - libcurand-dev\n    - libcusolver-dev\n    - libcusparse-dev\n    - libmagma-devel        # [cuda_compiler_version != \"12.8\"]\n    # cannot (yet) use libmagma-devel due to https://github.com/conda-forge/libmagma-feedstock/issues/32\n    - magma                 # [cuda_compiler_version == \"12.8\"]\n    - nccl                  # [linux]\n    - nvtx-c\n    {% endif %}\n    # other requirements\n    - python 3.12\n    - numpy *\n    - pip\n    - setuptools\n    - pyyaml\n    - requests\n    - six\n    - mkl-devel             # [blas_impl == \"mkl\"]\n    - libcblas * *_mkl      # [blas_impl == \"mkl\"]\n    - libblas               # [blas_impl != \"mkl\"]\n    - libcblas              # [blas_impl != \"mkl\"]\n    - liblapack             # [blas_impl != \"mkl\"]\n    - libabseil\n    - libprotobuf\n    - llvm-openmp\n    - sleef\n    - libuv\n    - pkg-config  # [unix]\n    - typing_extensions\n    - pybind11\n    - pybind11-abi\n    - eigen\n    - zlib\n    - fmt\n    - packaging\n  run:\n    - libblas * *{{ blas_impl }}        # [blas_impl == \"mkl\"]\n  run_constrained:\n    # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/65\n    - pytorch-cpu {{ version }}    # [cuda_compiler_version == \"None\"]\n    - pytorch-gpu <0.0a0           # [cuda_compiler_version == \"None\"]\n    - pytorch-gpu {{ version }}    # [cuda_compiler_version != \"None\"]\n    - pytorch-cpu <0.0a0           # [cuda_compiler_version != \"None\"]\n    - pytorch {{ version }} cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_*_{{ build }}  # [cuda_compiler_version != \"None\"]\n    - pytorch {{ version }} cpu_{{ blas_impl }}_*_{{ build }}                                                 # [cuda_compiler_version == \"None\"]\n    # if using OpenBLAS, ensure that a version compatible with OpenMP is used\n    # otherwise, we get the following warnings:\n    # OpenBLAS Warning : Detect OpenMP Loop and this application may hang. Please rebuild the library with USE_OPENMP=1 option.\n    - libopenblas * openmp_*       # [unix and blas_impl != \"mkl\"]\n    - openblas * openmp_*          # [unix and blas_impl != \"mkl\"]\n\n# these tests are for the libtorch output below, but due to\n# a particularity of conda-build, that output is defined in\n# the global build stage, including tests\ntest:\n  requires:\n    # cmake needs a compiler to run package detection, see\n    # https://discourse.cmake.org/t/questions-about-find-package-cli-msvc/6194\n    - {{ compiler('cxx') }}\n    # for CMake config to find cuda & nvrtc\n    - {{ compiler('cuda') }}    # [cuda_compiler_version != \"None\"]\n    - cuda-nvrtc-dev            # [cuda_compiler_version != \"None\"]\n    - nvtx-c                    # [cuda_compiler_version != \"None\"]\n    - cmake\n    - ninja\n    - pkg-config\n  files:\n    - cmake_test/\n  commands:\n    # libraries; peculiar formatting to avoid linter false positives about selectors\n    {% set torch_libs = [\n        \"c10\", \"shm\", \"torch\", \"torch_cpu\", \"torch_global_deps\"\n    ] + (cuda_compiler_version != \"None\" and target_platform.startswith(\"linux\")) * [\n        \"torch_cuda_linalg\"\n    ] + (cuda_compiler_version != \"None\") * [\n        \"c10_cuda\", \"caffe2_nvrtc\", \"torch_cuda\"\n    ]\n    %}\n    {% for each_lib in torch_libs %}\n    - test -f $PREFIX/lib/lib{{ each_lib }}.so              # [linux]\n    - test -f $PREFIX/lib/lib{{ each_lib }}.dylib           # [osx]\n    - if not exist %LIBRARY_BIN%\\{{ each_lib }}.dll exit 1  # [win]\n    {% if each_lib != \"torch_global_deps\" %}\n    - if not exist %LIBRARY_LIB%\\{{ each_lib }}.lib exit 1  # [win]\n    {% endif %}\n    {% endfor %}\n\n    # CMake files in share\n    - test -f $PREFIX/share/cmake/Torch/TorchConfig.cmake                       # [linux]\n    - if not exist %LIBRARY_PREFIX%\\share\\cmake\\Torch\\TorchConfig.cmake exit 1  # [win]\n\n    # test integrity of CMake metadata\n    - cd cmake_test\n    - cmake -GNinja -DCMAKE_CXX_STANDARD=17 $CMAKE_ARGS .   # [unix]\n    - cmake -GNinja -DCMAKE_CXX_STANDARD=17 %CMAKE_ARGS% .  # [win]\n\noutputs:\n  - name: libtorch\n  - name: pytorch\n    script: build.sh    # [unix]\n    script: bld.bat     # [win]\n    build:\n      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ build }}  # [cuda_compiler_version != \"None\"]\n      string: cpu_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ build }}                                                 # [cuda_compiler_version == \"None\"]\n      detect_binary_files_with_prefix: false\n      run_exports:\n        - {{ pin_subpackage('pytorch', max_pin='x.x') }}\n        - {{ pin_subpackage('libtorch', max_pin='x.x') }}\n      ignore_run_exports:\n        - libmagma_sparse\n    requirements:\n      build:\n        - python\n        - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n        - numpy                                  # [build_platform != target_platform]\n        - {{ stdlib('c') }}\n        - {{ compiler('c') }}\n        - {{ compiler('cxx') }}\n        - {{ compiler('cuda') }}                 # [cuda_compiler_version != \"None\"]\n        - cmake\n        - ninja\n        # Keep libprotobuf here so that a compatibile version\n        # of protobuf is installed between build and host\n        - libprotobuf\n        - protobuf\n        - make      # [linux]\n        - sccache   # [win]\n      host:\n        - {{ pin_subpackage('libtorch', exact=True) }}\n        # GPU requirements\n        {% if cuda_compiler_version != \"None\" %}\n        - cuda-cudart-dev\n        - cuda-cupti-dev\n        - cuda-driver-dev       # [linux]\n        - cuda-nvml-dev\n        - cuda-nvrtc-dev\n        - cuda-nvtx-dev\n        - cuda-profiler-api\n        - cuda-version {{ cuda_compiler_version }}\n        - cusparselt\n        - libcublas-dev\n        - libcudnn-dev\n        - libcudss-dev\n        - libcufile-dev         # [linux]\n        - libcufft-dev\n        - libcurand-dev\n        - libcusolver-dev\n        - libcusparse-dev\n        - libmagma-devel        # [cuda_compiler_version != \"12.8\"]\n        # cannot (yet) use libmagma-devel due to https://github.com/conda-forge/libmagma-feedstock/issues/32\n        - magma                 # [cuda_compiler_version == \"12.8\"]\n        - nccl                  # [linux]\n        - nvtx-c\n        {% endif %}\n        # other requirements\n        - python\n        - numpy\n        - pip\n        - setuptools\n        - pyyaml\n        - requests\n        - six\n        - mkl-devel             # [blas_impl == \"mkl\"]\n        - libcblas * *_mkl      # [blas_impl == \"mkl\"]\n        - libcblas              # [blas_impl != \"mkl\"]\n        - liblapack             # [blas_impl != \"mkl\"]\n        - libabseil\n        - libprotobuf\n        - llvm-openmp\n        - pybind11\n        - pybind11-abi\n        - eigen\n        - sleef\n        - libuv\n        - pkg-config  # [unix]\n        - typing_extensions\n        - zlib\n        - fmt\n        - packaging\n      run:\n        - {{ pin_subpackage('libtorch', exact=True) }}\n        - llvm-openmp\n        - libblas * *{{ blas_impl }}        # [blas_impl == \"mkl\"]\n        - nomkl                             # [blas_impl != \"mkl\"]\n        - triton =={{ triton }}             # [cuda_compiler_version != \"None\" and not win]\n        # avoid that people without GPUs needlessly download ~0.5-1GB\n        - __cuda                            # [cuda_compiler_version != \"None\"]\n        - python\n        # other requirements, see https://github.com/pytorch/pytorch/blame/main/requirements.txt\n        - filelock\n        - fsspec\n        - jinja2\n        - networkx\n        - optree >=0.13.0\n        - pybind11\n        - setuptools\n        - sympy >=1.13.3\n        - typing_extensions >=4.10.0\n      run_constrained:\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/65\n        - pytorch-cpu {{ version }}    # [cuda_compiler_version == \"None\"]\n        - pytorch-gpu <0.0a0           # [cuda_compiler_version == \"None\"]\n        - pytorch-gpu {{ version }}    # [cuda_compiler_version != \"None\"]\n        - pytorch-cpu <0.0a0           # [cuda_compiler_version != \"None\"]\n\n  - name: pytorch-tests\n    build:\n      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ build }}  # [cuda_compiler_version != \"None\"]\n      string: cpu_{{ blas_impl }}_py{{ CONDA_PY }}_h{{ PKG_HASH }}_{{ build }}                                                 # [cuda_compiler_version == \"None\"]\n      detect_binary_files_with_prefix: false\n    requirements:\n      host:\n        - python\n      run:\n        - pytorch {{ version }} cuda*_{{ blas_impl }}_py{{ CONDA_PY }}*{{ build }}   # [cuda_compiler_version != \"None\"]\n        - pytorch {{ version }} cpu_{{ blas_impl }}_py{{ CONDA_PY }}*{{ build }}     # [cuda_compiler_version == \"None\"]\n    test:\n      requires:\n        - {{ compiler('c') }}\n        - {{ compiler('cxx') }}\n        # for torch.compile tests\n        - {{ compiler('cuda') }}       # [cuda_compiler_version != \"None\"]\n        - ninja\n        - boto3\n        - hypothesis\n        # pytest-9 causes failure due to PytestRemovedIn9Warning\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/448#issuecomment-3529016115\n        - pytest <9\n        - tabulate\n        - pydot\n        - pip\n        - expecttest\n        - xmlrunner\n        - pyyaml\n        # Required by run_test.py\n        - pytest-flakefinder\n        - pytest-rerunfailures\n        - pytest-xdist\n        # danpetry/TF: Pytorch includes their own edited version of pytest-shard and adding\n        # it into the test deps as well results in the --shard-id option being added twice.\n        # https://github.com/pytorch/pytorch/blob/main/test/pytest_shard_custom.py\n        # - pytest-shard\n        # for cmake_test\n        - cmake\n        - cuda-nvrtc-dev            # [cuda_compiler_version != \"None\"]\n        - nvtx-c                    # [cuda_compiler_version != \"None\"]\n        - pybind11\n        # not required upstream, but useful\n        - pytest-timeout\n      imports:\n        - torch\n        - torch._C\n      files:\n        - cmake_test/\n      source_files:\n        # Only include the source_files if we are actually going to run the tests.\n        - test\n        - tools\n      commands:\n        # Run pip check so as to ensure that all pytorch packages are installed\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/24\n        - pip check\n        - python -c \"import torch; print(torch.__version__)\"\n        - python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"  # [x86 and cuda_compiler_version == \"None\"]\n        - python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"\n        # We have had issues with openmp .dylibs being doubly loaded in certain cases. These two tests catch the (observed) issue\n        - python -c \"import torch; import numpy\"\n        - python -c \"import numpy; import torch\"\n        - python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"\n        # distributed support is enabled by default on linux; for mac, we enable it manually in build.sh\n        - python -c \"import torch; assert torch.distributed.is_available()\"         # [linux or osx]\n        - python -c \"import torch; assert torch.backends.cuda.is_built()\"           # [cuda_compiler_version != \"None\"]\n        - python -c \"import torch; assert torch.backends.cudnn.is_available()\"      # [cuda_compiler_version != \"None\"]\n        - python -c \"import torch; assert torch.backends.cudnn.enabled\"             # [cuda_compiler_version != \"None\"]\n        - python -c \"import torch; assert torch.version.cuda is not None\"           # [cuda_compiler_version != \"None\"]\n        # At conda-forge, we target versions of OSX that are too old for MPS support\n        # But if users install a newer version of OSX, they will have MPS support\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/123#issuecomment-1186355073\n        # - python -c \"import torch; assert torch.backends.mps.is_available()\" # [osx]\n\n        # python-version-specific library (default location in SP_DIR symlinks back to this)\n        - test -f $PREFIX/lib/libtorch_python${SHLIB_EXT}           # [unix]\n        - if not exist %LIBRARY_BIN%\\torch_python.dll exit 1        # [win]\n        - if not exist %SP_DIR%\\torch\\lib\\torch_python.lib exit 1   # [win]\n        - if not exist %SP_DIR%\\torch\\lib\\_C.lib exit 1             # [win]\n\n        # a reasonably safe subset of tests that should run under 15 minutes\n        {% set tests = \" \".join([\n            \"test/test_autograd.py\",\n            \"test/test_autograd_fallback.py\",\n            \"test/test_custom_ops.py\",\n            \"test/test_linalg.py\",\n            \"test/test_mkldnn.py\",\n            \"test/test_modules.py\",\n            \"test/test_nn.py\",\n            \"test/test_torch.py\",\n            \"test/test_xnnpack_integration.py\",\n        ]) %}\n        # tests torch.compile; avoid on aarch because it adds >4h in test runtime in emulation;\n        # they add a lot of runtime (15->60min on windows), so run them for only one python version\n        {% set tests = tests ~ \" test/inductor/test_torchinductor.py\" %}    # [py==312 and not (aarch64 or osx)]\n\n        {% set skips = \"(TestTorch and test_print)\" %}\n        # minor tolerance violations\n        {% set skips = skips ~ \" or test_1_sized_with_0_strided_cpu_float32\" %}         # [osx]\n        {% set skips = skips ~ \" or test_batchnorm_nhwc_cpu\" %}                         # [unix]\n        {% set skips = skips ~ \" or test_layer_norm_backwards_eps\" %}                   # [unix]\n        # timeouts and failures on aarch, see https://github.com/conda-forge/pytorch-cpu-feedstock/pull/298#issuecomment-2555888508\n        {% set skips = skips ~ \" or test_pynode_destruction_deadlock\" %}                # [aarch64]\n        {% set skips = skips ~ \" or (TestLinalgCPU and test_cholesky_cpu_float32)\" %}   # [aarch64]\n        {% set skips = skips ~ \" or (TestLinalgCPU and test_pca_lowrank_cpu)\" %}        # [aarch64]\n        {% set skips = skips ~ \" or (TestLinalgCPU and test_svd_lowrank_cpu)\" %}        # [aarch64]\n        {% set skips = skips ~ \" or (TestMkldnnCPU and test_lstm_cpu)\" %}               # [aarch64]\n        # very long-running tests in emulation\n        {% set skips = skips ~ \" or test_eigh_lwork_lapack\" %}                          # [aarch64]\n        {% set skips = skips ~ \" or test_gradgrad_nn_LSTM\" %}                           # [aarch64]\n        {% set skips = skips ~ \" or test_grad_nn_Transformer\" %}                        # [aarch64]\n        {% set skips = skips ~ \" or test_inverse_errors_large\" %}                       # [aarch64]\n        {% set skips = skips ~ \" or (TestXNNPACKConv1dTransformPass and test_conv1d_basic)\" %}  # [aarch64]\n        # errors (possibly QEMU-related) with openblas 0.3.30\n        {% set skips = skips ~ \" or test_addbmm or test_baddbmm or test_bmm\" %}         # [aarch64]\n        # doesn't crash, but gets different result on aarch + CUDA\n        {% set skips = skips ~ \" or illcondition_matrix_input_should_not_crash_cpu\" %}  # [aarch64 and cuda_compiler_version != \"None\"]\n        # may crash spuriously\n        {% set skips = skips ~ \" or (TestAutograd and test_profiler_seq_nr)\" %}         # [not win]\n        {% set skips = skips ~ \" or (TestAutograd and test_profiler_propagation)\" %}    # [not win]\n        # tests that fail due to resource clean-up issues (non-unique temporary libraries), see\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/318#issuecomment-2620080859\n        {% set skips = skips ~ \" or test_mutable_custom_op_fixed_layout\" %}             # [not win]\n        # minor inaccuracy on aarch64 (emulation?)\n        {% set skips = skips ~ \" or (TestNN and test_upsampling_bfloat16)\" %}           # [aarch64]\n        # flaky failure: `Exec format error: '$PREFIX/bin/python3.12'`\n        {% set skips = skips ~ \" or test_terminate_handler_on_crash\" %}                 # [aarch64]\n        # may crash spuriously\n        {% set skips = skips ~ \" or (TestAutograd and test_profiler_seq_nr)\" %}\n        {% set skips = skips ~ \" or (TestAutograd and test_profiler_propagation)\" %}\n        # tests that fail due to resource clean-up issues (non-unique temporary libraries), see\n        # https://github.com/conda-forge/pytorch-cpu-feedstock/pull/318#issuecomment-2620080859\n        {% set skips = skips ~ \" or test_mutable_custom_op_fixed_layout\" %}\n        # trivial accuracy problems\n        {% set skips = skips ~ \" or test_BCELoss_weights_no_reduce_cuda\" %}             # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_ctc_loss_cudnn_tensor_cuda\" %}                 # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or (TestTorch and test_index_add_correctness)\" %}      # [linux and cuda_compiler_version != \"None\"]\n        # These tests require higher-resource or more recent GPUs than the CI provides\n        {% set skips = skips ~ \" or test_sdpa_inference_mode_aot_compile\" %}            # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or (TestNN and test_grid_sample)\" %}                   # [linux and cuda_compiler_version != \"None\"]\n        # don't mess with tests that rely on GPU failure handling\n        {% set skips = skips ~ \" or test_cublas_config_nondeterministic_alert_cuda\" %}  # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_cross_entropy_loss_2d_out_of_bounds_class\" %}  # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_indirect_device_assert\" %}                     # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_reentrant_parent_error_on_cpu_cuda\" %}         # [linux and cuda_compiler_version != \"None\"]\n        # test that fails to find temporary resource\n        {% set skips = skips ~ \" or (GPUTests and test_scatter_reduce2)\" %}             # [linux and cuda_compiler_version != \"None\"]\n        # ROCM test whose skip doesn't trigger\n        {% set skips = skips ~ \" or test_ck_blas_library_cpu\" %}                        # [linux and cuda_compiler_version != \"None\"]\n        # problem with finding output of `torch.cuda.tunable.write_file()`\n        {% set skips = skips ~ \" or test_matmul_offline_tunableop_cuda_float16\" %}      # [linux and cuda_compiler_version != \"None\"]\n        # catastropic accuracy failure in convolution\n        {% set skips = skips ~ \" or test_Conv3d_1x1x1_no_bias_cuda\" %}                  # [linux and cuda_compiler_version != \"None\"]\n        # some triton errors that appeared in #391\n        {% set skips = skips ~ \" or test_isinf_cuda\" %}                                 # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_donated_buffer_inplace_gpt\" %}                 # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_linear_dynamic_maxautotune_cuda\" %}            # [linux and cuda_compiler_version != \"None\"]\n        # skip some very long-running groups of tests (~30 minutes total)\n        {% set skips = skips ~ \" or (test_gradgrad_nn_Transformer and _cuda_)\" %}       # [linux and cuda_compiler_version != \"None\"]\n        {% set skips = skips ~ \" or test_avg_pool3d_backward2\" %}                       # [linux and cuda_compiler_version != \"None\"]\n        # MKL problems\n        {% set skips = skips ~ \" or (TestLinalgCPU and test_inverse_errors_large_cpu)\" %}   # [linux and blas_impl == \"mkl\" and cuda_compiler_version != \"None\"]\n        # non-MKL problems\n        {% set skips = skips ~ \" or test_gather_scatter_cpu or test_index_put2_cpu\" %}      # [linux and blas_impl != \"mkl\" and cuda_compiler_version != \"None\"]\n        # these tests are failing with low -n values\n        {% set skips = skips ~ \" or test_base_does_not_require_grad_mode_nothing\" %}    # [not win]\n        {% set skips = skips ~ \" or test_base_does_not_require_grad_mode_warn\" %}       # [not win]\n        {% set skips = skips ~ \" or test_composite_registered_to_cpu_mode_nothing\" %}   # [not win]\n        # these tests are failing on windows\n        {% set skips = skips ~ \" or (TestMkldnnCPU and test_batch_norm_2d_cpu)\" %}       # [win]\n        # flaky test, fragile to GC behavior\n        {% set skips = skips ~ \" or (TestTorch and test_tensor_cycle_via_slots)\" %}\n        # unexpected success\n        {% set skips = skips ~ \" or test_forward_nn_Bilinear_mps_float16\" %}            # [osx and arm64]\n        # \"quantized engine NoQEngine is not supported\"\n        {% set skips = skips ~ \" or test_qengine\" %}                                    # [osx and arm64]\n        # flaky failure on osx\n        {% set skips = skips ~ \" or test_LayerNorm_numeric_mps\" %}                      # [osx and arm64]\n        # some warning-related failure, maybe it's broken by --disable-warnings?\n        {% set skips = skips ~ \" or test_cpp_warnings_have_python_context_cpu\" %}\n        {% set skips = skips ~ \" or test_cpp_warnings_have_python_context_cuda\" %}\n        # \"Attempt to trace generator\"\n        {% set skips = skips ~ \" or test_lite_regional_compile_flex_attention_cuda\" %}\n\n        # the whole test suite takes forever, but we should get a good enough coverage\n        # for potential packaging problems by running a fixed subset\n        - export OMP_NUM_THREADS=4  # [unix]\n        # reduced paralellism to avoid OOM for CUDA builds\n        {% set jobs = \"-n 2\" %}\n        {% set jobs = \"-n 1\" %}     # [linux64 and cuda_compiler_version != \"None\"]\n        # test only one python version on aarch because emulation is super-slow;\n        # disable hypothesis because it randomly yields health check errors\n\n        # the opengpu server has a card with sm_70, an architecture dropped by CUDA 13.0\n        {% if (cuda_compiler_version or \"0\").split(\".\")[0]|int < 13 %}\n        - pytest {{ jobs }} {{ tests }} -k \"not ({{ skips }})\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings    # [not aarch64 or py==312]\n        {% endif %}\n\n        # regression test for https://github.com/conda-forge/pytorch-cpu-feedstock/issues/329, where we picked up\n        # duplicate `.pyc` files due to newest py-ver (3.13) in the build environment not matching the one in host;\n        # obviously this test can only be done for other python versions.\n        - test ! -f $SP_DIR/functorch/__pycache__/__init__.cpython-313.pyc          # [py!=313 and unix]\n        - if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1   # [py!=313 and win]\n\n        # test integrity of CMake metadata and ensure that THPLayoutType is visible as a symbol from libtorch_python\n        - cd cmake_test\n        - mkdir build build2\n        - cd build\n        - cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON $CMAKE_ARGS ..   # [unix]\n        - cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON %CMAKE_ARGS% ..  # [win]\n        - cmake --build .                   # [unix]\n        - cmake --build . --config Release  # [win]\n        - cd ../build2\n        # regression test for https://github.com/conda-forge/pytorch-cpu-feedstock/issues/479\n        - cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=$SP_DIR/torch/share/cmake/Torch $CMAKE_ARGS ..    # [unix]\n        - cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=%SP_DIR%/torch/share/cmake/Torch %CMAKE_ARGS% ..  # [win]\n        - cmake --build .                   # [unix]\n        - cmake --build . --config Release  # [win]\n\n  - name: pytorch-cpu   # [cuda_compiler_version == \"None\"]\n  - name: pytorch-gpu   # [cuda_compiler_version != \"None\"]\n    build:\n      string: cuda{{ cuda_compiler_version | replace('.', '') }}_{{ blas_impl }}_h{{ PKG_HASH }}_{{ build }}    # [cuda_compiler_version != \"None\"]\n      string: cpu_{{ blas_impl }}_h{{ PKG_HASH }}_{{ build }}                                                   # [cuda_compiler_version == \"None\"]\n      detect_binary_files_with_prefix: false\n    requirements:\n      run:\n        - pytorch {{ version }} cuda*_{{ blas_impl }}*{{ build }}   # [cuda_compiler_version != \"None\"]\n        - pytorch {{ version }} cpu_{{ blas_impl }}*{{ build }}     # [cuda_compiler_version == \"None\"]\n    test:\n      imports:\n        - torch\n\nabout:\n  home: https://pytorch.org/\n  dev_url: https://github.com/pytorch/pytorch\n  license: BSD-3-Clause\n  license_family: BSD\n  license_file:\n    - LICENSE\n    - NOTICE\n    - third_party/CMake/Copyright.txt\n  summary: PyTorch is an optimized tensor library for deep learning using GPUs and CPUs.\n  description: |\n    PyTorch is a Python package that provides two high-level features:\n      - Tensor computation (like NumPy) with strong GPU acceleration\n      - Deep neural networks built on a tape-based autograd system\n    You can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n  doc_url: https://pytorch.org/docs/\n\nextra:\n  recipe-maintainers:\n    - baszalmstra\n    - benjaminrwilson\n    - beckermr\n    - h-vetinari\n    - hmaarrfk\n    - jeongseok-meta\n    - mgorny\n    - sodre\n    - Tobias-Fischer\n  feedstock-name: pytorch-cpu\n",
  "req": {
    "__set__": true,
    "elements": [
      "__cuda",
      "c_compiler_stub",
      "c_stdlib_stub",
      "cmake",
      "cuda-cudart-dev",
      "cuda-cupti-dev",
      "cuda-driver-dev",
      "cuda-nvml-dev",
      "cuda-nvrtc-dev",
      "cuda-nvtx-dev",
      "cuda-profiler-api",
      "cuda-version",
      "cuda_compiler_stub",
      "cusparselt",
      "cxx_compiler_stub",
      "eigen",
      "filelock",
      "fmt",
      "fsspec",
      "grep",
      "jinja2",
      "libabseil",
      "libblas",
      "libcblas",
      "libcublas-dev",
      "libcudnn-dev",
      "libcudss-dev",
      "libcufft-dev",
      "libcufile-dev",
      "libcurand-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "liblapack",
      "libmagma-devel",
      "libprotobuf",
      "libtorch",
      "libuv",
      "llvm-openmp",
      "magma",
      "make",
      "mkl-devel",
      "nccl",
      "networkx",
      "ninja",
      "nomkl",
      "numpy",
      "nvtx-c",
      "optree",
      "packaging",
      "pip",
      "pkg-config",
      "protobuf",
      "pybind11",
      "pybind11-abi",
      "python",
      "pytorch",
      "pyyaml",
      "requests",
      "rsync",
      "sccache",
      "setuptools",
      "six",
      "sleef",
      "sympy",
      "triton",
      "typing_extensions",
      "zlib"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cmake",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "grep",
        "libprotobuf",
        "libuv",
        "llvm-openmp",
        "make",
        "ninja",
        "protobuf",
        "python",
        "rsync",
        "sccache"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cuda-cudart-dev",
        "cuda-cupti-dev",
        "cuda-driver-dev",
        "cuda-nvml-dev",
        "cuda-nvrtc-dev",
        "cuda-nvtx-dev",
        "cuda-profiler-api",
        "cuda-version",
        "cuda_compiler_stub",
        "cusparselt",
        "cxx_compiler_stub",
        "eigen",
        "fmt",
        "libabseil",
        "libblas",
        "libcblas",
        "libcublas-dev",
        "libcudnn-dev",
        "libcudss-dev",
        "libcufft-dev",
        "libcufile-dev",
        "libcurand-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "liblapack",
        "libmagma-devel",
        "libprotobuf",
        "libtorch",
        "libuv",
        "llvm-openmp",
        "magma",
        "mkl-devel",
        "nccl",
        "numpy",
        "nvtx-c",
        "openmp",
        "packaging",
        "pip",
        "pkg-config",
        "pybind11",
        "pybind11-abi",
        "python",
        "pyyaml",
        "requests",
        "setuptools",
        "six",
        "sleef",
        "typing_extensions",
        "zlib"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "__cuda",
        "c_compiler_stub",
        "c_stdlib_stub",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "filelock",
        "fsspec",
        "jinja2",
        "libblas",
        "libtorch",
        "llvm-openmp",
        "networkx",
        "nomkl",
        "openmp",
        "optree",
        "pybind11",
        "python",
        "pytorch",
        "setuptools",
        "sympy",
        "triton",
        "typing_extensions"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "boto3",
        "c_compiler_stub",
        "cmake",
        "cuda-nvrtc-dev",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "expecttest",
        "hypothesis",
        "ninja",
        "nvtx-c",
        "pip",
        "pkg-config",
        "pybind11",
        "pydot",
        "pytest",
        "pytest-flakefinder",
        "pytest-rerunfailures",
        "pytest-timeout",
        "pytest-xdist",
        "pyyaml",
        "tabulate",
        "xmlrunner"
      ]
    }
  },
  "strong_exports": false,
  "time": 1568135301.1552057,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cmake",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "grep",
        "libprotobuf",
        "libuv",
        "llvm-openmp",
        "make",
        "ninja",
        "protobuf",
        "python",
        "rsync",
        "sccache"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cuda-cudart-dev",
        "cuda-cupti-dev",
        "cuda-driver-dev",
        "cuda-nvml-dev",
        "cuda-nvrtc-dev",
        "cuda-nvtx-dev",
        "cuda-profiler-api",
        "cuda-version 12.8",
        "cuda-version 12.9",
        "cuda-version 13.0",
        "cusparselt",
        "eigen",
        "fmt",
        "libabseil",
        "libblas",
        "libcblas",
        "libcblas * *_mkl",
        "libcublas-dev",
        "libcudnn-dev",
        "libcudss-dev",
        "libcufft-dev",
        "libcufile-dev",
        "libcurand-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "liblapack",
        "libmagma-devel",
        "libprotobuf",
        "libtorch",
        "libuv",
        "llvm-openmp",
        "magma",
        "mkl-devel",
        "nccl",
        "numpy",
        "numpy *",
        "nvtx-c",
        "packaging",
        "pip",
        "pkg-config",
        "pybind11",
        "pybind11-abi",
        "python",
        "python 3.12",
        "pyyaml",
        "requests",
        "setuptools",
        "six",
        "sleef",
        "typing_extensions",
        "zlib"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "__cuda",
        "filelock",
        "fsspec",
        "jinja2",
        "libblas * *mkl",
        "libtorch",
        "llvm-openmp",
        "networkx",
        "nomkl",
        "optree >=0.13.0",
        "pybind11",
        "python",
        "pytorch 2.10.0 cpu_generic*1",
        "pytorch 2.10.0 cpu_generic_py314*1",
        "pytorch 2.10.0 cpu_mkl*101",
        "pytorch 2.10.0 cpu_mkl_py314*101",
        "pytorch 2.10.0 cuda*_generic*201",
        "pytorch 2.10.0 cuda*_generic_py314*201",
        "pytorch 2.10.0 cuda*_mkl*301",
        "pytorch 2.10.0 cuda*_mkl_py314*301",
        "setuptools",
        "sympy >=1.13.3",
        "triton ==3.6.0",
        "typing_extensions >=4.10.0"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "boto3",
        "c_compiler_stub",
        "cmake",
        "cuda-nvrtc-dev",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "expecttest",
        "hypothesis",
        "ninja",
        "nvtx-c",
        "pip",
        "pkg-config",
        "pybind11",
        "pydot",
        "pytest <9",
        "pytest-flakefinder",
        "pytest-rerunfailures",
        "pytest-timeout",
        "pytest-xdist",
        "pyyaml",
        "tabulate",
        "xmlrunner"
      ]
    }
  },
  "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz",
  "version": "2.10.0",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/pytorch-cpu.json"
  },
  "win_64_meta_yaml": {
    "about": {
      "description": "PyTorch is a Python package that provides two high-level features:\n  - Tensor computation (like NumPy) with strong GPU acceleration\n  - Deep neural networks built on a tape-based autograd system\nYou can reuse your favorite Python packages such as NumPy, SciPy, and Cython to extend PyTorch when needed.\n",
      "dev_url": "https://github.com/pytorch/pytorch",
      "doc_url": "https://pytorch.org/docs/",
      "home": "https://pytorch.org/",
      "license": "BSD-3-Clause",
      "license_family": "BSD",
      "license_file": [
        "LICENSE",
        "NOTICE",
        "third_party/CMake/Copyright.txt"
      ],
      "summary": "PyTorch is an optimized tensor library for deep learning using GPUs and CPUs."
    },
    "build": {
      "detect_binary_files_with_prefix": false,
      "ignore_run_exports": [
        "python *",
        "numpy *",
        "libmagma_sparse"
      ],
      "ignore_run_exports_from": [
        "python *",
        "numpy *"
      ],
      "missing_dso_whitelist": [
        "*/nvcuda.dll"
      ],
      "number": "101",
      "run_exports": [
        "libtorch"
      ],
      "string": "cpu_mkl_h1234567_101"
    },
    "extra": {
      "feedstock-name": "pytorch-cpu",
      "recipe-maintainers": [
        "baszalmstra",
        "benjaminrwilson",
        "beckermr",
        "h-vetinari",
        "hmaarrfk",
        "jeongseok-meta",
        "mgorny",
        "sodre",
        "Tobias-Fischer"
      ]
    },
    "outputs": [
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda128_mkl_py314_h1234567_301"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "sccache"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 12.8",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "magma",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "bld.bat"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda128_mkl_py314_h1234567_301"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_mkl_py314*301"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\torch_python.lib exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\_C.lib exit 1",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON %CMAKE_ARGS% ..",
            "cmake --build . --config Release",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=%SP_DIR%/torch/share/cmake/Torch %CMAKE_ARGS% .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda128_mkl_h1234567_301"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_mkl*301"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cuda130_mkl_py314_h1234567_301"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "sccache"
          ],
          "host": [
            "libtorch",
            "cuda-cudart-dev",
            "cuda-cupti-dev",
            "cuda-nvml-dev",
            "cuda-nvrtc-dev",
            "cuda-nvtx-dev",
            "cuda-profiler-api",
            "cuda-version 13.0",
            "cusparselt",
            "libcublas-dev",
            "libcudnn-dev",
            "libcudss-dev",
            "libcufft-dev",
            "libcurand-dev",
            "libcusolver-dev",
            "libcusparse-dev",
            "libmagma-devel",
            "nvtx-c",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "__cuda",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-gpu 2.10.0",
            "pytorch-cpu <0.0a0"
          ]
        },
        "script": "bld.bat"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_mkl_py314_h1234567_301"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cuda*_mkl_py314*301"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "python -c \"import torch; assert torch.backends.cuda.is_built()\"",
            "python -c \"import torch; assert torch.backends.cudnn.is_available()\"",
            "python -c \"import torch; assert torch.backends.cudnn.enabled\"",
            "python -c \"import torch; assert torch.version.cuda is not None\"",
            "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\torch_python.lib exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\_C.lib exit 1",
            "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON %CMAKE_ARGS% ..",
            "cmake --build . --config Release",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=%SP_DIR%/torch/share/cmake/Torch %CMAKE_ARGS% .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cuda_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "cuda-nvrtc-dev",
            "nvtx-c",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cuda130_mkl_h1234567_301"
        },
        "name": "pytorch-gpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cuda*_mkl*301"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      },
      {
        "name": "libtorch"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "ignore_run_exports": [
            "libmagma_sparse"
          ],
          "run_exports": [
            "pytorch",
            "libtorch"
          ],
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch",
        "requirements": {
          "build": [
            "python",
            "c_stdlib_stub",
            "c_compiler_stub",
            "cxx_compiler_stub",
            "cmake",
            "ninja",
            "libprotobuf",
            "protobuf",
            "sccache"
          ],
          "host": [
            "libtorch",
            "python",
            "numpy",
            "pip",
            "setuptools",
            "pyyaml",
            "requests",
            "six",
            "mkl-devel",
            "libcblas * *_mkl",
            "libabseil",
            "libprotobuf",
            "llvm-openmp",
            "pybind11",
            "pybind11-abi",
            "eigen",
            "sleef",
            "libuv",
            "typing_extensions",
            "zlib",
            "fmt",
            "packaging"
          ],
          "run": [
            "libtorch",
            "llvm-openmp",
            "libblas * *mkl",
            "python",
            "filelock",
            "fsspec",
            "jinja2",
            "networkx",
            "optree >=0.13.0",
            "pybind11",
            "setuptools",
            "sympy >=1.13.3",
            "typing_extensions >=4.10.0"
          ],
          "run_constrained": [
            "pytorch-cpu 2.10.0",
            "pytorch-gpu <0.0a0"
          ]
        },
        "script": "bld.bat"
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_py314_h1234567_101"
        },
        "name": "pytorch-tests",
        "requirements": {
          "host": [
            "python"
          ],
          "run": [
            "pytorch 2.10.0 cpu_mkl_py314*101"
          ]
        },
        "test": {
          "commands": [
            "pip check",
            "python -c \"import torch; print(torch.__version__)\"",
            "python -c \"import torch; assert torch.backends.mkldnn.m.is_available()\"",
            "python -c \"import torch; torch.tensor(1).to('cpu').numpy(); print('numpy support enabled!!!')\"",
            "python -c \"import torch; import numpy\"",
            "python -c \"import numpy; import torch\"",
            "python -c \"import numpy as np;import torch;x = torch.tensor([2], dtype=torch.complex128);res = torch.dot(x, x); assert res.real == 4.0, res\"",
            "if not exist %LIBRARY_BIN%\\torch_python.dll exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\torch_python.lib exit 1",
            "if not exist %SP_DIR%\\torch\\lib\\_C.lib exit 1",
            "pytest -n 1 test/test_autograd.py test/test_autograd_fallback.py test/test_custom_ops.py test/test_linalg.py test/test_mkldnn.py test/test_modules.py test/test_nn.py test/test_torch.py test/test_xnnpack_integration.py test/inductor/test_torchinductor.py -k \"not ((TestTorch and test_print) or test_1_sized_with_0_strided_cpu_float32 or test_batchnorm_nhwc_cpu or test_layer_norm_backwards_eps or test_pynode_destruction_deadlock or (TestLinalgCPU and test_cholesky_cpu_float32) or (TestLinalgCPU and test_pca_lowrank_cpu) or (TestLinalgCPU and test_svd_lowrank_cpu) or (TestMkldnnCPU and test_lstm_cpu) or test_eigh_lwork_lapack or test_gradgrad_nn_LSTM or test_grad_nn_Transformer or test_inverse_errors_large or (TestXNNPACKConv1dTransformPass and test_conv1d_basic) or test_addbmm or test_baddbmm or test_bmm or illcondition_matrix_input_should_not_crash_cpu or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or (TestNN and test_upsampling_bfloat16) or test_terminate_handler_on_crash or (TestAutograd and test_profiler_seq_nr) or (TestAutograd and test_profiler_propagation) or test_mutable_custom_op_fixed_layout or test_BCELoss_weights_no_reduce_cuda or test_ctc_loss_cudnn_tensor_cuda or (TestTorch and test_index_add_correctness) or test_sdpa_inference_mode_aot_compile or (TestNN and test_grid_sample) or test_cublas_config_nondeterministic_alert_cuda or test_cross_entropy_loss_2d_out_of_bounds_class or test_indirect_device_assert or test_reentrant_parent_error_on_cpu_cuda or (GPUTests and test_scatter_reduce2) or test_ck_blas_library_cpu or test_matmul_offline_tunableop_cuda_float16 or test_Conv3d_1x1x1_no_bias_cuda or test_isinf_cuda or test_donated_buffer_inplace_gpt or test_linear_dynamic_maxautotune_cuda or (test_gradgrad_nn_Transformer and _cuda_) or test_avg_pool3d_backward2 or (TestLinalgCPU and test_inverse_errors_large_cpu) or test_gather_scatter_cpu or test_index_put2_cpu or test_base_does_not_require_grad_mode_nothing or test_base_does_not_require_grad_mode_warn or test_composite_registered_to_cpu_mode_nothing or (TestMkldnnCPU and test_batch_norm_2d_cpu) or (TestTorch and test_tensor_cycle_via_slots) or test_forward_nn_Bilinear_mps_float16 or test_qengine or test_LayerNorm_numeric_mps or test_cpp_warnings_have_python_context_cpu or test_cpp_warnings_have_python_context_cuda or test_lite_regional_compile_flex_attention_cuda)\" -m \"not hypothesis\" --durations=50 --timeout=1200 --disable-warnings",
            "if exist %SP_DIR%\\functorch\\__pycache__\\__init__.cpython-313.pyc exit 1",
            "cd cmake_test",
            "mkdir build build2",
            "cd build",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON %CMAKE_ARGS% ..",
            "cmake --build . --config Release",
            "cd ../build2",
            "cmake -GNinja -DCMAKE_CXX_STANDARD=17 -DWITH_TORCH_PYTHON=ON -DTorch_DIR=%SP_DIR%/torch/share/cmake/Torch %CMAKE_ARGS% .."
          ],
          "files": [
            "cmake_test/"
          ],
          "imports": [
            "torch",
            "torch._C"
          ],
          "requires": [
            "c_compiler_stub",
            "cxx_compiler_stub",
            "ninja",
            "boto3",
            "hypothesis",
            "pytest <9",
            "tabulate",
            "pydot",
            "pip",
            "expecttest",
            "xmlrunner",
            "pyyaml",
            "pytest-flakefinder",
            "pytest-rerunfailures",
            "pytest-xdist",
            "cmake",
            "pybind11",
            "pytest-timeout"
          ],
          "source_files": [
            "test",
            "tools"
          ]
        }
      },
      {
        "build": {
          "detect_binary_files_with_prefix": false,
          "string": "cpu_mkl_h1234567_101"
        },
        "name": "pytorch-cpu",
        "requirements": {
          "run": [
            "pytorch 2.10.0 cpu_mkl*101"
          ]
        },
        "test": {
          "imports": [
            "torch"
          ]
        }
      }
    ],
    "package": {
      "name": "libtorch",
      "version": "2.10.0"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "libuv",
        "llvm-openmp",
        "cmake",
        "ninja",
        "libprotobuf",
        "protobuf",
        "sccache"
      ],
      "host": [
        "cuda-cudart-dev",
        "cuda-cupti-dev",
        "cuda-nvml-dev",
        "cuda-nvrtc-dev",
        "cuda-nvtx-dev",
        "cuda-profiler-api",
        "cuda-version 12.8",
        "cusparselt",
        "libcublas-dev",
        "libcudnn-dev",
        "libcudss-dev",
        "libcufft-dev",
        "libcurand-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "magma",
        "nvtx-c",
        "python 3.12",
        "numpy *",
        "pip",
        "setuptools",
        "pyyaml",
        "requests",
        "six",
        "mkl-devel",
        "libcblas * *_mkl",
        "libabseil",
        "libprotobuf",
        "llvm-openmp",
        "sleef",
        "libuv",
        "typing_extensions",
        "pybind11",
        "pybind11-abi",
        "eigen",
        "zlib",
        "fmt",
        "packaging",
        "cuda-version 13.0",
        "libmagma-devel"
      ],
      "run": [
        "libblas * *mkl"
      ],
      "run_constrained": [
        "pytorch-gpu 2.10.0",
        "pytorch-cpu <0.0a0",
        "pytorch 2.10.0 cuda128_mkl_*_301",
        "pytorch 2.10.0 cuda130_mkl_*_301",
        "pytorch-cpu 2.10.0",
        "pytorch-gpu <0.0a0",
        "pytorch 2.10.0 cpu_mkl_*_101"
      ]
    },
    "schema_version": 0,
    "source": [
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0008-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0008-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      },
      {
        "patches": [
          "patches/0001-Force-usage-of-python-3-and-error-without-numpy.patch",
          "patches/0002-Allow-overriding-CUDA-related-paths.patch",
          "patches/0003-Use-BLAS_USE_CBLAS_DOT-for-OpenBLAS-builds.patch",
          "patches/0004-Fix-FindOpenBLAS.patch",
          "patches/0005-point-include-paths-to-Conda-prefix-include-dir.patch",
          "patches/0006-Add-conda-prefix-to-inductor-include-lib-paths.patch",
          "patches/0007-make-ATEN_INCLUDE_DIR-relative-to-TORCH_INSTALL_PREF.patch",
          "patches/0008-remove-DESTINATION-lib-from-CMake-install-TARGETS-di.patch",
          "patches/0009-avoid-deprecated-find_package-CUDA-in-caffe2-CMake-m.patch",
          "patches/0010-skip-test_norm_matrix_degenerate_shapes-on-numpy-2.3.patch",
          "patches/0011-Define-PY_SSIZE_T_CLEAN-before-include-Python.h.patch",
          "patches/0012-Add-USE_SYSTEM-options-for-KLEIDI-CUDNN_FRONTEND-CUT.patch",
          "patches/0013-Fix-building-kineto-against-system-fmt.patch",
          "patches/0014-Attempt-to-fix-torch.backends.cudnn.rnn-import.patch",
          "patches/0015-Use-Intel-LLVM-openmp.patch",
          "patches/0016-Fix-TorchConfig.cmake.in-to-account-for-different-in.patch",
          "patches_submodules/tensorpipe/0001-switch-away-from-find_package-CUDA.patch"
        ],
        "sha256": "fa8ccbe87f83f48735505371c1c313b4aa6db400b0ae4f8a02844d1e150c695f",
        "url": "https://github.com/pytorch/pytorch/releases/download/v2.10.0/pytorch-v2.10.0.tar.gz"
      }
    ],
    "test": {
      "commands": [
        "if not exist %LIBRARY_BIN%\\c10.dll exit 1",
        "if not exist %LIBRARY_LIB%\\c10.lib exit 1",
        "if not exist %LIBRARY_BIN%\\shm.dll exit 1",
        "if not exist %LIBRARY_LIB%\\shm.lib exit 1",
        "if not exist %LIBRARY_BIN%\\torch.dll exit 1",
        "if not exist %LIBRARY_LIB%\\torch.lib exit 1",
        "if not exist %LIBRARY_BIN%\\torch_cpu.dll exit 1",
        "if not exist %LIBRARY_LIB%\\torch_cpu.lib exit 1",
        "if not exist %LIBRARY_BIN%\\torch_global_deps.dll exit 1",
        "if not exist %LIBRARY_BIN%\\c10_cuda.dll exit 1",
        "if not exist %LIBRARY_LIB%\\c10_cuda.lib exit 1",
        "if not exist %LIBRARY_BIN%\\caffe2_nvrtc.dll exit 1",
        "if not exist %LIBRARY_LIB%\\caffe2_nvrtc.lib exit 1",
        "if not exist %LIBRARY_BIN%\\torch_cuda.dll exit 1",
        "if not exist %LIBRARY_LIB%\\torch_cuda.lib exit 1",
        "if not exist %LIBRARY_PREFIX%\\share\\cmake\\Torch\\TorchConfig.cmake exit 1",
        "cd cmake_test",
        "cmake -GNinja -DCMAKE_CXX_STANDARD=17 %CMAKE_ARGS% ."
      ],
      "files": [
        "cmake_test/"
      ],
      "requires": [
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "cuda-nvrtc-dev",
        "nvtx-c",
        "cmake",
        "ninja",
        "pkg-config"
      ]
    }
  },
  "win_64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cmake",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "libprotobuf",
        "libuv",
        "llvm-openmp",
        "ninja",
        "protobuf",
        "python",
        "sccache"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cuda-cudart-dev",
        "cuda-cupti-dev",
        "cuda-nvml-dev",
        "cuda-nvrtc-dev",
        "cuda-nvtx-dev",
        "cuda-profiler-api",
        "cuda-version",
        "cusparselt",
        "eigen",
        "fmt",
        "libabseil",
        "libcblas",
        "libcublas-dev",
        "libcudnn-dev",
        "libcudss-dev",
        "libcufft-dev",
        "libcurand-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "libmagma-devel",
        "libprotobuf",
        "libtorch",
        "libuv",
        "llvm-openmp",
        "magma",
        "mkl-devel",
        "numpy",
        "nvtx-c",
        "packaging",
        "pip",
        "pybind11",
        "pybind11-abi",
        "python",
        "pyyaml",
        "requests",
        "setuptools",
        "six",
        "sleef",
        "typing_extensions",
        "zlib"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "__cuda",
        "filelock",
        "fsspec",
        "jinja2",
        "libblas",
        "libtorch",
        "llvm-openmp",
        "networkx",
        "optree",
        "pybind11",
        "python",
        "pytorch",
        "setuptools",
        "sympy",
        "typing_extensions"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "boto3",
        "c_compiler_stub",
        "cmake",
        "cuda-nvrtc-dev",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "expecttest",
        "hypothesis",
        "ninja",
        "nvtx-c",
        "pip",
        "pkg-config",
        "pybind11",
        "pydot",
        "pytest",
        "pytest-flakefinder",
        "pytest-rerunfailures",
        "pytest-timeout",
        "pytest-xdist",
        "pyyaml",
        "tabulate",
        "xmlrunner"
      ]
    }
  }
}