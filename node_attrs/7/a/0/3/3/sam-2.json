{
  "archived": false,
  "branch": "main",
  "ci_support_linux_64_cuda_compiler_version12.9python3.10.____cpython.yaml": "c_compiler:\n- gcc\nc_compiler_version:\n- '14'\nc_stdlib:\n- sysroot\nc_stdlib_version:\n- '2.17'\nchannel_sources:\n- conda-forge\nchannel_targets:\n- conda-forge main\ncuda_compiler:\n- cuda-nvcc\ncuda_compiler_version:\n- '12.9'\ncxx_compiler:\n- gxx\ncxx_compiler_version:\n- '14'\ndocker_image:\n- quay.io/condaforge/linux-anvil-x86_64:alma9\npin_run_as_build:\n  python:\n    min_pin: x.x\n    max_pin: x.x\npython:\n- 3.10.* *_cpython\npytorch:\n- '2.10'\ntarget_platform:\n- linux-64\nzip_keys:\n- - c_compiler_version\n  - cxx_compiler_version\n  - c_stdlib_version\n  - cuda_compiler_version\n",
  "conda-forge.yml": {
    "azure": {
      "free_disk_space": true,
      "settings_win": {
        "variables": {
          "CONDA_BLD_PATH": "C:\\bld\\",
          "MINIFORGE_HOME": "C:\\bld\\"
        }
      }
    },
    "build_platform": {
      "linux_aarch64": "linux_64",
      "osx_arm64": "osx_64"
    },
    "conda_build": {
      "error_overlinking": true
    },
    "conda_forge_output_validation": true,
    "github": {
      "branch_name": "main",
      "tooling_branch_name": "main"
    },
    "test": "native_and_emulated"
  },
  "feedstock_hash": "97d706578cd4d999d4b0feb045f38ef02cf56250",
  "feedstock_hash_ts": 1769863441,
  "feedstock_name": "sam-2",
  "hash_type": "sha256",
  "linux_64_meta_yaml": {
    "about": {
      "description": "Segment Anything Model 2 (SAM 2) is a foundation model towards solving\npromptable visual segmentation in images and videos. We extend SAM to video\nby considering images as a video with a single frame. The model design is a\nsimple transformer architecture with streaming memory for real-time video\nprocessing. We build a model-in-the-loop data engine, which improves model\nand data via user interaction, to collect our SA-V dataset, the largest\nvideo segmentation dataset to date. SAM 2 trained on our data provides\nstrong performance across a wide range of tasks and visual domains.\n",
      "home": "https://github.com/facebookresearch/segment-anything-2",
      "license": "Apache-2.0",
      "license_family": "Apache",
      "license_file": "LICENSE",
      "summary": "SAM 2: Segment Anything in Images and Videos"
    },
    "build": {
      "number": "303",
      "script": [
        "export export TORCH_CUDA_ARCH_LIST=\"5.0;6.0;7.0;7.5;8.0;8.6;8.9;9.0;10.0;12.0+PTX\"",
        "export CUDA_TOOLKIT_ROOT_DIR=\"${PREFIX}\"",
        "export SAM2_BUILD_ALLOW_ERRORS=0",
        "export FORCE_CUDA=1",
        "python -m pip install . -vv"
      ],
      "string": "cpu_py314h1234567_3"
    },
    "extra": {
      "recipe-maintainers": [
        "hmaarrfk"
      ]
    },
    "package": {
      "name": "sam-2",
      "version": "1.0.0.20241215"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "ninja"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "pytorch",
        "libtorch *=cuda*",
        "libcublas-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "cuda-cudart-dev",
        "cuda-version 12.9",
        "libtorch *=cpu*"
      ],
      "run": [
        "python",
        "hydra-core >=1.3.2",
        "pytorch",
        "libtorch *=cuda*",
        "torchvision >=0.20.1",
        "iopath >=0.1.10",
        "tqdm",
        "pillow >=9.4.0",
        "__cuda",
        "libtorch *=cpu*",
        "scikit-image"
      ],
      "run_constrained": [
        "pytorch >=2.3.1",
        "sam2 >=1.0.0"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "216_be_compatible_with_cpu_only.patch"
      ],
      "sha256": "1f2fbfad3ffa38110368abac76c6ef9df9c282a66d5c2807bc94abf4d2fb30f8",
      "url": "https://github.com/facebookresearch/segment-anything-2/archive/2b90b9f5ceec907a1c18123530e92e794ad901a4.tar.gz"
    },
    "test": {
      "commands": [
        "pip check",
        "test -f ${SP_DIR}/sam2/_C.so"
      ],
      "imports": [
        "sam2"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "linux_64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "ninja"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cuda-cudart-dev",
        "cuda-version",
        "libcublas-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "libtorch",
        "pip",
        "python",
        "pytorch",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "__cuda",
        "hydra-core",
        "iopath",
        "libtorch",
        "pillow",
        "python",
        "pytorch",
        "scikit-image",
        "torchvision",
        "tqdm"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "linux_aarch64_meta_yaml": {
    "about": {
      "description": "Segment Anything Model 2 (SAM 2) is a foundation model towards solving\npromptable visual segmentation in images and videos. We extend SAM to video\nby considering images as a video with a single frame. The model design is a\nsimple transformer architecture with streaming memory for real-time video\nprocessing. We build a model-in-the-loop data engine, which improves model\nand data via user interaction, to collect our SA-V dataset, the largest\nvideo segmentation dataset to date. SAM 2 trained on our data provides\nstrong performance across a wide range of tasks and visual domains.\n",
      "home": "https://github.com/facebookresearch/segment-anything-2",
      "license": "Apache-2.0",
      "license_family": "Apache",
      "license_file": "LICENSE",
      "summary": "SAM 2: Segment Anything in Images and Videos"
    },
    "build": {
      "number": "303",
      "script": [
        "export export TORCH_CUDA_ARCH_LIST=\"5.0;6.0;7.0;7.5;8.0;8.6;8.9;9.0;10.0;12.0+PTX\"",
        "export CUDA_TOOLKIT_ROOT_DIR=\"${PREFIX}\"",
        "export SAM2_BUILD_ALLOW_ERRORS=0",
        "export FORCE_CUDA=1",
        "python -m pip install . -vv"
      ],
      "string": "cpu_py314h1234567_3"
    },
    "extra": {
      "recipe-maintainers": [
        "hmaarrfk"
      ]
    },
    "package": {
      "name": "sam-2",
      "version": "1.0.0.20241215"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "ninja"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "pytorch",
        "libtorch *=cuda*",
        "libcublas-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "cuda-cudart-dev",
        "cuda-version 12.9",
        "libtorch *=cpu*"
      ],
      "run": [
        "python",
        "hydra-core >=1.3.2",
        "pytorch",
        "libtorch *=cuda*",
        "torchvision >=0.20.1",
        "iopath >=0.1.10",
        "tqdm",
        "pillow >=9.4.0",
        "__cuda",
        "libtorch *=cpu*",
        "scikit-image"
      ],
      "run_constrained": [
        "pytorch >=2.3.1",
        "sam2 >=1.0.0"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "216_be_compatible_with_cpu_only.patch"
      ],
      "sha256": "1f2fbfad3ffa38110368abac76c6ef9df9c282a66d5c2807bc94abf4d2fb30f8",
      "url": "https://github.com/facebookresearch/segment-anything-2/archive/2b90b9f5ceec907a1c18123530e92e794ad901a4.tar.gz"
    },
    "test": {
      "commands": [
        "pip check",
        "test -f ${SP_DIR}/sam2/_C.so"
      ],
      "imports": [
        "sam2"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "linux_aarch64_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "ninja"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cuda-cudart-dev",
        "cuda-version",
        "libcublas-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "libtorch",
        "pip",
        "python",
        "pytorch",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "__cuda",
        "hydra-core",
        "iopath",
        "libtorch",
        "pillow",
        "python",
        "pytorch",
        "scikit-image",
        "torchvision",
        "tqdm"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "meta_yaml": {
    "about": {
      "description": "Segment Anything Model 2 (SAM 2) is a foundation model towards solving\npromptable visual segmentation in images and videos. We extend SAM to video\nby considering images as a video with a single frame. The model design is a\nsimple transformer architecture with streaming memory for real-time video\nprocessing. We build a model-in-the-loop data engine, which improves model\nand data via user interaction, to collect our SA-V dataset, the largest\nvideo segmentation dataset to date. SAM 2 trained on our data provides\nstrong performance across a wide range of tasks and visual domains.\n",
      "home": "https://github.com/facebookresearch/segment-anything-2",
      "license": "Apache-2.0",
      "license_family": "Apache",
      "license_file": "LICENSE",
      "summary": "SAM 2: Segment Anything in Images and Videos"
    },
    "build": {
      "number": "303",
      "script": [
        "export export TORCH_CUDA_ARCH_LIST=\"5.0;6.0;7.0;7.5;8.0;8.6;8.9;9.0;10.0;12.0+PTX\"",
        "export CUDA_TOOLKIT_ROOT_DIR=\"${PREFIX}\"",
        "export SAM2_BUILD_ALLOW_ERRORS=0",
        "export FORCE_CUDA=1",
        "python -m pip install . -vv"
      ],
      "string": "cpu_py314h1234567_3"
    },
    "extra": {
      "recipe-maintainers": [
        "hmaarrfk"
      ]
    },
    "package": {
      "name": "sam-2",
      "version": "1.0.0.20241215"
    },
    "requirements": {
      "build": [
        "c_stdlib_stub",
        "c_compiler_stub",
        "cxx_compiler_stub",
        "cuda_compiler_stub",
        "ninja"
      ],
      "host": [
        "python",
        "pip",
        "setuptools",
        "pytorch",
        "libtorch *=cuda*",
        "libcublas-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "cuda-cudart-dev",
        "cuda-version 12.9",
        "libtorch *=cpu*"
      ],
      "run": [
        "python",
        "hydra-core >=1.3.2",
        "pytorch",
        "libtorch *=cuda*",
        "torchvision >=0.20.1",
        "iopath >=0.1.10",
        "tqdm",
        "pillow >=9.4.0",
        "__cuda",
        "libtorch *=cpu*",
        "scikit-image"
      ],
      "run_constrained": [
        "pytorch >=2.3.1",
        "sam2 >=1.0.0"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "216_be_compatible_with_cpu_only.patch"
      ],
      "sha256": "1f2fbfad3ffa38110368abac76c6ef9df9c282a66d5c2807bc94abf4d2fb30f8",
      "url": "https://github.com/facebookresearch/segment-anything-2/archive/2b90b9f5ceec907a1c18123530e92e794ad901a4.tar.gz"
    },
    "test": {
      "commands": [
        "pip check",
        "test -f ${SP_DIR}/sam2/_C.so"
      ],
      "imports": [
        "sam2"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "name": "sam-2",
  "osx_64_meta_yaml": {
    "about": {
      "description": "Segment Anything Model 2 (SAM 2) is a foundation model towards solving\npromptable visual segmentation in images and videos. We extend SAM to video\nby considering images as a video with a single frame. The model design is a\nsimple transformer architecture with streaming memory for real-time video\nprocessing. We build a model-in-the-loop data engine, which improves model\nand data via user interaction, to collect our SA-V dataset, the largest\nvideo segmentation dataset to date. SAM 2 trained on our data provides\nstrong performance across a wide range of tasks and visual domains.\n",
      "home": "https://github.com/facebookresearch/segment-anything-2",
      "license": "Apache-2.0",
      "license_family": "Apache",
      "license_file": "LICENSE",
      "summary": "SAM 2: Segment Anything in Images and Videos"
    },
    "build": {
      "number": "303",
      "script": [
        "python -m pip install . -vv"
      ],
      "string": "cpu_py314h1234567_3"
    },
    "extra": {
      "recipe-maintainers": [
        "hmaarrfk"
      ]
    },
    "package": {
      "name": "sam-2",
      "version": "1.0.0.20241215"
    },
    "requirements": {
      "build": [],
      "host": [
        "python",
        "pip",
        "setuptools",
        "pytorch",
        "libtorch *=cpu*"
      ],
      "run": [
        "python",
        "hydra-core >=1.3.2",
        "pytorch",
        "libtorch *=cpu*",
        "torchvision >=0.20.1",
        "scikit-image",
        "iopath >=0.1.10",
        "tqdm",
        "pillow >=9.4.0"
      ],
      "run_constrained": [
        "pytorch >=2.3.1",
        "sam2 >=1.0.0"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "216_be_compatible_with_cpu_only.patch"
      ],
      "sha256": "1f2fbfad3ffa38110368abac76c6ef9df9c282a66d5c2807bc94abf4d2fb30f8",
      "url": "https://github.com/facebookresearch/segment-anything-2/archive/2b90b9f5ceec907a1c18123530e92e794ad901a4.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "sam2"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "osx_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "libtorch",
        "pip",
        "python",
        "pytorch",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "hydra-core",
        "iopath",
        "libtorch",
        "pillow",
        "python",
        "pytorch",
        "scikit-image",
        "torchvision",
        "tqdm"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "osx_arm64_meta_yaml": {
    "about": {
      "description": "Segment Anything Model 2 (SAM 2) is a foundation model towards solving\npromptable visual segmentation in images and videos. We extend SAM to video\nby considering images as a video with a single frame. The model design is a\nsimple transformer architecture with streaming memory for real-time video\nprocessing. We build a model-in-the-loop data engine, which improves model\nand data via user interaction, to collect our SA-V dataset, the largest\nvideo segmentation dataset to date. SAM 2 trained on our data provides\nstrong performance across a wide range of tasks and visual domains.\n",
      "home": "https://github.com/facebookresearch/segment-anything-2",
      "license": "Apache-2.0",
      "license_family": "Apache",
      "license_file": "LICENSE",
      "summary": "SAM 2: Segment Anything in Images and Videos"
    },
    "build": {
      "number": "303",
      "script": [
        "python -m pip install . -vv"
      ],
      "string": "cpu_py314h1234567_3"
    },
    "extra": {
      "recipe-maintainers": [
        "hmaarrfk"
      ]
    },
    "package": {
      "name": "sam-2",
      "version": "1.0.0.20241215"
    },
    "requirements": {
      "build": [],
      "host": [
        "python",
        "pip",
        "setuptools",
        "pytorch",
        "libtorch *=cpu*"
      ],
      "run": [
        "python",
        "hydra-core >=1.3.2",
        "pytorch",
        "libtorch *=cpu*",
        "torchvision >=0.20.1",
        "scikit-image",
        "iopath >=0.1.10",
        "tqdm",
        "pillow >=9.4.0"
      ],
      "run_constrained": [
        "pytorch >=2.3.1",
        "sam2 >=1.0.0"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "216_be_compatible_with_cpu_only.patch"
      ],
      "sha256": "1f2fbfad3ffa38110368abac76c6ef9df9c282a66d5c2807bc94abf4d2fb30f8",
      "url": "https://github.com/facebookresearch/segment-anything-2/archive/2b90b9f5ceec907a1c18123530e92e794ad901a4.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "sam2"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "osx_arm64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "libtorch",
        "pip",
        "python",
        "pytorch",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "hydra-core",
        "iopath",
        "libtorch",
        "pillow",
        "python",
        "pytorch",
        "scikit-image",
        "torchvision",
        "tqdm"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "outputs_names": {
    "__set__": true,
    "elements": [
      "sam-2"
    ]
  },
  "parsing_error": false,
  "platforms": [
    "linux_64",
    "linux_aarch64",
    "osx_64",
    "osx_arm64",
    "win_64"
  ],
  "pr_info": {
    "__lazy_json__": "pr_info/sam-2.json"
  },
  "raw_meta_yaml": "{% set git_hash_date = \"20241215\" %}\n{% set git_hash = \"2b90b9f5ceec907a1c18123530e92e794ad901a4\" %}\n# They claim version 1.0 but they don't really release anything on pypi\n# hmaarrfk -- 2024/12\n# I removed the hash from the version since the solver\n# would think they are beta / alpha versions.\n# I figure the date is enough.... maybe...\n{% set version = \"1.0.0.\" + git_hash_date %}\n\npackage:\n  # Their package name is \"SAM 2\" pip claims it is \"SAM-2\"\n  # the lower case is thus \"sam-2\"\n  name: sam-2\n  version: {{ version }}\n\nsource:\n  url: https://github.com/facebookresearch/segment-anything-2/archive/{{ git_hash }}.tar.gz\n  sha256: 1f2fbfad3ffa38110368abac76c6ef9df9c282a66d5c2807bc94abf4d2fb30f8\n  patches:\n    - 216_be_compatible_with_cpu_only.patch\n\n{% set build = 3 %}\n{% set build = build + 300 %}  # [cuda_compiler_version != \"None\"]\n\nbuild:\n  string: cpu_py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version == \"None\"]\n  string: cuda{{ cuda_compiler_version | replace('.', '') }}py{{ CONDA_PY }}h{{ PKG_HASH }}_{{ PKG_BUILDNUM }}  # [cuda_compiler_version != \"None\"]\n  script:\n    # Ensure to add PTX at the end, always\n    - set TORCH_CUDA_ARCH_LIST=5.0;6.0;7.0;7.5;8.0;8.6;8.9;9.0;10.0;12.0+PTX              # [cuda_compiler_version != \"None\" and win]\n    - set CUDA_TOOLKIT_ROOT_DIR=%PREFIX%                                                  # [cuda_compiler_version != \"None\" and win]\n    - export export TORCH_CUDA_ARCH_LIST=\"5.0;6.0;7.0;7.5;8.0;8.6;8.9;9.0;10.0;12.0+PTX\"  # [cuda_compiler_version != \"None\" and unix]\n    - export CUDA_TOOLKIT_ROOT_DIR=\"${PREFIX}\"                                            # [cuda_compiler_version != \"None\" and unix]\n    - set SAM2_BUILD_ALLOW_ERRORS=0                                                       # [cuda_compiler_version != \"None\" and win]\n    - set FORCE_CUDA=1                                                                    # [cuda_compiler_version != \"None\" and win]\n    - export SAM2_BUILD_ALLOW_ERRORS=0                                                    # [cuda_compiler_version != \"None\" and unix]\n    - export FORCE_CUDA=1                                                                 # [cuda_compiler_version != \"None\" and unix]\n    - python -m pip install . -vv\n  number: {{ build }}\n  # I'm (hmaarrfk) giving up on compiling for windows 2025/11\n  # https://github.com/conda-forge/pytorch-cpu-feedstock/issues/459\n  skip: true   # [cuda_compiler_version != \"None\" and win]\n\nrequirements:\n  build:\n    - python                                 # [build_platform != target_platform]\n    - cross-python_{{ target_platform }}     # [build_platform != target_platform]\n    - pytorch                                # [build_platform != target_platform]\n    - {{ stdlib('c') }}                      # [cuda_compiler_version != \"None\"]\n    - {{ compiler('c') }}                    # [cuda_compiler_version != \"None\"]\n    - {{ compiler('cxx') }}                  # [cuda_compiler_version != \"None\"]\n    - {{ compiler('cuda') }}                 # [cuda_compiler_version != \"None\"]\n    - ninja                                  # [cuda_compiler_version != \"None\"]\n    - libcublas-dev                          # [build_platform != target_platform and cuda_compiler_version != \"None\"]\n    - libcusolver-dev                        # [build_platform != target_platform and cuda_compiler_version != \"None\"]\n    - libcusparse-dev                        # [build_platform != target_platform and cuda_compiler_version != \"None\"]\n    - cuda-cudart-dev                        # [build_platform != target_platform and cuda_compiler_version != \"None\"]\n  host:\n    - python\n    - pip\n    - setuptools\n    - pytorch\n    - libtorch *=cpu*                        # [cuda_compiler_version == \"None\"]\n    - libtorch *=cuda*                       # [cuda_compiler_version != \"None\"]\n    - libcublas-dev                          # [cuda_compiler_version != \"None\"]\n    - libcusolver-dev                        # [cuda_compiler_version != \"None\"]\n    - libcusparse-dev                        # [cuda_compiler_version != \"None\"]\n    - cuda-cudart-dev                        # [cuda_compiler_version != \"None\"]\n    - cuda-version {{ cuda_compiler_version }}  # [cuda_compiler_version != \"None\"]\n  run:\n    - python\n    - hydra-core >=1.3.2\n    - pytorch\n    - libtorch *=cpu*                        # [cuda_compiler_version == \"None\"]\n    - libtorch *=cuda*                       # [cuda_compiler_version != \"None\"]\n    - torchvision >=0.20.1\n    # https://github.com/facebookresearch/segment-anything-2/pull/216\n    - scikit-image                           # [cuda_compiler_version == \"None\"]\n    # It doesn't seem to be used anywhere in their code...\n    # https://github.com/conda-forge/iopath-feedstock/pull/3\n    - iopath >=0.1.10\n    - tqdm\n    - pillow >=9.4.0\n    # avoid that people without GPUs needlessly download ~0.5-1GB\n    - __cuda                                 # [cuda_compiler_version != \"None\"]\n  run_constrained:\n    # Let the run_export from pytorch take effect\n    # so put their requirement here\n    - pytorch >=2.3.1\n    # There seems to be an other package on conda-forge with\n    # a similar name that wasn't packaged from the official\n    # source\n    # https://github.com/conda-forge/sam2-feedstock/issues/4\n    # I will be working with them to ensure that\n    # we have a cohesive version at conda-forge but the 0.4.1\n    # version should not be co-installed with this package\n    - sam2 >=1.0.0\n\ntest:\n  imports:\n    - sam2\n  requires:\n    - pip\n  commands:\n    - pip check\n    # Tests that cuda compilation worked for the expected output\n    - test -f ${SP_DIR}/sam2/_C.so              # [linux and cuda_compiler_version != \"None\"]\n    - if not exist %SP_DIR%\\sam2\\_C.pyd exit 1  # [win and cuda_compiler_version != \"None\"]\n\nabout:\n  home: https://github.com/facebookresearch/segment-anything-2\n  summary: 'SAM 2: Segment Anything in Images and Videos'\n  description: |\n    Segment Anything Model 2 (SAM 2) is a foundation model towards solving\n    promptable visual segmentation in images and videos. We extend SAM to video\n    by considering images as a video with a single frame. The model design is a\n    simple transformer architecture with streaming memory for real-time video\n    processing. We build a model-in-the-loop data engine, which improves model\n    and data via user interaction, to collect our SA-V dataset, the largest\n    video segmentation dataset to date. SAM 2 trained on our data provides\n    strong performance across a wide range of tasks and visual domains.\n  license: Apache-2.0\n  license_family: Apache\n  license_file: LICENSE\n\nextra:\n  recipe-maintainers:\n    - hmaarrfk\n",
  "req": {
    "__set__": true,
    "elements": [
      "__cuda",
      "c_compiler_stub",
      "c_stdlib_stub",
      "cuda-cudart-dev",
      "cuda-version",
      "cuda_compiler_stub",
      "cxx_compiler_stub",
      "hydra-core",
      "iopath",
      "libcublas-dev",
      "libcusolver-dev",
      "libcusparse-dev",
      "libtorch",
      "ninja",
      "pillow",
      "pip",
      "python",
      "pytorch",
      "scikit-image",
      "setuptools",
      "torchvision",
      "tqdm"
    ]
  },
  "requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "ninja"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cuda-cudart-dev",
        "cuda-version",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "libcublas-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "libtorch",
        "pip",
        "python",
        "pytorch",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "__cuda",
        "c_compiler_stub",
        "c_stdlib_stub",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "hydra-core",
        "iopath",
        "libtorch",
        "pillow",
        "python",
        "pytorch",
        "scikit-image",
        "torchvision",
        "tqdm"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "strong_exports": false,
  "total_requirements": {
    "build": {
      "__set__": true,
      "elements": [
        "c_compiler_stub",
        "c_stdlib_stub",
        "cuda_compiler_stub",
        "cxx_compiler_stub",
        "ninja"
      ]
    },
    "host": {
      "__set__": true,
      "elements": [
        "cuda-cudart-dev",
        "cuda-version 12.9",
        "libcublas-dev",
        "libcusolver-dev",
        "libcusparse-dev",
        "libtorch *=cpu*",
        "libtorch *=cuda*",
        "pip",
        "python",
        "pytorch",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "__cuda",
        "hydra-core >=1.3.2",
        "iopath >=0.1.10",
        "libtorch *=cpu*",
        "libtorch *=cuda*",
        "pillow >=9.4.0",
        "python",
        "pytorch",
        "scikit-image",
        "torchvision >=0.20.1",
        "tqdm"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  },
  "url": "https://github.com/facebookresearch/segment-anything-2/archive/2b90b9f5ceec907a1c18123530e92e794ad901a4.tar.gz",
  "version": "1.0.0.20241215",
  "version_pr_info": {
    "__lazy_json__": "version_pr_info/sam-2.json"
  },
  "win_64_meta_yaml": {
    "about": {
      "description": "Segment Anything Model 2 (SAM 2) is a foundation model towards solving\npromptable visual segmentation in images and videos. We extend SAM to video\nby considering images as a video with a single frame. The model design is a\nsimple transformer architecture with streaming memory for real-time video\nprocessing. We build a model-in-the-loop data engine, which improves model\nand data via user interaction, to collect our SA-V dataset, the largest\nvideo segmentation dataset to date. SAM 2 trained on our data provides\nstrong performance across a wide range of tasks and visual domains.\n",
      "home": "https://github.com/facebookresearch/segment-anything-2",
      "license": "Apache-2.0",
      "license_family": "Apache",
      "license_file": "LICENSE",
      "summary": "SAM 2: Segment Anything in Images and Videos"
    },
    "build": {
      "number": "303",
      "script": [
        "python -m pip install . -vv"
      ],
      "string": "cpu_py314h1234567_3"
    },
    "extra": {
      "recipe-maintainers": [
        "hmaarrfk"
      ]
    },
    "package": {
      "name": "sam-2",
      "version": "1.0.0.20241215"
    },
    "requirements": {
      "build": [],
      "host": [
        "python",
        "pip",
        "setuptools",
        "pytorch",
        "libtorch *=cpu*"
      ],
      "run": [
        "python",
        "hydra-core >=1.3.2",
        "pytorch",
        "libtorch *=cpu*",
        "torchvision >=0.20.1",
        "scikit-image",
        "iopath >=0.1.10",
        "tqdm",
        "pillow >=9.4.0"
      ],
      "run_constrained": [
        "pytorch >=2.3.1",
        "sam2 >=1.0.0"
      ]
    },
    "schema_version": 0,
    "source": {
      "patches": [
        "216_be_compatible_with_cpu_only.patch"
      ],
      "sha256": "1f2fbfad3ffa38110368abac76c6ef9df9c282a66d5c2807bc94abf4d2fb30f8",
      "url": "https://github.com/facebookresearch/segment-anything-2/archive/2b90b9f5ceec907a1c18123530e92e794ad901a4.tar.gz"
    },
    "test": {
      "commands": [
        "pip check"
      ],
      "imports": [
        "sam2"
      ],
      "requires": [
        "pip"
      ]
    }
  },
  "win_64_requirements": {
    "build": {
      "__set__": true,
      "elements": []
    },
    "host": {
      "__set__": true,
      "elements": [
        "libtorch",
        "pip",
        "python",
        "pytorch",
        "setuptools"
      ]
    },
    "run": {
      "__set__": true,
      "elements": [
        "hydra-core",
        "iopath",
        "libtorch",
        "pillow",
        "python",
        "pytorch",
        "scikit-image",
        "torchvision",
        "tqdm"
      ]
    },
    "test": {
      "__set__": true,
      "elements": [
        "pip"
      ]
    }
  }
}